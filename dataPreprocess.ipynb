{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2torkTyrKNq"
   },
   "source": [
    "# Leveraging Bitext mining and COMET-QE for improving parallel data selection of low-resource machine translation  \n",
    "<a href=\"https://colab.research.google.com/github/emmanuelayanful/AIMS-NLP-Project/blob/main/dataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743746302853,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "mb3juNSs5kIS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import runpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.11.0 (from afrolid) (from versions: 2.2.0, 2.2.1, 2.2.2)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.11.0\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/UBC-NLP/afrolid.git --q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5bz9AaB5kIX",
    "outputId": "ff8d7288-76fc-4f44-b267-107a539ec45d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install -r requirements.txt -q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743711933777,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "UJqqKMMrUdjH",
    "outputId": "83950c77-c514-4efd-db84-15a5e7c74205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataPreprocess.ipynb   language_map.py   MBART-50.ipynb   Results\n",
      " dataPreprocess.py      M2M.ipynb\t  __pycache__\t  'Results from Experiment.gsheet'\n",
      " Google-T5.ipynb        main.ipynb\t  README.md\t   run_translation.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743746302853,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "lh2ygyCH6hlu"
   },
   "outputs": [],
   "source": [
    "os.chdir(\"AIMS-NLP-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1743746115119,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "8xHk-MlugkRc"
   },
   "outputs": [],
   "source": [
    "! rm -r data/mafand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1743746158476,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "F2KYnMJLYzaP",
    "outputId": "6422191b-0ccb-4232-965f-0eae93cd3f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m__pycache__/\u001b[m\n",
      "\t\u001b[31mdata/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5189,
     "status": "ok",
     "timestamp": 1743746174017,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "SwjCRSP9Y2rl"
   },
   "outputs": [],
   "source": [
    "! git add data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 969,
     "status": "ok",
     "timestamp": 1743746181998,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "Yv5xXdUmZF2U",
    "outputId": "9865f6fb-c5a8-48e2-a930-7600539afb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 9e521d1] final data to be used\n",
      " 90 files changed, 956309 insertions(+)\n",
      " create mode 100644 data/flores/en-ha/dev.json\n",
      " create mode 100644 data/flores/en-ha/devtest.json\n",
      " create mode 100644 data/flores/en-ig/dev.json\n",
      " create mode 100644 data/flores/en-ig/devtest.json\n",
      " create mode 100644 data/flores/en-sw/dev.json\n",
      " create mode 100644 data/flores/en-sw/devtest.json\n",
      " create mode 100644 data/flores/en-yo/dev.json\n",
      " create mode 100644 data/flores/en-yo/devtest.json\n",
      " create mode 100644 data/flores/fr-sw/dev.json\n",
      " create mode 100644 data/flores/fr-sw/devtest.json\n",
      " create mode 100644 data/mafand/en-ha/merged.json\n",
      " create mode 100644 data/mafand/en-ha/test.json\n",
      " create mode 100644 data/mafand/en-ha/train.json\n",
      " create mode 100644 data/mafand/en-ha/validation.json\n",
      " create mode 100644 data/mafand/en-ig/merged.json\n",
      " create mode 100644 data/mafand/en-ig/test.json\n",
      " create mode 100644 data/mafand/en-ig/train.json\n",
      " create mode 100644 data/mafand/en-ig/validation.json\n",
      " create mode 100644 data/mafand/en-sw/merged.json\n",
      " create mode 100644 data/mafand/en-sw/test.json\n",
      " create mode 100644 data/mafand/en-sw/train.json\n",
      " create mode 100644 data/mafand/en-sw/validation.json\n",
      " create mode 100644 data/mafand/en-yo/merged.json\n",
      " create mode 100644 data/mafand/en-yo/test.json\n",
      " create mode 100644 data/mafand/en-yo/train.json\n",
      " create mode 100644 data/mafand/en-yo/validation.json\n",
      " create mode 100644 data/mafand/fr-sw/merged.json\n",
      " create mode 100644 data/mafand/fr-sw/test.json\n",
      " create mode 100644 data/mafand/fr-sw/train.json\n",
      " create mode 100644 data/mafand/fr-sw/validation.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/train_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ha/trainer_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/train_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-ig/trainer_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/train_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-sw/trainer_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/train_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/en-yo/trainer_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/train_8000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_1000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_16000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_2000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_32000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_4000.json\n",
      " create mode 100644 data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_8000.json\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"final data to be used\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1743746186177,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "yi_ti5NBZo_0",
    "outputId": "f862551e-3e34-475e-f40f-67774e99a806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t\u001b[31m__pycache__/\u001b[m\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22587,
     "status": "ok",
     "timestamp": 1743746214400,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "9qVozvGha2Z-",
    "outputId": "465b82c0-ab22-455c-e246-4aabcdbfbfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 113, done.\n",
      "Counting objects:   0% (1/113)\rCounting objects:   1% (2/113)\rCounting objects:   2% (3/113)\rCounting objects:   3% (4/113)\rCounting objects:   4% (5/113)\rCounting objects:   5% (6/113)\rCounting objects:   6% (7/113)\rCounting objects:   7% (8/113)\rCounting objects:   8% (10/113)\rCounting objects:   9% (11/113)\rCounting objects:  10% (12/113)\rCounting objects:  11% (13/113)\rCounting objects:  12% (14/113)\rCounting objects:  13% (15/113)\rCounting objects:  14% (16/113)\rCounting objects:  15% (17/113)\rCounting objects:  16% (19/113)\rCounting objects:  17% (20/113)\rCounting objects:  18% (21/113)\rCounting objects:  19% (22/113)\rCounting objects:  20% (23/113)\rCounting objects:  21% (24/113)\rCounting objects:  22% (25/113)\rCounting objects:  23% (26/113)\rCounting objects:  24% (28/113)\rCounting objects:  25% (29/113)\rCounting objects:  26% (30/113)\rCounting objects:  27% (31/113)\rCounting objects:  28% (32/113)\rCounting objects:  29% (33/113)\rCounting objects:  30% (34/113)\rCounting objects:  31% (36/113)\rCounting objects:  32% (37/113)\rCounting objects:  33% (38/113)\rCounting objects:  34% (39/113)\rCounting objects:  35% (40/113)\rCounting objects:  36% (41/113)\rCounting objects:  37% (42/113)\rCounting objects:  38% (43/113)\rCounting objects:  39% (45/113)\rCounting objects:  40% (46/113)\rCounting objects:  41% (47/113)\rCounting objects:  42% (48/113)\rCounting objects:  43% (49/113)\rCounting objects:  44% (50/113)\rCounting objects:  45% (51/113)\rCounting objects:  46% (52/113)\rCounting objects:  47% (54/113)\rCounting objects:  48% (55/113)\rCounting objects:  49% (56/113)\rCounting objects:  50% (57/113)\rCounting objects:  51% (58/113)\rCounting objects:  52% (59/113)\rCounting objects:  53% (60/113)\rCounting objects:  54% (62/113)\rCounting objects:  55% (63/113)\rCounting objects:  56% (64/113)\rCounting objects:  57% (65/113)\rCounting objects:  58% (66/113)\rCounting objects:  59% (67/113)\rCounting objects:  60% (68/113)\rCounting objects:  61% (69/113)\rCounting objects:  62% (71/113)\rCounting objects:  63% (72/113)\rCounting objects:  64% (73/113)\rCounting objects:  65% (74/113)\rCounting objects:  66% (75/113)\rCounting objects:  67% (76/113)\rCounting objects:  68% (77/113)\rCounting objects:  69% (78/113)\rCounting objects:  70% (80/113)\rCounting objects:  71% (81/113)\rCounting objects:  72% (82/113)\rCounting objects:  73% (83/113)\rCounting objects:  74% (84/113)\rCounting objects:  75% (85/113)\rCounting objects:  76% (86/113)\rCounting objects:  77% (88/113)\rCounting objects:  78% (89/113)\rCounting objects:  79% (90/113)\rCounting objects:  80% (91/113)\rCounting objects:  81% (92/113)\rCounting objects:  82% (93/113)\rCounting objects:  83% (94/113)\rCounting objects:  84% (95/113)\rCounting objects:  85% (97/113)\rCounting objects:  86% (98/113)\rCounting objects:  87% (99/113)\rCounting objects:  88% (100/113)\rCounting objects:  89% (101/113)\rCounting objects:  90% (102/113)\rCounting objects:  91% (103/113)\rCounting objects:  92% (104/113)\rCounting objects:  93% (106/113)\rCounting objects:  94% (107/113)\rCounting objects:  95% (108/113)\rCounting objects:  96% (109/113)\rCounting objects:  97% (110/113)\rCounting objects:  98% (111/113)\rCounting objects:  99% (112/113)\rCounting objects: 100% (113/113)\rCounting objects: 100% (113/113), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (111/111), done.\n",
      "Writing objects: 100% (112/112), 42.88 MiB | 4.48 MiB/s, done.\n",
      "Total 112 (delta 37), reused 18 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (37/37), completed with 1 local object.\u001b[K\n",
      "To github.com:emmanuelayanful/AIMS-NLP-Project.git\n",
      "   39749dc..9e521d1  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9erw4okyam8t"
   },
   "outputs": [],
   "source": [
    "! git reset --soft HEAD~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1743745816075,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "c6IBatFT_qMd",
    "outputId": "36c07923-9b9f-4e64-b03c-e86ba5c0ecec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 7, done.\u001b[K\n",
      "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
      "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (4/4), 114.15 KiB | 806.00 KiB/s, done.\n",
      "From github.com:emmanuelayanful/AIMS-NLP-Project\n",
      "   2bc3298..39749dc  main       -> origin/main\n",
      "Updating 2bc3298..39749dc\n",
      "Fast-forward\n",
      " M2M.ipynb            |     2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " dataPreprocess.ipynb | 47023 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
      " 2 files changed, 46395 insertions(+), 630 deletions(-)\n"
     ]
    }
   ],
   "source": [
    "! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTjjUdWeUJxG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 38663,
     "status": "error",
     "timestamp": 1743746349423,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "Pc3R3HzL_Lsc",
    "outputId": "24f33664-421d-4f22-9a4c-da5f5b4aa084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cc162acbe348fe8512b13fef3b34fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a110c965124e31b6ca630159cbf30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6347e7feda7a48548c5758c759f910dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd8da8c412d436cbde5edb7b8a95d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2e92f3dafc4cd78836049a0e190fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da00d61ae62c469f998ff34edc852b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb68779c0764490b8abe6e2003d98c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0f3770d5d246e9a29ac5a5548d89d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b70e6eed8284441843a0f2fe6e169b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387274391258485d92d8315c54a1dab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc678c21c3460a909ca4425982d82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586889d0979844708a65ae8540ba8142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8003d40aceb4c3d8acf0295c2a0eb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3d71b1cb9f4d4faefc2df98a280697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0cf7f28d0b4cd2a757a34f541e6f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def32ef1046d44bea72c90a9a6799d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fcb8a53d574dce8ae7c1b5d0fcb5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9185fafb37148a18371db84d2b97fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "No COMET-QE model provided. Using random sampling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84053527946d4750b54125c92581ba3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f7d6b9f9054e09a103557dbcf45109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Language pairs and dataset sources (with dataset-specific codes)\n",
    "language_pairs = {\n",
    "    \"allenai/nllb\": [\n",
    "        (\"ewe_Latn\", \"fra_Latn\", \"Ewe\", \"French\"),\n",
    "        (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "        (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "        (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "        (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    # \"facebook/flores\": [\n",
    "    #     (\"fra_Latn\", \"ewe_Latn\", \"French\", \"Ewe\"),\n",
    "    #     (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "    #     (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "    #     (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "    #     (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    # ],\n",
    "    # \"masakhane/mafand\": [\n",
    "    #     (\"fr\", \"ewe\", \"French\", \"Ewe\"),\n",
    "    #     (\"en\", \"twi\", \"English\", \"Twi\"),\n",
    "    #     (\"en\", \"hau\", \"English\", \"Hausa\"),\n",
    "    #     (\"en\", \"ibo\", \"English\", \"Igbo\"),\n",
    "    #     (\"en\", \"yor\", \"English\", \"Yoruba\")\n",
    "    # ]\n",
    "}\n",
    "\n",
    "top_k_values = [1000 * 2 ** i for i in range(6)]\n",
    "HF_TOKEN = \"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\"\n",
    "DEVICE = \"cuda\"\n",
    "COMET_MODEL = \"masakhane/africomet-qe-stl-1.1\"\n",
    "#COMET_MODEL = \"None\"\n",
    "\n",
    "base_path = Path(\"data\")\n",
    "\n",
    "# Download and preprocess data\n",
    "for dataset, pairs in language_pairs.items():\n",
    "    for src, tgt, src_name, tgt_name in pairs:\n",
    "        if dataset.startswith(\"allenai/nllb\"):\n",
    "            for top_k in top_k_values:\n",
    "                print(f\"\\n>>> Processing {dataset} | {src}-{tgt} | top_k={top_k}\")\n",
    "                sys.argv = [\n",
    "                    \"dataPreprocess.py\",\n",
    "                    \"--output_dir\", str(base_path),\n",
    "                    \"--dataset_name\", dataset,\n",
    "                    \"--source_lang\", src,\n",
    "                    \"--source_lang_name\", src_name,\n",
    "                    \"--target_lang\", tgt,\n",
    "                    \"--target_lang_name\", tgt_name,\n",
    "                    \"--hf_token\", HF_TOKEN,\n",
    "                    \"--batch_size\", \"4096\",\n",
    "                    \"--top_k_train\", str(top_k),\n",
    "                    \"--device\", DEVICE,\n",
    "                    \"--comet_model\", COMET_MODEL\n",
    "                ]\n",
    "                runpy.run_path(\"/content/AIMS-NLP-Project/dataPreprocess.py\", run_name=\"__main__\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n>>> Processing {dataset} | {src}-{tgt}\")\n",
    "            sys.argv = [\n",
    "                \"dataPreprocess.py\",\n",
    "                \"--output_dir\", str(base_path),\n",
    "                \"--dataset_name\", dataset,\n",
    "                \"--source_lang\", src,\n",
    "                \"--source_lang_name\", src_name,\n",
    "                \"--target_lang\", tgt,\n",
    "                \"--target_lang_name\", tgt_name,\n",
    "                \"--hf_token\", HF_TOKEN,\n",
    "                \"--batch_size\", \"4096\",\n",
    "                \"--device\", DEVICE,\n",
    "                \"--comet_model\", COMET_MODEL\n",
    "            ]\n",
    "\n",
    "            runpy.run_path(\"/content/AIMS-NLP-Project/dataPreprocess.py\", run_name=\"__main__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5761,
     "status": "ok",
     "timestamp": 1743746146733,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "WxOw0RtmVBMq",
    "outputId": "7e0ba44e-80d4-4814-d42b-c37cad01ed84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 2000, 4000, 8000, 16000, 32000]\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_1000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_1000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_1000.json\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_2000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_2000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_2000.json\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_4000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_4000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_4000.json\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_8000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_8000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_8000.json\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_16000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_16000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_16000.json\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_32000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_32000.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_32000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_1000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_1000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_1000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_2000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_2000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_2000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_4000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_4000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_4000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_8000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_8000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_8000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_16000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_16000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_16000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_32000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_32000.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_32000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_1000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_1000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_1000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_2000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_2000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_2000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_4000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_4000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_4000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_8000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_8000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_8000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_16000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_16000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_16000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_32000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_32000.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_32000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_1000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_1000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_1000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_2000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_2000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_2000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_4000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_4000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_4000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_8000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_8000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_8000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_16000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_16000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_16000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_32000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_32000.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_32000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_1000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_1000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_1000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_2000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_2000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_2000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_4000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_4000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_4000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_8000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_8000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_8000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_16000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_16000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_16000.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_32000.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_32000.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_32000.json\n"
     ]
    }
   ],
   "source": [
    "from dataPreprocess import merge_jsonlines\n",
    "\n",
    "# Merge with baseline mafand data\n",
    "top_k_values = [1000 * 2 ** i for i in range(6)]\n",
    "print(top_k_values)\n",
    "for lang in [\"fr-sw\", \"en-sw\", \"en-ha\", \"en-ig\", \"en-yo\"]:\n",
    "    output_path = base_path / \"nllb\" / \"africomet-qe-stl-1.1\" / f\"{lang}\"\n",
    "    baseline_file = base_path / \"mafand\" / f\"{lang}\" / \"merged.json\"\n",
    "    input_files = [output_path / f\"train_{top_k}.json\" for top_k in top_k_values]\n",
    "\n",
    "    for input_file in input_files:\n",
    "        trainer_file = output_path / f\"trainer_{input_file.stem.split('_')[-1]}.json\"\n",
    "        print(trainer_file)\n",
    "        print(f\"\\n>>> Merging {input_file} with baseline {baseline_file} into {trainer_file}\")\n",
    "        merge_jsonlines([str(baseline_file), str(input_file)], str(trainer_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | ewe_Latn-fra_Latn | top_k=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into Hugging Face.\n",
      "Processing language pair: ewe_Latn-fra_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the ewe_Latn-fra_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a62643886f474ba3ddd2a6f43f7495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8554a2b7e54491a142b3a3d92f6a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model after LID filtering.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "python(31162) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(31211) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:47<00:00,  3.62s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53ea4ad13c54201abbae4707139df16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-twi_Latn | top_k=100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into Hugging Face.\n",
      "Processing language pair: eng_Latn-twi_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-twi_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2d6efb391149bdac617428ce051b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ef00aaf5d294945b1abdcee44253464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model after LID filtering.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:420: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n",
      "python(31530) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(31570) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Predicting DataLoader 0: 100%|██████████| 13/13 [00:48<00:00,  3.74s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766ae6069fab43d69bc631ab0a9826c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch# Language pairs and dataset sources (with dataset-specific codes)\n",
    "language_pairs = {\n",
    "    \"allenai/nllb\": [\n",
    "        (\"ewe_Latn\", \"fra_Latn\", \"Ewe\", \"French\"),\n",
    "        (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "        # (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "        # (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "        # (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    # \"facebook/flores\": [\n",
    "    #     (\"fra_Latn\", \"ewe_Latn\", \"French\", \"Ewe\"),\n",
    "    #     (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "    #     (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "    #     (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "    #     (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    # ],\n",
    "    # \"masakhane/mafand\": [\n",
    "    #     (\"fr\", \"ewe\", \"French\", \"Ewe\"),\n",
    "    #     (\"en\", \"twi\", \"English\", \"Twi\"),\n",
    "    #     (\"en\", \"hau\", \"English\", \"Hausa\"),\n",
    "    #     (\"en\", \"ibo\", \"English\", \"Igbo\"),\n",
    "    #     (\"en\", \"yor\", \"English\", \"Yoruba\")\n",
    "    # ]\n",
    "}\n",
    "\n",
    "top_k_values = [100]#0 * 2 ** i for i in range(6)]\n",
    "HF_TOKEN = \"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\"\n",
    "DEVICE = \"cuda\"\n",
    "COMET_MODEL = \"masakhane/africomet-qe-stl-1.1\"\n",
    "#COMET_MODEL = \"None\"\n",
    "\n",
    "base_path = Path(\"data\")\n",
    "\n",
    "# Download and preprocess data\n",
    "for dataset, pairs in language_pairs.items():\n",
    "    for src, tgt, src_name, tgt_name in pairs:\n",
    "        if dataset.startswith(\"allenai/nllb\"):\n",
    "            for top_k in top_k_values:\n",
    "                print(f\"\\n>>> Processing {dataset} | {src}-{tgt} | top_k={top_k}\")\n",
    "                sys.argv = [\n",
    "                    \"try.py\",\n",
    "                    \"--output_dir\", str(base_path),\n",
    "                    \"--dataset_name\", dataset,\n",
    "                    \"--source_lang\", src,\n",
    "                    \"--source_lang_name\", src_name,\n",
    "                    \"--target_lang\", tgt,\n",
    "                    \"--target_lang_name\", tgt_name,\n",
    "                    \"--hf_token\", HF_TOKEN,\n",
    "                    \"--batch_size\", \"4096\",\n",
    "                    \"--top_k_train\", str(top_k),\n",
    "                    \"--device\", DEVICE,\n",
    "                    \"--comet_model\", COMET_MODEL\n",
    "                ]\n",
    "                runpy.run_path(\"./try.py\", run_name=\"__main__\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n>>> Processing {dataset} | {src}-{tgt}\")\n",
    "            sys.argv = [\n",
    "                \"try.py\",\n",
    "                \"--output_dir\", str(base_path),\n",
    "                \"--dataset_name\", dataset,\n",
    "                \"--source_lang\", src,\n",
    "                \"--source_lang_name\", src_name,\n",
    "                \"--target_lang\", tgt,\n",
    "                \"--target_lang_name\", tgt_name,\n",
    "                \"--hf_token\", HF_TOKEN,\n",
    "                \"--batch_size\", \"4096\",\n",
    "                \"--device\", DEVICE,\n",
    "                \"--comet_model\", COMET_MODEL\n",
    "            ]\n",
    "\n",
    "            runpy.run_path(\"./try.py\", run_name=\"__main__\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
