{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2torkTyrKNq"
   },
   "source": [
    "# Leveraging Bitext mining and COMET-QE for improving parallel data selection of low-resource machine translation  \n",
    "<a href=\"https://colab.research.google.com/github/emmanuelayanful/AIMS-NLP-Project/blob/main/dataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1743355767913,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "mb3juNSs5kIS"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5bz9AaB5kIX",
    "outputId": "ff8d7288-76fc-4f44-b267-107a539ec45d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install -r requirements.txt -q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "error",
     "timestamp": 1743355769569,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "lh2ygyCH6hlu",
    "outputId": "058c1b22-8da3-458d-df1f-0322c7b4b59c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AIMS-NLP-Project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6b11c4f6bb7d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AIMS-NLP-Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AIMS-NLP-Project'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"AIMS-NLP-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_1000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_1000.json\n",
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_2000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_2000.json\n",
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_4000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_4000.json\n",
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_8000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_8000.json\n",
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_16000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_16000.json\n",
      "\n",
      ">>> Merging data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_32000.json with baseline data/mafand/en-zu/merged.json into data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainers_32000.json\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 37514.79 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 14617.56 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 35962.63 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 15750.89 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 33017.50 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 15738.49 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 29201.97 examples/s]\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 11042.74 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 16000/16000 [00:00<00:00, 33689.31 examples/s]\n",
      "Map: 100%|██████████| 16000/16000 [00:01<00:00, 13416.37 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-hau | top_k=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-hau\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 32000/32000 [00:01<00:00, 24978.38 examples/s]\n",
      "Map: 100%|██████████| 32000/32000 [00:04<00:00, 7444.61 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 35677.38 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 13672.60 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 37552.24 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 15366.54 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 37086.06 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 11917.74 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 36441.83 examples/s]\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 15773.06 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 16000/16000 [00:00<00:00, 19073.47 examples/s]\n",
      "Map: 100%|██████████| 16000/16000 [00:01<00:00, 10891.32 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-ibo | top_k=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-ibo\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 32000/32000 [00:01<00:00, 27111.25 examples/s]\n",
      "Map: 100%|██████████| 32000/32000 [00:03<00:00, 10126.66 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 26593.52 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:00<00:00, 12671.42 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 33087.37 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:00<00:00, 15369.49 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 32845.82 examples/s]\n",
      "Map: 100%|██████████| 4000/4000 [00:00<00:00, 15077.96 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 33069.31 examples/s]\n",
      "Map: 100%|██████████| 8000/8000 [00:00<00:00, 15818.40 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 16000/16000 [00:00<00:00, 31366.65 examples/s]\n",
      "Map: 100%|██████████| 16000/16000 [00:01<00:00, 13319.30 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/wmt22_african | eng-yor | top_k=32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng-yor\n",
      "No COMET-QE model provided. Using random sampling.\n",
      "Map: 100%|██████████| 32000/32000 [00:01<00:00, 25200.26 examples/s]\n",
      "Map: 100%|██████████| 32000/32000 [00:03<00:00, 10082.89 examples/s]\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-hau_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng_Latn-hau_Latn\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-ibo_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-yor_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-hau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: en-hau\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-ibo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: en-ibo\n",
      "Processing completed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-yor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n",
      "Processing language pair: en-yor\n",
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Language pairs and dataset sources (with dataset-specific codes)\n",
    "language_pairs = {\n",
    "    \"allenai/wmt22_african\": [\n",
    "        (\"eng\", \"hau\", \"English\", \"Hausa\"),\n",
    "        (\"eng\", \"ibo\", \"English\", \"Igbo\"),\n",
    "        (\"eng\", \"yor\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    \"facebook/flores\": [\n",
    "        (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "        (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "        (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    \"masakhane/mafand\": [\n",
    "        (\"en\", \"hau\", \"English\", \"Hausa\"),\n",
    "        (\"en\", \"ibo\", \"English\", \"Igbo\"),\n",
    "        (\"en\", \"yor\", \"English\", \"Yoruba\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "top_k_values = [1000 * 2 ** i for i in range(6)]\n",
    "HF_TOKEN = \"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\"\n",
    "DEVICE = \"cuda\"\n",
    "COMET_MODEL = \"None\"#\"africomet-qe-stl-1.1\"\n",
    "\n",
    "base_path = Path(\"data\")\n",
    "\n",
    "# Download and preprocess data\n",
    "for dataset, pairs in language_pairs.items():\n",
    "    for src, tgt, src_name, tgt_name in pairs:\n",
    "        if dataset.startswith(\"allenai/wmt22_african\"):\n",
    "            for top_k in top_k_values:\n",
    "                print(f\"\\n>>> Processing {dataset} | {src}-{tgt} | top_k={top_k}\")\n",
    "                cmd = [\n",
    "                    \"python\", \"dataPreprocess.py\",\n",
    "                    \"--output_dir\", str(base_path),\n",
    "                    \"--dataset_name\", dataset,\n",
    "                    \"--source_langs\", src,\n",
    "                    \"--source_langs_names\", src_name,\n",
    "                    \"--target_langs\", tgt,\n",
    "                    \"--target_langs_names\", tgt_name,\n",
    "                    \"--hf_token\", HF_TOKEN,\n",
    "                    \"--batch_size\", \"4096\",\n",
    "                    \"--top_k_train\", str(top_k),\n",
    "                    \"--device\", DEVICE,\n",
    "                    \"--comet_model\", COMET_MODEL\n",
    "                ]\n",
    "                subprocess.run(cmd)\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n>>> Processing {dataset} | {src}-{tgt}\")\n",
    "            cmd = [\n",
    "                \"python\", \"dataPreprocess.py\",\n",
    "                \"--output_dir\", str(base_path),\n",
    "                \"--dataset_name\", dataset,\n",
    "                \"--source_langs\", src,\n",
    "                \"--source_langs_names\", src_name,\n",
    "                \"--target_langs\", tgt,\n",
    "                \"--target_langs_names\", tgt_name,\n",
    "                \"--hf_token\", HF_TOKEN,\n",
    "                \"--batch_size\", \"4096\",\n",
    "                \"--top_k_train\", str(top_k),\n",
    "                \"--device\", DEVICE,\n",
    "                \"--comet_model\", COMET_MODEL\n",
    "            ]\n",
    "\n",
    "            subprocess.run(cmd)\n",
    "\n",
    "# Merge with baseline mafand data\n",
    "# for lang in [\"hau\", \"ibo\", \"yor\"]:\n",
    "#     output_path = base_path / \"wmt22_african\" / \"africomet-qe-stl-1.1\" / f\"en-{lang}\"\n",
    "#     baseline_file = base_path / \"mafand\" / f\"en-{lang}\" / \"merged.json\"\n",
    "#     input_files = [output_path / f\"train_{top_k}.json\" for top_k in top_k_values]\n",
    "\n",
    "#     for input_file in input_files:\n",
    "#         trainer_file = output_path / f\"trainers_{input_file.stem.split('_')[-1]}.json\"\n",
    "#         print(f\"\\n>>> Merging {input_file} with baseline {baseline_file} into {trainer_file}\")\n",
    "#         from dataPreprocess import merge_jsonlines\n",
    "#         merge_jsonlines([str(baseline_file), str(input_file)], str(trainer_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eukoWoOGrKNz"
   },
   "outputs": [],
   "source": [
    "input_files = [\n",
    "   path + f\"/wmt22_african/africomet-qe-stl-1.1/en-zu/train_{1000*2**i}.json\" for i in range(6)\n",
    "]\n",
    "baseline_file = path + \"/mafand/en-zu/merged.json\"\n",
    "\n",
    "output_path = path + \"/wmt22_african/africomet-qe-stl-1.1/en-zu\"\n",
    "\n",
    "for input_file in input_files:\n",
    "    merge_jsonlines([baseline_file, input_file], os.path.join(output_path, f\"trainer_{input_file.split('_')[-1]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1742633717528,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "RZbvbzWZrKNz",
    "outputId": "1ce2a281-fa89-43d9-81c0-205307523b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1576,
     "status": "ok",
     "timestamp": 1742633727904,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "2XlqXMRprQPE",
    "outputId": "c238db88-1956-44b2-c6b1-e2f7f1536535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rremote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 15.06 KiB | 1.00 MiB/s, done.\n",
      "From github.com:emmanuelayanful/AIMS-NLP-Project\n",
      "   aaf4e29..01683cb  main       -> origin/main\n",
      "Updating aaf4e29..01683cb\n",
      "Fast-forward\n",
      " M2M.ipynb            |    2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " dataPreprocess.ipynb | 1034 \u001b[32m+\u001b[m\u001b[31m---------------------------------------------------------------------\u001b[m\n",
      " run_translation.py   |  706 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 3 files changed, 708 insertions(+), 1034 deletions(-)\n",
      " create mode 100644 run_translation.py\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
