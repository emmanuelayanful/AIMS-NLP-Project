{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2torkTyrKNq"
   },
   "source": [
    "# Leveraging Bitext mining and COMET-QE for improving parallel data selection of low-resource machine translation  \n",
    "<a href=\"https://colab.research.google.com/github/emmanuelayanful/AIMS-NLP-Project/blob/main/dataPreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mb3juNSs5kIS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import runpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "H5bz9AaB5kIX",
    "outputId": "ff8d7288-76fc-4f44-b267-107a539ec45d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install -r requirements.txt -q\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lh2ygyCH6hlu"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'AIMS-NLP-Project'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIMS-NLP-Project\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AIMS-NLP-Project'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"AIMS-NLP-Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xHk-MlugkRc"
   },
   "outputs": [],
   "source": [
    "! rm -r data/mafand/en-ha/merged.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1743444817650,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "F2KYnMJLYzaP",
    "outputId": "5f1a8398-e2a8-4edb-936e-950acaabc16a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add/rm <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\t\u001b[31mdeleted:    data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_1000.json\u001b[m\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SwjCRSP9Y2rl"
   },
   "outputs": [],
   "source": [
    "! git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 439,
     "status": "ok",
     "timestamp": 1743445105197,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "Yv5xXdUmZF2U",
    "outputId": "8efd39ea-ff73-44c5-b951-057edf686a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 94eecfb] more data\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"more data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1743445130107,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "yi_ti5NBZo_0",
    "outputId": "6ce659b2-683c-4341-fac4-8a313adc591c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6971,
     "status": "ok",
     "timestamp": 1743445121421,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "9qVozvGha2Z-",
    "outputId": "574e7211-fe1e-402b-fdb2-2a1ae5d96fc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 41, done.\n",
      "Counting objects:   2% (1/36)\rCounting objects:   5% (2/36)\rCounting objects:   8% (3/36)\rCounting objects:  11% (4/36)\rCounting objects:  13% (5/36)\rCounting objects:  16% (6/36)\rCounting objects:  19% (7/36)\rCounting objects:  22% (8/36)\rCounting objects:  25% (9/36)\rCounting objects:  27% (10/36)\rCounting objects:  30% (11/36)\rCounting objects:  33% (12/36)\rCounting objects:  36% (13/36)\rCounting objects:  38% (14/36)\rCounting objects:  41% (15/36)\rCounting objects:  44% (16/36)\rCounting objects:  47% (17/36)\rCounting objects:  50% (18/36)\rCounting objects:  52% (19/36)\rCounting objects:  55% (20/36)\rCounting objects:  58% (21/36)\rCounting objects:  61% (22/36)\rCounting objects:  63% (23/36)\rCounting objects:  66% (24/36)\rCounting objects:  69% (25/36)\rCounting objects:  72% (26/36)\rCounting objects:  75% (27/36)\rCounting objects:  77% (28/36)\rCounting objects:  80% (29/36)\rCounting objects:  83% (30/36)\rCounting objects:  86% (31/36)\rCounting objects:  88% (32/36)\rCounting objects:  91% (33/36)\rCounting objects:  94% (34/36)\rCounting objects:  97% (35/36)\rCounting objects: 100% (36/36)\rCounting objects: 100% (36/36), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (29/29), done.\n",
      "Writing objects: 100% (29/29), 11.34 MiB | 4.37 MiB/s, done.\n",
      "Total 29 (delta 4), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (4/4), completed with 3 local objects.\u001b[K\n",
      "To github.com:emmanuelayanful/AIMS-NLP-Project.git\n",
      "   764c3f5..94eecfb  main -> main\n"
     ]
    }
   ],
   "source": [
    "! git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9erw4okyam8t"
   },
   "outputs": [],
   "source": [
    "! git reset --soft HEAD~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7192,
     "status": "ok",
     "timestamp": 1743445616891,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "c6IBatFT_qMd",
    "outputId": "93e1010d-7dfc-45b9-9fb9-d25cda183323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 40, done.\u001b[K\n",
      "remote: Counting objects:   2% (1/40)\u001b[K\rremote: Counting objects:   5% (2/40)\u001b[K\rremote: Counting objects:   7% (3/40)\u001b[K\rremote: Counting objects:  10% (4/40)\u001b[K\rremote: Counting objects:  12% (5/40)\u001b[K\rremote: Counting objects:  15% (6/40)\u001b[K\rremote: Counting objects:  17% (7/40)\u001b[K\rremote: Counting objects:  20% (8/40)\u001b[K\rremote: Counting objects:  22% (9/40)\u001b[K\rremote: Counting objects:  25% (10/40)\u001b[K\rremote: Counting objects:  27% (11/40)\u001b[K\rremote: Counting objects:  30% (12/40)\u001b[K\rremote: Counting objects:  32% (13/40)\u001b[K\rremote: Counting objects:  35% (14/40)\u001b[K\rremote: Counting objects:  37% (15/40)\u001b[K\rremote: Counting objects:  40% (16/40)\u001b[K\rremote: Counting objects:  42% (17/40)\u001b[K\rremote: Counting objects:  45% (18/40)\u001b[K\rremote: Counting objects:  47% (19/40)\u001b[K\rremote: Counting objects:  50% (20/40)\u001b[K\rremote: Counting objects:  52% (21/40)\u001b[K\rremote: Counting objects:  55% (22/40)\u001b[K\rremote: Counting objects:  57% (23/40)\u001b[K\rremote: Counting objects:  60% (24/40)\u001b[K\rremote: Counting objects:  62% (25/40)\u001b[K\rremote: Counting objects:  65% (26/40)\u001b[K\rremote: Counting objects:  67% (27/40)\u001b[K\rremote: Counting objects:  70% (28/40)\u001b[K\rremote: Counting objects:  72% (29/40)\u001b[K\rremote: Counting objects:  75% (30/40)\u001b[K\rremote: Counting objects:  77% (31/40)\u001b[K\rremote: Counting objects:  80% (32/40)\u001b[K\rremote: Counting objects:  82% (33/40)\u001b[K\rremote: Counting objects:  85% (34/40)\u001b[K\rremote: Counting objects:  87% (35/40)\u001b[K\rremote: Counting objects:  90% (36/40)\u001b[K\rremote: Counting objects:  92% (37/40)\u001b[K\rremote: Counting objects:  95% (38/40)\u001b[K\rremote: Counting objects:  97% (39/40)\u001b[K\rremote: Counting objects: 100% (40/40)\u001b[K\rremote: Counting objects: 100% (40/40), done.\u001b[K\n",
      "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
      "remote: Total 30 (delta 17), reused 30 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (30/30), 14.96 MiB | 3.49 MiB/s, done.\n",
      "From github.com:emmanuelayanful/AIMS-NLP-Project\n",
      "   94eecfb..78400d2  main       -> origin/main\n",
      "Updating 94eecfb..78400d2\n",
      "Fast-forward\n",
      " data/mafand/en-ha/merged.json                                   |  8665 \u001b[32m++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_1000.json |  9665 \u001b[32m++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_16000.json | 24665 \u001b[32m+++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_2000.json | 10665 \u001b[32m+++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_32000.json | 40665 \u001b[32m+++++++++++++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_4000.json | 12665 \u001b[32m++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_8000.json | 16665 \u001b[32m++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_1000.json | 10998 \u001b[32m+++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_16000.json | 25998 \u001b[32m++++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_2000.json | 11998 \u001b[32m++++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_32000.json | 41998 \u001b[32m++++++++++++++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_4000.json | 13998 \u001b[32m+++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_8000.json | 17998 \u001b[32m+++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_1000.json | 10746 \u001b[32m+++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_16000.json | 25746 \u001b[32m++++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_2000.json | 11746 \u001b[32m+++++++\u001b[m\n",
      " .../wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_32000.json | 41746 \u001b[32m+++++++++++++++++++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_4000.json | 13746 \u001b[32m+++++++++\u001b[m\n",
      " data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_8000.json | 17746 \u001b[32m+++++++++++\u001b[m\n",
      " dataPreprocess.ipynb                                            |   741 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 20 files changed, 368859 insertions(+), 1 deletion(-)\n",
      " create mode 100644 data/mafand/en-ha/merged.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_1000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_16000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_2000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_32000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_4000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ha/trainer_8000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_1000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_16000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_2000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_32000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_4000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-ig/trainer_8000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_1000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_16000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_2000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_32000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_4000.json\n",
      " create mode 100644 data/wmt22_african/africomet-qe-stl-1.1/en-yo/trainer_8000.json\n"
     ]
    }
   ],
   "source": [
    "! git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "a = load_dataset(\"allenai/nllb\", \"ewe_Latn-fra_Latn\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'laser_score', 'source_sentence_lid', 'target_sentence_lid', 'source_sentence_source', 'source_sentence_url', 'target_sentence_source', 'target_sentence_url'],\n",
       "        num_rows: 1039385\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ewe_Latn': 'Ne wole ame vɔ̃ɖiwo tsrɔ̃m la, àkpɔ eteƒe.',\n",
       "  'fra_Latn': 'tu verras le châtiment des pécheurs.'},\n",
       " {'ewe_Latn': 'Gake mlɔeba la, mete ɖe Mawu ŋu le gbedodoɖa me hebiae be wòatsɔ nye nu vɔ̃wo akem.',\n",
       "  'fra_Latn': \"Je l'ai fait et demandé pardon à Allah.\"},\n",
       " {'ewe_Latn': 'Nya siwo gbɔna nye nusiwo ŋu woke ɖo la ƒe akpa aɖe ko:',\n",
       "  'fra_Latn': \"Et ce n'est qu'une petite partie de ce qu'ils ont montré!\"},\n",
       " {'ewe_Latn': 'Eyata míavɔ̃ o, nenye be, anyigba gli le enu, eye towo ʋã le atsiaƒu titina,',\n",
       "  'fra_Latn': \"C'est pour cela que nous ne craindrons pas, tandis que la terre sera bouleversée, et que des montagnes seront transportées au cœur des mers.\"},\n",
       " {'ewe_Latn': 'Mitsɔ eƒe esi ƒe kutsetse nɛ, eye eƒe dɔwɔwɔwo akafui le dua me!',\n",
       "  'fra_Latn': \"Donnez-lui le fruit de ses mains, et qu'aux portes ses œuvres la louent.\"},\n",
       " {'ewe_Latn': 'Ɔ ti wolaa o nyi ilaa ibono ɔ laa wɔra mɔ.',\n",
       "  'fra_Latn': \"Il est faiseur de ce qu'Il veut, Clément et Miséricordieux,\"},\n",
       " {'ewe_Latn': 'Ne wole ame vɔ̃ɖiwo tsrɔ̃m la,+ àkpɔ eteƒe.',\n",
       "  'fra_Latn': 'tu verras le châtiment des pécheurs.'},\n",
       " {'ewe_Latn': 'Ne wotrɔ dzime la etsɔnɛ kea wo.',\n",
       "  'fra_Latn': \"S'ils ont à pardonner, c'est alors qu'ils pardonnent,\"},\n",
       " {'ewe_Latn': 'Ðe menye wò kple fofowò ƒe aƒe blibo la tɔe oa?\"',\n",
       "  'fra_Latn': 'N\\'est-ce pas à toi et à toute la maison de ton père?\"'},\n",
       " {'ewe_Latn': 'Eya ta mana dzo nado tso mewò ne wòafiã wò.',\n",
       "  'fra_Latn': \"Ô Seigneur, je cherche refuge auprès de Toi contre le châtiment de l'enfer,\"},\n",
       " {'ewe_Latn': 'Wo Hamesha Tere Pas Ho,',\n",
       "  'fra_Latn': \"et de l'utilisation de vos jours de détente\"},\n",
       " {'ewe_Latn': 'Ðe menye wò kple fofowò ƒe aƒe blibo la tɔe oa?\"',\n",
       "  'fra_Latn': 'N\\'est-ce pas pour toi et pour toute la maison de ton père?\"'},\n",
       " {'ewe_Latn': 'Womeɖo ŋku wò amenuveve geɖeawo dzi o,',\n",
       "  'fra_Latn': \"ils ne se sont pas souvenus de l'abondance de ta miséricorde,\"},\n",
       " {'ewe_Latn': '18 Ale miekpɔ be Mawu nyo dɔme na ame aɖewo elabena edi be yeanyo dɔme na wo eye wònaa ame aɖewo sẽa dzime.',\n",
       "  'fra_Latn': 'Il est vrai que Dieu est miséricordieux envers qui il veut.'},\n",
       " {'ewe_Latn': \"Bɔbɔ ke mi le ji la wɔ a, mi sɔ ɖo mi be ata mɛ, n'ɛ mi n'ɛ mi la do acɛ eji,\",\n",
       "  'fra_Latn': 'A qui Il veut Il donne ce qui Lui plaît et, à qui Il veut, Il le refuse.'},\n",
       " {'ewe_Latn': 'Aɖe gbeƒã wò ku, wò tɔtrɔva.',\n",
       "  'fra_Latn': \"C'est Lui qui donne la vie et qui donne la mort; et c'est vers Lui que vous serez ramenés\"},\n",
       " {'ewe_Latn': 'Eye wòɖo eŋu be: \"Vi mele esi o, eye srɔ̃a hã ku amegã.\"',\n",
       "  'fra_Latn': \"dit: Eh bien, elle n'a pas de fils, et son mari est vieux.\"},\n",
       " {'ewe_Latn': 'Nu ka tae woatsɔ eya ŋutɔ kple eƒe dzidzimeviwo aƒu gbe',\n",
       "  'fra_Latn': 'Pourquoi ont-ils été expulsés, lui et sa descendance,'},\n",
       " {'ewe_Latn': 'Wobiae be, \"Ele se nu be ŋutsu nagbe srɔ̃a le susu',\n",
       "  'fra_Latn': 'dirent: \" Est-il permis à l\\'homme marié de se séparer de sa femme'},\n",
       " {'ewe_Latn': '...míekpɔ eƒe ɣletivi le ɣedzeƒe, eye míeva ta de ge agu na eyama esi.',\n",
       "  'fra_Latn': 'Car nous avons vu son étoile en Orient, et nous sommes venus pour l\\'adorer \" [17].'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['train'][:20]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 393835,
     "status": "error",
     "timestamp": 1743443949532,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "Pc3R3HzL_Lsc",
    "outputId": "cd8c9f69-1a04-434d-80f0-fb7e23b6fc57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | ewe_Latn-fra_Latn | top_k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: ewe_Latn-fra_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the ewe_Latn-fra_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351ebca279fd41b9a80b2a5713dbd5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "\n",
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:18<00:00,  2.71s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dede46b8de4a4767920a74837c2723e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-twi_Latn | top_k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-twi_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-twi_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ba1a0d4fba4a47b8c72bd9b4b0ffae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "\n",
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:14<00:00,  2.13s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329e44f67ae74704ba08c07e67f50fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-hau_Latn | top_k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-hau_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-hau_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aefccf10f744d378636683c28fffb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "\n",
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:15<00:00,  2.26s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee9f65ab65c4534a366d7b4f26f8de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-ibo_Latn | top_k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcd437d8a86473dbc5fabd8b1ea6d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "\n",
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:21<00:00,  3.14s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5031ea19fdeb41ababa574a67e5f94e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing allenai/nllb | eng_Latn-yor_Latn | top_k=50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41681b634edb4ae88cbee6e1ea710732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "\n",
      "Selecting top sentences with masakhane/africomet-qe-stl-1.1 model.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Predicting DataLoader 0: 100%|██████████| 7/7 [00:28<00:00,  4.08s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1fa6b29a584007b29e4eb69d6753b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | fra_Latn-ewe_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: fra_Latn-ewe_Latn\n",
      "Dataset for the fra_Latn-ewe_Latn loaded!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ca711d842d4075bc3d787eb85c42c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9042a71eddc437ab8d26857ad511219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1012 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-twi_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-twi_Latn\n",
      "Dataset for the eng_Latn-twi_Latn loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-hau_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-hau_Latn\n",
      "Dataset for the eng_Latn-hau_Latn loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-ibo_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-ibo_Latn\n",
      "Dataset for the eng_Latn-ibo_Latn loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing facebook/flores | eng_Latn-yor_Latn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: eng_Latn-yor_Latn\n",
      "Dataset for the eng_Latn-yor_Latn loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | fr-ewe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: fr-ewe\n",
      "Dataset for the fr-ewe loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-twi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: en-twi\n",
      "Dataset for the en-twi loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-hau\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: en-hau\n",
      "Dataset for the en-hau loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-ibo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: en-ibo\n",
      "Dataset for the en-ibo loaded!\n",
      "Processing completed successfully.\n",
      "Logging into huggingface.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Processing masakhane/mafand | en-yor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing language pair: en-yor\n",
      "Dataset for the en-yor loaded!\n",
      "Processing completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Language pairs and dataset sources (with dataset-specific codes)\n",
    "language_pairs = {\n",
    "    \"allenai/nllb\": [\n",
    "        (\"ewe_Latn\", \"fra_Latn\", \"Ewe\", \"French\"),\n",
    "        (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "        (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "        (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "        (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    \"facebook/flores\": [\n",
    "        (\"fra_Latn\", \"ewe_Latn\", \"Ewe\", \"French\"),\n",
    "        (\"eng_Latn\", \"twi_Latn\", \"English\", \"Twi\"),\n",
    "        (\"eng_Latn\", \"hau_Latn\", \"English\", \"Hausa\"),\n",
    "        (\"eng_Latn\", \"ibo_Latn\", \"English\", \"Igbo\"),\n",
    "        (\"eng_Latn\", \"yor_Latn\", \"English\", \"Yoruba\")\n",
    "    ],\n",
    "    \"masakhane/mafand\": [\n",
    "        (\"fr\", \"ewe\", \"French\", \"Ewe\"),\n",
    "        (\"en\", \"twi\", \"English\", \"Twi\"),\n",
    "        (\"en\", \"hau\", \"English\", \"Hausa\"),\n",
    "        (\"en\", \"ibo\", \"English\", \"Igbo\"),\n",
    "        (\"en\", \"yor\", \"English\", \"Yoruba\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "top_k_values = [1000 * 2 ** i for i in range(6)]\n",
    "HF_TOKEN = \"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\"\n",
    "DEVICE = \"cpu\"\n",
    "COMET_MODEL = \"masakhane/africomet-qe-stl-1.1\"\n",
    "\n",
    "base_path = Path(\"data\")\n",
    "\n",
    "# Download and preprocess data\n",
    "for dataset, pairs in language_pairs.items():\n",
    "    for src, tgt, src_name, tgt_name in pairs:\n",
    "        if dataset.startswith(\"allenai/nllb\"):\n",
    "            for top_k in top_k_values:\n",
    "                print(f\"\\n>>> Processing {dataset} | {src}-{tgt} | top_k={top_k}\")\n",
    "                sys.argv = [\n",
    "                    \"dataPreprocess.py\",\n",
    "                    \"--output_dir\", str(base_path),\n",
    "                    \"--dataset_name\", dataset,\n",
    "                    \"--source_lang\", src,\n",
    "                    \"--source_lang_name\", src_name,\n",
    "                    \"--target_lang\", tgt,\n",
    "                    \"--target_lang_name\", tgt_name,\n",
    "                    \"--hf_token\", HF_TOKEN,\n",
    "                    \"--batch_size\", \"4096\",\n",
    "                    \"--top_k_train\", str(top_k),\n",
    "                    \"--device\", DEVICE,\n",
    "                    \"--comet_model\", COMET_MODEL\n",
    "                ]\n",
    "                runpy.run_path(\"/Users/emmanuelayanful/Library/CloudStorage/GoogleDrive-emmanuelka@aims.ac.za/My Drive/AIMS PROJECT/AIMS-NLP-Project/dataPreprocess.py\", run_name=\"__main__\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\n>>> Processing {dataset} | {src}-{tgt}\")\n",
    "            sys.argv = [\n",
    "                \"dataPreprocess.py\",\n",
    "                \"--output_dir\", str(base_path),\n",
    "                \"--dataset_name\", dataset,\n",
    "                \"--source_lang\", src,\n",
    "                \"--source_lang_name\", src_name,\n",
    "                \"--target_lang\", tgt,\n",
    "                \"--target_lang_name\", tgt_name,\n",
    "                \"--hf_token\", HF_TOKEN,\n",
    "                \"--batch_size\", \"4096\",\n",
    "                \"--device\", DEVICE,\n",
    "                \"--comet_model\", COMET_MODEL\n",
    "            ]\n",
    "\n",
    "            runpy.run_path(\"/Users/emmanuelayanful/Library/CloudStorage/GoogleDrive-emmanuelka@aims.ac.za/My Drive/AIMS PROJECT/AIMS-NLP-Project/dataPreprocess.py\", run_name=\"__main__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "executionInfo": {
     "elapsed": 7282,
     "status": "error",
     "timestamp": 1743444381188,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "WxOw0RtmVBMq",
    "outputId": "1084a337-ec1d-4ccc-c5b6-0cb2c5adfcdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\n",
      "data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_50.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/fr-sw/train_50.json with baseline data/mafand/fr-sw/merged.json into data/nllb/africomet-qe-stl-1.1/fr-sw/trainer_50.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-sw/trainer_50.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-sw/train_50.json with baseline data/mafand/en-sw/merged.json into data/nllb/africomet-qe-stl-1.1/en-sw/trainer_50.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ha/trainer_50.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ha/train_50.json with baseline data/mafand/en-ha/merged.json into data/nllb/africomet-qe-stl-1.1/en-ha/trainer_50.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-ig/trainer_50.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-ig/train_50.json with baseline data/mafand/en-ig/merged.json into data/nllb/africomet-qe-stl-1.1/en-ig/trainer_50.json\n",
      "data/nllb/africomet-qe-stl-1.1/en-yo/trainer_50.json\n",
      "\n",
      ">>> Merging data/nllb/africomet-qe-stl-1.1/en-yo/train_50.json with baseline data/mafand/en-yo/merged.json into data/nllb/africomet-qe-stl-1.1/en-yo/trainer_50.json\n"
     ]
    }
   ],
   "source": [
    "from dataPreprocess import merge_jsonlines\n",
    "\n",
    "# Merge with baseline mafand data\n",
    "top_k_values = [1000 * 2 ** i for i in range(6)]\n",
    "print(top_k_values)\n",
    "for lang in [\"fr-sw\", \"en-sw\", \"en-ha\", \"en-ig\", \"en-yo\"]:\n",
    "    output_path = base_path / \"nllb\" / \"africomet-qe-stl-1.1\" / f\"{lang}\"\n",
    "    baseline_file = base_path / \"mafand\" / f\"{lang}\" / \"merged.json\"\n",
    "    input_files = [output_path / f\"train_{top_k}.json\" for top_k in top_k_values]\n",
    "\n",
    "    for input_file in input_files:\n",
    "        trainer_file = output_path / f\"trainer_{input_file.stem.split('_')[-1]}.json\"\n",
    "        print(trainer_file)\n",
    "        print(f\"\\n>>> Merging {input_file} with baseline {baseline_file} into {trainer_file}\")\n",
    "        merge_jsonlines([str(baseline_file), str(input_file)], str(trainer_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "error",
     "timestamp": 1743444339804,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "eukoWoOGrKNz",
    "outputId": "e315c53f-4654-4b59-cad1-6add379f202a"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4db19c3e6e55>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m input_files = [\n\u001b[0m\u001b[1;32m      2\u001b[0m    \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"/wmt22_african/africomet-qe-stl-1.1/en-zu/train_{1000*2**i}.json\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/mafand/en-zu/merged.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4db19c3e6e55>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m input_files = [\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"/wmt22_african/africomet-qe-stl-1.1/en-zu/train_{1000*2**i}.json\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      4\u001b[0m \u001b[0mbaseline_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/mafand/en-zu/merged.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "source": [
    "input_files = [\n",
    "   base_path + f\"/nllb/africomet-qe-stl-1.1/en-zu/train_{1000*2**i}.json\" for i in range(6)\n",
    "]\n",
    "baseline_file = base_path + \"/mafand/en-zu/merged.json\"\n",
    "\n",
    "output_path = base_path + \"/wmt22_african/africomet-qe-stl-1.1/en-zu\"\n",
    "\n",
    "for input_file in input_files:\n",
    "    merge_jsonlines([baseline_file, input_file], os.path.join(output_path, f\"trainer_{input_file.split('_')[-1]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 411,
     "status": "ok",
     "timestamp": 1742633717528,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "RZbvbzWZrKNz",
    "outputId": "1ce2a281-fa89-43d9-81c0-205307523b7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "! git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1576,
     "status": "ok",
     "timestamp": 1742633727904,
     "user": {
      "displayName": "Emmanuel Kwame AYANFUL",
      "userId": "02540403979605827324"
     },
     "user_tz": -120
    },
    "id": "2XlqXMRprQPE",
    "outputId": "c238db88-1956-44b2-c6b1-e2f7f1536535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects:  12% (1/8)\u001b[K\rremote: Counting objects:  25% (2/8)\u001b[K\rremote: Counting objects:  37% (3/8)\u001b[K\rremote: Counting objects:  50% (4/8)\u001b[K\rremote: Counting objects:  62% (5/8)\u001b[K\rremote: Counting objects:  75% (6/8)\u001b[K\rremote: Counting objects:  87% (7/8)\u001b[K\rremote: Counting objects: 100% (8/8)\u001b[K\rremote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "Unpacking objects:  20% (1/5)\rUnpacking objects:  40% (2/5)\rremote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects:  60% (3/5)\rUnpacking objects:  80% (4/5)\rUnpacking objects: 100% (5/5)\rUnpacking objects: 100% (5/5), 15.06 KiB | 1.00 MiB/s, done.\n",
      "From github.com:emmanuelayanful/AIMS-NLP-Project\n",
      "   aaf4e29..01683cb  main       -> origin/main\n",
      "Updating aaf4e29..01683cb\n",
      "Fast-forward\n",
      " M2M.ipynb            |    2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " dataPreprocess.ipynb | 1034 \u001b[32m+\u001b[m\u001b[31m---------------------------------------------------------------------\u001b[m\n",
      " run_translation.py   |  706 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 3 files changed, 708 insertions(+), 1034 deletions(-)\n",
      " create mode 100644 run_translation.py\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
