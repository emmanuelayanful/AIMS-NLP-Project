{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1259,"status":"ok","timestamp":1743759380601,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"vqsa3QW1weGy"},"outputs":[],"source":["import wandb\n","import os\n","import subprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ICCsdcJZpub"},"outputs":[],"source":["# !rm -rf Google_T5"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"JEU-1o2gFQkC","executionInfo":{"status":"ok","timestamp":1743747665987,"user_tz":-120,"elapsed":27,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}}},"outputs":[],"source":["!chmod u+x /content/AIMS-NLP-Project/run_translation.py"]},{"cell_type":"code","source":["# Log in with your API key\n","wandb.login(key=\"7f13d9fe09d0856f7c12099a27ccda7aa15c8afd\")\n","\n"],"metadata":{"id":"j_TvZ5HWiqoA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743759388117,"user_tz":-120,"elapsed":6159,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"447c0191-d50e-4b09-acee-303e1b00f8e7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["! rm -r M2M-100"],"metadata":{"id":"MJ242hrGBmbJ","executionInfo":{"status":"ok","timestamp":1743712682472,"user_tz":-120,"elapsed":867,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GPgjaPdU-cgP","executionInfo":{"status":"error","timestamp":1743759296529,"user_tz":-120,"elapsed":569180,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["18e354739b914b7ebde213663315212c","f8f1b2a9394949e2b3b49f0efa6c1609","b50d6b0327ba468693e68dd02ddc1ae9","662cd99346404b32a9937c5c4f9c2f40","9d6f41fdd80945afadbc3d1d40a4d621","0ff38c13637442a798f9d9d8ba9f1c9d","86a5f195e8664d068d6244009b3c13ae","3952ed20c57e4ecf9749766d6d0de90e","ee4d84b071c24252a096c8c7d1a70f25","54d9ba0a3ce84d54a763a25bdeaef1df","de2d8cc0ac4c432cb9b2905e445595cc","7584bafe63464729a6a2968ee16067a4","568ce92e79db4997b20e6e6a97cad1a8","4aca65fd137343528d36de9644868cfb","cd7025743bd34091b5e50a8b9979f473","7a131a66986b46d1ae93c51a4d3339d5","11c9982155c4410db25556466e0496a9","610186b1e05d448ebc9622dbadbb1aea","fde9f14690814a05af333842f79d9cad","294d6a1afecc48809f59454dbc93ba34","32ac7484bbd14b8ea615bedfe71284c8","7698b64d479c49d58a858aa2c55d2f8f","48a77774f5f2406099135fd2845b6385","2c767385e1e44dda8784a663b7f96a7e","7cacbd57017b4a47bb3cf338548fb407","649793ca226448c58fe11f94f8290d45","fab69dac7b1c4dc18e65b1737534246a","b71696d0b46b45c785e1c1c68fa18343","e9210ff911bd43c29879fb1c879ab369","b1ca98ac79644a97b801fe9f3502fff4","5974fecde90e4576b0a029d7e9a0dc51","894463542cde43a280dab58d9c1c6c32","ae2a4c7408e2467e8cb291557c8189d5","5edb7abcd1f44bf09864800d70db7aa3","060e5eb6ab664bc68bec198ca0d0bb20","7f69cfaa2eca4d138f227a2a68d11876","2406ee4be4784efd97003c3c34e83a1b","a6ef119b783a41f08da51efe77730f08","e3104d6d92604fb5b700d7ddcc5dc28e","9ad4c10900a04ed69db445f921f8acaa","76b386edd779436d9c8bb488b09cd1e2","7784e31f60ca4712929a251a16fd939a","8488896c2e804f6aa9b99262b24cffd8","2ffe77c11b66401095222525561c31ff","e433c024240347eabe9857b62307a91e","ad27bd64b4fe4513b14f1df61d6143cb","3355e8642f43481cb05ec43966ea51a0","e6fecc0792194b608412d1da1f7a3fba","16ebb4602e2d4263a070c873375b83f4","2a8d05edd52546ce9ab36a814e108545","e97d316b8a6e4f2bb3f1192510459eea","20599909f8594343ba156437b5c6cdf0","6ce8e0f20f234cab91e2b74eaced6971","0545ab591f214532bbd59b187e0ff1fc","617dc0451d6d4b68ad364647e360fbab","7893ab2a24674c0eba1b192736dd6ecf","0631b86da1134a25abd04c5dd4e65f7e","781d3fbaa2bc44df949d5ef7efa5e7c3","6ff156e5635f4873b630fac7df4862d9","ba4c53d525994c00ba76c974c415bb3c","235f9e8df2604d00a7340947098e0a0b","4402f479752f4d18b6113fc834fea27b","d534a3da51c448ac92620cd1b916db9d","c4f3a7beead8469497bc839f171c2c36","56651c9f0c92424fa406e9b11e06bc25","133c3f834cd54c6497705971cd3e16c4","58b6126a528c4157af5681a379fdcc54","4170874c813f4447bddd1c823fe1345c","2a0b8f5ecdf547e98cc2ae87e65ad854","7727b0a0e093445f869a73f59b446e65","bc9d1283f79d4b9ebbb8045adfcaf353","70f6023c48454e679e39574cd6689a9d","1601636eca2346a6b705e7403e9e963a","c26f84227d064e86b9e79e08d3ca2938","f8258ceb5c6646c3a7bab4c4da1e8039","6bb6ebf376b74b99ba9c3354a107bdd6","5ed7b66183844080b2db7b7eb8fe9877","1dc0bd3e71c7436092553482582b6aaf","161a9a25f1bd41aeae1fe689482ced2d","b1b4a4c90efb462684b9aa9a79d8e9ab","facbfab6a6bb4e2294323777f2c28847","9fb175540bc04271a43f832170624740","0e3081900c4b428db3811593174d19c5","eaffbd2bed9c47b4b160ed20a831eb6c","242c8b6d58254584b5395774b0e71146","a2e518b3bbce40679252ae16e5b55d18","52ab29dc6b424f508ad182b417611d5c","490126a62f114ad6a42ca8adcafa7d8e","d1a1c81d2ae84d7a9c6c0a9a72d5b2d2","f964bfd73bc64096b64f8ace04a4d8b1","3e22f377049641f7b00b17d5dc3dd667","a6afaacfb61446778ec0c5b817ab509f","e8e361559ee44ccea9486f85a71bdcef","095c2b0dcef34b26ab8a3298560b1c41","025dd055b4d04456acaa58a214e4a8f1","9f6510a34a2c4413a4fe76a8f2d261c1","7713c2de056645b089dd26e96f513262","feccf55fe1264fb0a8b27036f4d1cd31","d06b635e46db4d1b8f71d78905087c01","aed9217b9b014dd9894f774cad5cde3e","0b7346b3d1ab4147bab02105bd3dff93","60c6e771e8e94167aaa9ad27bef78c86","771ed34cfad14015b9690c23e7428b27","e97e8e8f103f4af5907057939efb44e7","7f0febe7586b482b81b4d1865d99fae6","0870bed0d707449298deb6fc40241e1a","55a7017a2a9444efa710663d36368d4e","936060b009d04e0ca051324a3757fee5","143375c8d2d64c209fd8ffb9403c050a","f1676a04c4534096b7fcebc5ff65c7a0","5bc27fd6a4a84f5b9d9f82c4016bea99","8a9b2cb27d994577983dc8bca7a8b0eb","0970b11e2ac4438da3f85e53831a4f65","b6e454f1a6bf428f960a341dfc318323","c68fcaa9c4654f789c0bf04e43f33754","315e7f389052463fafd1ea386d1b1a87","1956205c963c487fab73f3b634eb7eb8","30abfbc51bdb4a65949e373be0c02687","79034f04c5424f9cb1d75cf61ef8f969","7c69d71bd8794d68a95a2a92aafae23e","eb0b65641aa1413ba2ce95fdc3177410","6887cd6d0b9746b586af15eba6e2e8b9","49cfa26cf06e42d8b17155d91518a127","c55bfcadb69a42229f72ff26b7d0a28a","f6562fb7589146a189129211742b98dd","b61b64f0a536416b976d3c0e49aaa355","bfdd8fbe2eb548498a7055e21e38da1a","61417713e8a24026af4c036c7ea745e5","fac2b737c1e04fcca7292f18a9796c6d","593f1f9ccf0c4107bfcdc5277d389003","8b4a074d215a4305b083fe5710c4b12a","5945a657e5e44bbc912255e804ce08cd","2a6b8610210040fe93a96bedb082ff68","be2a59005ca6481b8846b9f61791b0d5","19e9fe6f06b0489b815e179035a3d4a5","c6b8b86c4b974215b170a7f7b1b2c2ad","56e86863ff8843a78f85a789ca8be6d3","22ce6615f29f4fe2a7ac8f63503ab383","756eb886d7a34f85b0f42d391abcf381","1e34143948a0476ba5a731cfb92c8d04","c1b9a0d6500042fe8892cb4cc9b61aee","586a4c7004b04d00a44bf03de74901d2","cf5f821056d6462cbe85870dcd8462fa","bd061ae80c174faea56692de3e376308","70a7b97e2dd24bd2b424ae905c7b0e41","9e847f9f273a4df8b4dc28f234e63af4","3278491357084d36b2dc97559d0869fd","2e4b04b3155f463d9c9a3d8878366b52","853c833465e144a9b70f8b04a5784c75","0ad5839b9b054d809b56949515ea60e9","3c91940103154430b34a03c77b46c06f","7149d97d08ad4d55a734216d221e5959","6c0f64bf34554de3aaad6ff463534b7d","2121473a680a490c8836814940660f1a","a11ff0a9ba89464fb7ea81ee2fe2cbae","97a0e588734549f98bb2f55bfc372963","643aad3a4d1b4971826e15b6ca98a00e","c562ced07e034a8ea6327c67cc820239","040c57119a3e4bef9b41ec9b83162a87","b9590091ebdc4250a3577974683ae392","f7b515d6cf4a43fd9e0dc00383c72556","bbbfb826cf46403783312b3aa38a2145","1ee2e1941762431b9931621c69a2b21a","ab06d47d3bee417ab29e73c9eab8a41e","8f95991e5a8e4b9bb409b55aac771f24","396d5d2f80474832850d52cff455493f","17a73c3f09b743879e5de32cd3a4c00b","831416f1365c4dd19c1ee8fedb3c8b4f","d565f72da82f42d89b14ab4201de292a","bfa4061e10f342e49f243c4bcc8142c6","38d8e4a99d6443dabdfb19235fb54efc","7013c546fcb54229804ec365d21a0c69","417b651761e345f59a8a3e95ff186bda","9b25138baf88497c91056f467ef5fa78","0341432788714b458b581f6377e3c5bc","c8179419a2654194a00a38741bcca8a6","3444cacdf0f14324ba44568001756eed","5ea06aa9f11a44baaa50b40d6fb6d4bf","6e58ac66baad4b9c912df21aeaf390c5","b9c78fb067e04b898be3263cb930ceed","fd514d9786f84b5c876df3bc0b28c9eb","51b640fd793a4b83b4fb3123f0b28d18","7e65bc45a5674e81a4ce6e6605f6354b","928363012fbf47cf92c4cc0ee6d8c094","7d167bf696d349a489bd54cd4b934637","438848ce708b40b7b909f8f341c0b3cd","45b6f8d739294a5a814619dd033eba91","5d1b40e1a6a74b29a47c662eeade465f","91a741fa72ff4477b543a022318205f7","59f8c2a0d76e448f8a41297c705cb147","858eb26fcef343908c2577d1d450c5cd","0223399acb0d4b289fe5dc44fa6994e0","cc0816f55db44baba346a39d861c859f","f6ee0afcfae84daeb9369d6cda684225","02b48885248846d5af662b5307f6ab23","71479537af01475b9bab888aa19311f4","cd61aa68f7a24542a474b1f8fbaf8db6","a1b4b68551a348a4892ecd4da49318be","52252d6da4824a989fbdc66354f61161","ab592135229d46ba99e46e9cab569463","3c42a546761d4146a3ed09e8a6f469af","a87a725a62e247699feb03e65f1ab8e0","ee7e6578546a44f3a477f66254efc125","d4a874ac43b24ba69d8a72c333243a3f","c9be883a5f794f949c58c4f39ef00f50","c1a756c812324695b955dd46436376ca","eef7765a78ac4d1daa0553b45925e3fc","8bd0e0f76002487383b6d8117ec96210","cac4054ca1cb4b2da90becee13fa4b0a","f264dbdc11684370bd9a2e40bb282a7e","253b882ff7ef4f9fa10f48c286b80987","2ac68027810543c9833e5317f17e074b","9389e60b3d15472c9c213efbb79aa5a5","4e1190a19d99402ebeff547509a1db25","5916cc4149d8444a83c5ff37bf5ee643","e2be632b6dfe4fd987ae333525fc7a1a","51f7dfe6d6d54a16ae8b8bf64f03c2d9","a4f0bd7a7ec84d41935826b7cd925739","26feee206a744090ba91d5a9ddf04b99","2ac0f48294514b5f9df96132bc7f8ef2","6752651b5a3b470b84414f4958411ce9","9ef5b950ee194b8bb9a198661859c3bd","6c2d4f3c4a934deca015e05e499fff52","34ba435ba42f44d3bf1e05b4179a2866","aa26496f37e647c9b6bdb31e82f3477d","4a3a50d9d26f432c81a74707dcc4c037","e049c83a9df0478297b8fd3ef8579865","2211163a84fd4a83bda7f7938c68d4e5","726946aba15b4287a07f3490e91f6b88","21e69b4469cd4656a1c447cf1ce1bc02","b911c45fb9b14d5fa7e144ec694097d8","248f360bd35849398a577470ab4846c8","3dde59e58dfb45d2b2e1cb101fe3530b","ee6c704e31c642beb40cb7fc9620c2c2","72b341f25e154d669efe19f5ef12da17","278ccfdc9f97468d8ad819c2376ed334","fcff7952585840a293cd2ac390376c7c","592da6a66c4442eab9e780039654d7d9","81e9b8538dda4f7a97ecc036604fd465","e0419bfc992e46c0bc9cabfbb14fdaff","9bf68032d6ac4f9083ae48550867b148","c20d078e499646db87eb9e715784522e","799da935d81c45a399335a62bc10e94c","c8914e05b19549009ecc9cef73b6847c","da84f6d5ce074deabb8ee268d48bc2a6","0afb2f0eb2b743ae8a7ce25a939b593b","d7306b9076f4489284d8cf3ce6e40ad0","7e5ac6894f924a9093aceb2092674c70","57c0023a56264298be3a42e9ba63b466","f64f18f94c3b44cc8828e763df93e480","b6c5f24eb2c44f44a31797d4c8d5f82d","99e9880687ce44259e3af28b0df5d187","0bb1b3ff6e4c4cfe987edc5afbfcd3b3","d792ee661a524ec3b1155155721b3da7","1034928bf9854f0e87d502d748923697","b1598f206510493ab56bf31e6568cd25","1bb99aa4e8864a6380b5d13a8a24bbd1","6f690735a69c44eaba08a66af5f5b69b","dd363892dc1644318747ff0e006a0fac","e49afd1083b24347aa5382680ba8a71b","4d5fa13327de496f93abedcfd6e21999","9d0480e0756a42e781cfc69de7e7f421","30e882558cd0404cac5fcbef8a87ed6a","1ce8279221ae4aa9a9186a090696d54c"]},"outputId":"2cee5626-02c1-4d53-cd29-3d3f5f5f71ec"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250404_062114-thdhj68u</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/thdhj68u' target=\"_blank\">baseline_fr-sw</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/thdhj68u' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/thdhj68u</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/fr-sw/runs/Apr04_06-21-28_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/fr-sw,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/fr-sw,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-18f265e3c1a7bc15\n","INFO:datasets.builder:Using custom data configuration default-18f265e3c1a7bc15\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e354739b914b7ebde213663315212c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7584bafe63464729a6a2968ee16067a4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a77774f5f2406099135fd2845b6385"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","[INFO|configuration_utils.py:699] 2025-04-04 06:21:37,729 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 06:21:37,735 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 06:21:37,859 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 06:21:37,862 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,866 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,867 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,869 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,871 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,872 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,874 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 06:21:37,876 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 06:21:37,878 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 06:21:37,880 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 06:21:38,898 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|safetensors_conversion.py:61] 2025-04-04 06:21:39,039 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-04-04 06:21:39,565 >> Safetensors PR exists\n","[INFO|configuration_utils.py:1140] 2025-04-04 06:21:39,793 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-04-04 06:21:39,975 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-04-04 06:21:39,977 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 06:21:40,090 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 06:21:40,092 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/5003 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5edb7abcd1f44bf09864800d70db7aa3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c0d7e89f23b76def.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c0d7e89f23b76def.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/997 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e433c024240347eabe9857b62307a91e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4d76fb81d689436c.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4d76fb81d689436c.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1012 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7893ab2a24674c0eba1b192736dd6ecf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c2c58ecba99bd7c4.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-18f265e3c1a7bc15/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c2c58ecba99bd7c4.arrow\n","[INFO|trainer.py:2407] 2025-04-04 06:21:57,907 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 06:21:57,909 >>   Num examples = 5,003\n","[INFO|trainer.py:2409] 2025-04-04 06:21:57,911 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 06:21:57,913 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 06:21:57,915 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 06:21:57,917 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 06:21:57,918 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 06:21:57,919 >>   Total optimization steps = 1,878\n","[INFO|trainer.py:2416] 2025-04-04 06:21:57,922 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 06:21:57,930 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1878' max='1878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1878/1878 27:08, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.053300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.130100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.760000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3944] 2025-04-04 06:28:51,191 >> Saving model checkpoint to M2M-100/baseline/fr-sw/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-04-04 06:28:51,203 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 06:28:51,205 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 06:28:56,127 >> Model weights saved in M2M-100/baseline/fr-sw/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 06:28:56,134 >> tokenizer config file saved in M2M-100/baseline/fr-sw/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 06:28:56,137 >> Special tokens file saved in M2M-100/baseline/fr-sw/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 06:28:56,139 >> added tokens file saved in M2M-100/baseline/fr-sw/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 06:36:05,604 >> Saving model checkpoint to M2M-100/baseline/fr-sw/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-04-04 06:36:05,608 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 06:36:05,610 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 06:36:10,587 >> Model weights saved in M2M-100/baseline/fr-sw/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 06:36:10,595 >> tokenizer config file saved in M2M-100/baseline/fr-sw/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 06:36:10,597 >> Special tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 06:36:10,599 >> added tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 06:43:18,612 >> Saving model checkpoint to M2M-100/baseline/fr-sw/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-04-04 06:43:18,616 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 06:43:18,619 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 06:43:23,699 >> Model weights saved in M2M-100/baseline/fr-sw/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 06:43:23,705 >> tokenizer config file saved in M2M-100/baseline/fr-sw/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 06:43:23,707 >> Special tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 06:43:23,709 >> added tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 06:48:50,660 >> Saving model checkpoint to M2M-100/baseline/fr-sw/checkpoint-1878\n","[INFO|configuration_utils.py:423] 2025-04-04 06:48:50,665 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1878/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 06:48:50,667 >> Configuration saved in M2M-100/baseline/fr-sw/checkpoint-1878/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 06:48:55,931 >> Model weights saved in M2M-100/baseline/fr-sw/checkpoint-1878/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 06:48:55,938 >> tokenizer config file saved in M2M-100/baseline/fr-sw/checkpoint-1878/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 06:48:55,940 >> Special tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1878/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 06:48:55,942 >> added tokens file saved in M2M-100/baseline/fr-sw/checkpoint-1878/added_tokens.json\n","[INFO|trainer.py:2659] 2025-04-04 06:49:09,448 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3944] 2025-04-04 06:49:09,459 >> Saving model checkpoint to M2M-100/baseline/fr-sw\n","[INFO|configuration_utils.py:423] 2025-04-04 06:49:09,463 >> Configuration saved in M2M-100/baseline/fr-sw/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 06:49:09,465 >> Configuration saved in M2M-100/baseline/fr-sw/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 06:49:18,408 >> Model weights saved in M2M-100/baseline/fr-sw/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 06:49:18,416 >> tokenizer config file saved in M2M-100/baseline/fr-sw/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 06:49:18,418 >> Special tokens file saved in M2M-100/baseline/fr-sw/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 06:49:18,420 >> added tokens file saved in M2M-100/baseline/fr-sw/added_tokens.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4260] 2025-04-04 06:49:18,576 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-04-04 06:49:18,578 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-04-04 06:49:18,579 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  2032456GF\n","  train_loss               =     2.1652\n","  train_runtime            = 0:27:11.52\n","  train_samples            =       5003\n","  train_samples_per_second =      9.199\n","  train_steps_per_second   =      1.151\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Predict ***\n","[INFO|trainer.py:4260] 2025-04-04 07:01:00,654 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-04-04 07:01:00,655 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-04-04 07:01:00,657 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     3.9174\n","  eval_chrf               =    24.4352\n","  eval_gen_len            =    54.9047\n","  eval_loss               =     3.1149\n","  eval_runtime            = 0:11:42.04\n","  eval_samples            =        997\n","  eval_samples_per_second =       1.42\n","  eval_steps_per_second   =      0.178\n","***** predict metrics *****\n","  predict_bleu               =     3.5708\n","  predict_chrf               =    24.4753\n","  predict_gen_len            =    55.1067\n","  predict_loss               =     3.1154\n","  predict_runtime            = 0:12:03.05\n","  predict_samples            =       1012\n","  predict_samples_per_second =        1.4\n","  predict_steps_per_second   =      0.176\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:449] 2025-04-04 07:13:20,021 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 3.9174}]}\n","[INFO|training_args.py:2206] 2025-04-04 07:13:20,077 >> PyTorch: setting up devices\n","[INFO|training_args.py:1877] 2025-04-04 07:13:20,109 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/en-sw/runs/Apr04_07-13-20_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/en-sw,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/en-sw,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-4b587bdc777f3b43\n","INFO:datasets.builder:Using custom data configuration default-4b587bdc777f3b43\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58b6126a528c4157af5681a379fdcc54"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dc0bd3e71c7436092553482582b6aaf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1a1c81d2ae84d7a9c6c0a9a72d5b2d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-04-04 07:13:20,625 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 07:13:20,629 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 07:13:20,743 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 07:13:20,745 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,749 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,750 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,751 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,753 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,755 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,757 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 07:13:20,759 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 07:13:20,761 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 07:13:20,763 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 07:13:21,692 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-04-04 07:13:21,765 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-04-04 07:13:21,856 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-04-04 07:13:21,882 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-04-04 07:13:21,886 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 07:13:22,013 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 07:13:22,016 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-04-04 07:13:22,943 >> Safetensors PR exists\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/6121 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aed9217b9b014dd9894f774cad5cde3e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1a627de8ffa937fa.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1a627de8ffa937fa.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/997 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bc27fd6a4a84f5b9d9f82c4016bea99"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-47a1ce6e7abad718.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-47a1ce6e7abad718.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1012 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6887cd6d0b9746b586af15eba6e2e8b9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2f1d7b212ca4d5c9.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-4b587bdc777f3b43/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2f1d7b212ca4d5c9.arrow\n","[INFO|trainer.py:2407] 2025-04-04 07:13:41,436 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 07:13:41,438 >>   Num examples = 6,121\n","[INFO|trainer.py:2409] 2025-04-04 07:13:41,439 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 07:13:41,441 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 07:13:41,444 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 07:13:41,446 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 07:13:41,448 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 07:13:41,449 >>   Total optimization steps = 2,298\n","[INFO|trainer.py:2416] 2025-04-04 07:13:41,453 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 07:13:41,460 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2298' max='2298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2298/2298 35:58, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.063500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.221600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.903000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.574000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3944] 2025-04-04 07:21:12,082 >> Saving model checkpoint to M2M-100/baseline/en-sw/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-04-04 07:21:12,087 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:21:12,089 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:21:17,027 >> Model weights saved in M2M-100/baseline/en-sw/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:21:17,033 >> tokenizer config file saved in M2M-100/baseline/en-sw/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:21:17,035 >> Special tokens file saved in M2M-100/baseline/en-sw/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:21:17,037 >> added tokens file saved in M2M-100/baseline/en-sw/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 07:28:58,709 >> Saving model checkpoint to M2M-100/baseline/en-sw/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-04-04 07:28:58,715 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:28:58,717 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:29:03,580 >> Model weights saved in M2M-100/baseline/en-sw/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:29:03,585 >> tokenizer config file saved in M2M-100/baseline/en-sw/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:29:03,587 >> Special tokens file saved in M2M-100/baseline/en-sw/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:29:03,589 >> added tokens file saved in M2M-100/baseline/en-sw/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 07:36:47,663 >> Saving model checkpoint to M2M-100/baseline/en-sw/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-04-04 07:36:47,667 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:36:47,669 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:36:52,814 >> Model weights saved in M2M-100/baseline/en-sw/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:36:52,821 >> tokenizer config file saved in M2M-100/baseline/en-sw/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:36:52,823 >> Special tokens file saved in M2M-100/baseline/en-sw/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:36:52,825 >> added tokens file saved in M2M-100/baseline/en-sw/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 07:44:35,395 >> Saving model checkpoint to M2M-100/baseline/en-sw/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-04-04 07:44:35,399 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:44:35,401 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:44:40,483 >> Model weights saved in M2M-100/baseline/en-sw/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:44:40,488 >> tokenizer config file saved in M2M-100/baseline/en-sw/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:44:40,490 >> Special tokens file saved in M2M-100/baseline/en-sw/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:44:40,492 >> added tokens file saved in M2M-100/baseline/en-sw/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 07:49:21,728 >> Saving model checkpoint to M2M-100/baseline/en-sw/checkpoint-2298\n","[INFO|configuration_utils.py:423] 2025-04-04 07:49:21,732 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-2298/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:49:21,735 >> Configuration saved in M2M-100/baseline/en-sw/checkpoint-2298/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:49:26,972 >> Model weights saved in M2M-100/baseline/en-sw/checkpoint-2298/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:49:26,977 >> tokenizer config file saved in M2M-100/baseline/en-sw/checkpoint-2298/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:49:26,979 >> Special tokens file saved in M2M-100/baseline/en-sw/checkpoint-2298/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:49:26,982 >> added tokens file saved in M2M-100/baseline/en-sw/checkpoint-2298/added_tokens.json\n","[INFO|trainer.py:2659] 2025-04-04 07:49:40,577 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3944] 2025-04-04 07:49:40,590 >> Saving model checkpoint to M2M-100/baseline/en-sw\n","[INFO|configuration_utils.py:423] 2025-04-04 07:49:40,595 >> Configuration saved in M2M-100/baseline/en-sw/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 07:49:40,597 >> Configuration saved in M2M-100/baseline/en-sw/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 07:49:49,522 >> Model weights saved in M2M-100/baseline/en-sw/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 07:49:49,528 >> tokenizer config file saved in M2M-100/baseline/en-sw/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 07:49:49,530 >> Special tokens file saved in M2M-100/baseline/en-sw/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 07:49:49,532 >> added tokens file saved in M2M-100/baseline/en-sw/added_tokens.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4260] 2025-04-04 07:49:49,691 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-04-04 07:49:49,693 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-04-04 07:49:49,695 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  2451396GF\n","  train_loss               =     2.1046\n","  train_runtime            = 0:35:59.12\n","  train_samples            =       6121\n","  train_samples_per_second =      8.505\n","  train_steps_per_second   =      1.064\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Predict ***\n","[INFO|trainer.py:4260] 2025-04-04 08:04:37,036 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-04-04 08:04:37,036 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-04-04 08:04:37,037 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     5.6147\n","  eval_chrf               =    26.7379\n","  eval_gen_len            =    68.5296\n","  eval_loss               =     2.5678\n","  eval_runtime            = 0:14:47.32\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.124\n","  eval_steps_per_second   =      0.141\n","***** predict metrics *****\n","  predict_bleu               =     5.2412\n","  predict_chrf               =    26.0251\n","  predict_gen_len            =    70.5623\n","  predict_loss               =     2.6595\n","  predict_runtime            = 0:15:20.00\n","  predict_samples            =       1012\n","  predict_samples_per_second =        1.1\n","  predict_steps_per_second   =      0.138\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:449] 2025-04-04 08:20:14,200 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 5.6147}]}\n","[INFO|training_args.py:2206] 2025-04-04 08:20:14,255 >> PyTorch: setting up devices\n","[INFO|training_args.py:1877] 2025-04-04 08:20:14,288 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/en-ha/runs/Apr04_08-20-14_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/en-ha,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/en-ha,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-7ffedfb6e1362060\n","INFO:datasets.builder:Using custom data configuration default-7ffedfb6e1362060\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a6b8610210040fe93a96bedb082ff68"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd061ae80c174faea56692de3e376308"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a11ff0a9ba89464fb7ea81ee2fe2cbae"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-04-04 08:20:14,815 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 08:20:14,818 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 08:20:14,938 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 08:20:14,940 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,943 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,944 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,946 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,947 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,949 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,951 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 08:20:14,953 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 08:20:14,955 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 08:20:14,957 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 08:20:15,921 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-04-04 08:20:15,990 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-04-04 08:20:16,405 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-04-04 08:20:16,502 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-04-04 08:20:16,504 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 08:20:16,619 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 08:20:16,620 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-04-04 08:20:17,526 >> Safetensors PR exists\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/8665 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"396d5d2f80474832850d52cff455493f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-26143064b83f0537.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-26143064b83f0537.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/997 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3444cacdf0f14324ba44568001756eed"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6bbc8988a2155ad2.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6bbc8988a2155ad2.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1012 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d1b40e1a6a74b29a47c662eeade465f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-fae0d8df7dbd8b21.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7ffedfb6e1362060/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-fae0d8df7dbd8b21.arrow\n","[INFO|trainer.py:2407] 2025-04-04 08:20:36,784 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 08:20:36,785 >>   Num examples = 8,665\n","[INFO|trainer.py:2409] 2025-04-04 08:20:36,786 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 08:20:36,788 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 08:20:36,789 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 08:20:36,790 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 08:20:36,791 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 08:20:36,792 >>   Total optimization steps = 3,252\n","[INFO|trainer.py:2416] 2025-04-04 08:20:36,795 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 08:20:36,805 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3252' max='3252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3252/3252 50:27, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>3.654800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.847500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>2.317900</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>2.153300</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.890500</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.751800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3944] 2025-04-04 08:28:00,246 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-04-04 08:28:00,251 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 08:28:00,253 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 08:28:05,139 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 08:28:05,144 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 08:28:05,146 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 08:28:05,148 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 08:35:44,010 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-04-04 08:35:44,014 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 08:35:44,017 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 08:35:49,104 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 08:35:49,109 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 08:35:49,111 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 08:35:49,113 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 08:43:29,376 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-04-04 08:43:29,380 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 08:43:29,382 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 08:43:34,518 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 08:43:34,524 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 08:43:34,526 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 08:43:34,528 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 08:51:12,957 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-04-04 08:51:12,961 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 08:51:12,963 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 08:51:18,085 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 08:51:18,092 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 08:51:18,094 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 08:51:18,096 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 08:58:55,790 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-04-04 08:58:55,794 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 08:58:55,796 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 08:59:00,973 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 08:59:00,978 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 08:59:00,980 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 08:59:00,983 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 09:06:43,086 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-04-04 09:06:43,090 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:06:43,093 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:06:48,235 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:06:48,240 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:06:48,242 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:06:48,245 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 09:10:46,359 >> Saving model checkpoint to M2M-100/baseline/en-ha/checkpoint-3252\n","[INFO|configuration_utils.py:423] 2025-04-04 09:10:46,364 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-3252/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:10:46,366 >> Configuration saved in M2M-100/baseline/en-ha/checkpoint-3252/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:10:51,666 >> Model weights saved in M2M-100/baseline/en-ha/checkpoint-3252/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:10:51,672 >> tokenizer config file saved in M2M-100/baseline/en-ha/checkpoint-3252/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:10:51,674 >> Special tokens file saved in M2M-100/baseline/en-ha/checkpoint-3252/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:10:51,677 >> added tokens file saved in M2M-100/baseline/en-ha/checkpoint-3252/added_tokens.json\n","[INFO|trainer.py:2659] 2025-04-04 09:11:05,319 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3944] 2025-04-04 09:11:05,332 >> Saving model checkpoint to M2M-100/baseline/en-ha\n","[INFO|configuration_utils.py:423] 2025-04-04 09:11:05,337 >> Configuration saved in M2M-100/baseline/en-ha/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:11:05,340 >> Configuration saved in M2M-100/baseline/en-ha/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:11:14,219 >> Model weights saved in M2M-100/baseline/en-ha/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:11:14,226 >> tokenizer config file saved in M2M-100/baseline/en-ha/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:11:14,228 >> Special tokens file saved in M2M-100/baseline/en-ha/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:11:14,231 >> added tokens file saved in M2M-100/baseline/en-ha/added_tokens.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4260] 2025-04-04 09:11:14,387 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-04-04 09:11:14,388 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-04-04 09:11:14,390 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3782573GF\n","  train_loss               =     2.3831\n","  train_runtime            = 0:50:28.52\n","  train_samples            =       8665\n","  train_samples_per_second =      8.583\n","  train_steps_per_second   =      1.074\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Predict ***\n","[INFO|trainer.py:4260] 2025-04-04 09:22:24,583 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-04-04 09:22:24,584 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-04-04 09:22:24,585 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     8.5945\n","  eval_chrf               =    35.7502\n","  eval_gen_len            =    50.2889\n","  eval_loss               =     2.8971\n","  eval_runtime            = 0:11:10.18\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.488\n","  eval_steps_per_second   =      0.187\n","***** predict metrics *****\n","  predict_bleu               =      8.722\n","  predict_chrf               =    35.4816\n","  predict_gen_len            =       51.5\n","  predict_loss               =     2.9301\n","  predict_runtime            = 0:11:53.11\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.419\n","  predict_steps_per_second   =      0.178\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:449] 2025-04-04 09:34:33,591 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 8.5945}]}\n","[INFO|training_args.py:2206] 2025-04-04 09:34:33,647 >> PyTorch: setting up devices\n","[INFO|training_args.py:1877] 2025-04-04 09:34:33,679 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/en-ig/runs/Apr04_09-34-33_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/en-ig,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/en-ig,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-05b9308cf4fe5e2d\n","INFO:datasets.builder:Using custom data configuration default-05b9308cf4fe5e2d\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52252d6da4824a989fbdc66354f61161"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f264dbdc11684370bd9a2e40bb282a7e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6752651b5a3b470b84414f4958411ce9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-04-04 09:34:34,201 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:34:34,204 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 09:34:34,341 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:34:34,344 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,347 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,348 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,350 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,352 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,354 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,356 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:34:34,357 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 09:34:34,360 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:34:34,362 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 09:34:35,285 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-04-04 09:34:35,360 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-04-04 09:34:35,474 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-04-04 09:34:35,476 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 09:34:35,615 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 09:34:35,617 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-04-04 09:34:36,004 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-04-04 09:34:36,745 >> Safetensors PR exists\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/9998 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248f360bd35849398a577470ab4846c8"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dbd38746d406bdac.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dbd38746d406bdac.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/997 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799da935d81c45a399335a62bc10e94c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-28f17e6955670165.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-28f17e6955670165.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1012 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d792ee661a524ec3b1155155721b3da7"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7d7e0b139d778021.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7d7e0b139d778021.arrow\n","[INFO|trainer.py:2407] 2025-04-04 09:34:55,211 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 09:34:55,213 >>   Num examples = 9,998\n","[INFO|trainer.py:2409] 2025-04-04 09:34:55,215 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 09:34:55,217 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 09:34:55,218 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 09:34:55,220 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 09:34:55,221 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 09:34:55,223 >>   Total optimization steps = 3,750\n","[INFO|trainer.py:2416] 2025-04-04 09:34:55,225 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 09:34:55,233 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 8464 has 14.74 GiB memory in use. Of the allocated memory 14.08 GiB is allocated by PyTorch, and 205.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-772030cd1bc7>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     ]\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mrunpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/AIMS-NLP-Project/run_translation.py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.10/runpy.py\u001b[0m in \u001b[0;36mrun_path\u001b[0;34m(path_name, init_globals, run_name)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# execfile() doesn't help as we want to allow compiled files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_code_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         return _run_module_code(code, init_globals, run_name,\n\u001b[0m\u001b[1;32m    290\u001b[0m                                 pkg_name=pkg_name, script_name=fname)\n\u001b[1;32m    291\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/runpy.py\u001b[0m in \u001b[0;36m_run_module_code\u001b[0;34m(code, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_TempModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ModifiedArgv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mmod_globals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         _run_code(code, mod_globals, init_globals,\n\u001b[0m\u001b[1;32m     97\u001b[0m                   mod_name, mod_spec, pkg_name, script_name)\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Copy the globals of the temporary module, as they\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/runpy.py\u001b[0m in \u001b[0;36m_run_code\u001b[0;34m(code, run_globals, init_globals, mod_name, mod_spec, pkg_name, script_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m                        \u001b[0m__package__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkg_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                        __spec__ = mod_spec)\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_globals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/AIMS-NLP-Project/run_translation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/AIMS-NLP-Project/run_translation.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2241\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2243\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2244\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2245\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2599\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_pre_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2601\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_by_lr_sched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    218\u001b[0m             )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             adamw(\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_multi_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_max_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0mexp_avg_sq_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_sqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq_sqrt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 8464 has 14.74 GiB memory in use. Of the allocated memory 14.08 GiB is allocated by PyTorch, and 205.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"fr-sw\", \"en-sw\", \"en-ha\", \"en-ig\", \"en-yo\"]  # Add more as needed\n","\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    # Initialize WandB\n","    wandb.init(project=\"machine translation\", name=f\"baseline_{lang_pair}\")\n","\n","    sys.argv = [\n","        \"run_translation.py\",\n","        \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","        \"--do_train\", \"--do_eval\", \"--do_predict\",\n","        \"--source_lang\", src,\n","        \"--target_lang\", tgt,\n","        \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","        \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","        \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","        \"--num_beams\", \"10\",\n","        \"--output_dir\", f\"M2M-100/baseline/{lang_pair}\",\n","        \"--per_device_train_batch_size=4\",\n","        \"--per_device_eval_batch_size=4\",\n","        \"--overwrite_output_dir\",\n","        \"--predict_with_generate\"\n","    ]\n","\n","    runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"en-ig\", \"en-yo\"]  # Add more as needed\n","\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    # Initialize WandB\n","    wandb.init(project=\"machine translation\", name=f\"baseline_{lang_pair}\")\n","\n","    sys.argv = [\n","        \"run_translation.py\",\n","        \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","        \"--do_train\", \"--do_eval\", \"--do_predict\",\n","        \"--source_lang\", src,\n","        \"--target_lang\", tgt,\n","        \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","        \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","        \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","        \"--num_beams\", \"10\",\n","        \"--output_dir\", f\"M2M-100/baseline/{lang_pair}\",\n","        \"--per_device_train_batch_size=4\",\n","        \"--per_device_eval_batch_size=4\",\n","        \"--overwrite_output_dir\",\n","        \"--predict_with_generate\"\n","    ]\n","\n","    runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d68fec237bb94e84836918bd11245422","5583b01abd8743769d5fee932e9cf3c6","ad32ac6516684b61898e5313e52618af","201697c34e4f44239bed6ce86d358085","3edd9f47074e4b5e9f813b4c91d40537","c3e54a10869f4fbe938c8521cc2d4f26","a7355af0ea2e44a0a3ecddd8c03e6152","e5087ec0b0a345e4938b2aa1d3c2bc63","80420145b0b940d2ba043bbe151ba467","f84ca03e7f77461880026207611e7687","9e790c2125634710afcfd2c464daf17b","7aefb6db6c134089b01f39894e1019ff","95ecef486878458d801765c581924791","9164538d1dd54fbe8c0c4728f7738103","07ccc2ee8c114c199ceadc4b14ddbb08","3e595d72275b4c16a6c02e9b76a5e6c7","62bf148dd1b54b19ba0f4a1b27c2f433","a59636048ac74ef39f0926cedf97bfc8","394f47b77a6f4813a969ae6dcc40c96d","4f4cd0bb217b4664856788439f316e13","ebd83a0ac3494d229c68e89d3b7b5ed9","b4de2085fe8e400ebab370e5629012d4","b8a9ae8f374841dd87c308b437d95077","7c91483c1a49478baa9dfe885d82cf0c","656e0184748e412199f5b0b2162441da","f5f82472948842d08ea0007ba0b6279f","4d94b212d8fd4bc18beffd47c5ab275d","200697e47b3248a3b55fb23aa44a2745","f37b7d6fcee94aa198ecf9fa581f61fc","baae1b4441c64130b5d494554c1a0369","9619d16d80e64b948668e3d979c46fcc","71bb74baf43f447c9fe6e5593531613b","022e191469004ad2adfa7f1c325c8769","b5539c2c3cc5429fa6a3da10631c7f4c","49507ce27ecc414ea48dda9728d379f7","476a303e8121485a9dd5d1f32ad688cf","c5e14a7d4628403b87dd25bf45c87e5e","b22020e48e394fe4a18652fda8bc23e2","a4fa21d5199f428fb7d0ef75f3c4524b","ce01bf43fa9d4aca82d8aec3a14113a4","e24557ca6e5d432caac03b37ce95780d","cc249200899c49e0b78519b5ddab1215","5237dc272968482697f2b87eb072b629","d2de7cdb7aae45b68c529202554e3af9","c6b9a927f0f34279943874855d5fb5fd","8c658c27f62848a4b86ad7526cd8b122","0f064a02f859466489a7ee2a11f569cb","88e449708243440ebd57608ad0553b59","b5bc1a96413843b2adbc340febdb91f7","bd65aa1df84143c89693a1da33bb42ba","93d0ae0bdd0a440583fd6e7eda033207","684abaf47da64300bda3d1a85d760241","3086588e850a46c08a717fe6a5ed7873","b019e87daa164b32a318251da0385829","7f03728d3b2a4d868ab4be884da05fba","ad695ce74d2a4d0495e319839dc24831","6a2bf4d2223e48c58d415bb10e351393","de2b04c4e86b40629fbf8da0f6572ed8","3691bc4082d54753bec81be256d75c6f","c1313549fce04ab7a8c949cf574b96a8","9d055765b7984994897d23ffe1c7b36c","ed635958bee64a7dbc32e6f33dfeb56b","b4c913b08aad462c97dca91856e9e4c4","d63a0c0766b7413cb7a693ef12d5dbae","04a482f0ebde4d9fa9fcefcdf9c46f1b","67827431c6134a4ea986ac83c3e1e34e"]},"id":"Wq-lF3t5KDbs","executionInfo":{"status":"ok","timestamp":1743769174436,"user_tz":-120,"elapsed":9782028,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"1932e968-af9e-4359-a2e0-13febcef0d5c"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250404_093632-hzouwxhs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/hzouwxhs' target=\"_blank\">baseline_en-ig</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/hzouwxhs' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/hzouwxhs</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/en-ig/runs/Apr04_09-36-47_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/en-ig,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/en-ig,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-05b9308cf4fe5e2d\n","INFO:datasets.builder:Using custom data configuration default-05b9308cf4fe5e2d\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","INFO:datasets.builder:Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","INFO:datasets.info:Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n","Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n","You are not authenticated with the Hugging Face Hub in this notebook.\n","If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n","  warnings.warn(\n","[INFO|configuration_utils.py:699] 2025-04-04 09:36:58,129 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:36:58,135 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 09:36:58,256 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:36:58,258 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,261 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,262 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,264 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,266 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,268 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,269 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 09:36:58,271 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 09:36:58,273 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 09:36:58,275 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 09:36:59,252 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-04-04 09:36:59,332 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-04-04 09:36:59,393 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-04-04 09:36:59,453 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-04-04 09:36:59,458 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 09:36:59,571 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 09:36:59,573 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-04-04 09:36:59,852 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dbd38746d406bdac.arrow\n","INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dbd38746d406bdac.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-28f17e6955670165.arrow\n","INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-28f17e6955670165.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7d7e0b139d778021.arrow\n","INFO:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-05b9308cf4fe5e2d/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7d7e0b139d778021.arrow\n","[INFO|trainer.py:2407] 2025-04-04 09:37:06,491 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 09:37:06,493 >>   Num examples = 9,998\n","[INFO|trainer.py:2409] 2025-04-04 09:37:06,496 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 09:37:06,497 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 09:37:06,499 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 09:37:06,501 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 09:37:06,503 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 09:37:06,505 >>   Total optimization steps = 3,750\n","[INFO|trainer.py:2416] 2025-04-04 09:37:06,510 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 09:37:06,518 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3750/3750 53:44, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.894200</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.288800</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.884000</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.649000</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.584800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.263200</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.242000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3944] 2025-04-04 09:43:56,914 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-04-04 09:43:56,926 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:43:56,928 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:44:01,860 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:44:01,866 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:44:01,868 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:44:01,870 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 09:51:05,188 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-04-04 09:51:05,192 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:51:05,195 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:51:10,292 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:51:10,299 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:51:10,303 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:51:10,306 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 09:58:15,122 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-04-04 09:58:15,126 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 09:58:15,128 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 09:58:20,093 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 09:58:20,100 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 09:58:20,102 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 09:58:20,104 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 10:05:25,140 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-04-04 10:05:25,144 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:05:25,146 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:05:30,146 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:05:30,152 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:05:30,155 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:05:30,158 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 10:12:33,463 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-04-04 10:12:33,467 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:12:33,469 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:12:38,586 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:12:38,592 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:12:38,594 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:12:38,597 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 10:19:44,458 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-04-04 10:19:44,461 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:19:44,464 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:19:49,284 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:19:49,291 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:19:49,294 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:19:49,297 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 10:26:50,375 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-04-04 10:26:50,379 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:26:50,382 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:26:55,519 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:26:55,525 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:26:55,528 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:26:55,531 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 10:30:34,691 >> Saving model checkpoint to M2M-100/baseline/en-ig/checkpoint-3750\n","[INFO|configuration_utils.py:423] 2025-04-04 10:30:34,695 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3750/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:30:34,697 >> Configuration saved in M2M-100/baseline/en-ig/checkpoint-3750/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:30:39,968 >> Model weights saved in M2M-100/baseline/en-ig/checkpoint-3750/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:30:39,974 >> tokenizer config file saved in M2M-100/baseline/en-ig/checkpoint-3750/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:30:39,977 >> Special tokens file saved in M2M-100/baseline/en-ig/checkpoint-3750/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:30:39,980 >> added tokens file saved in M2M-100/baseline/en-ig/checkpoint-3750/added_tokens.json\n","[INFO|trainer.py:2659] 2025-04-04 10:30:53,606 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3944] 2025-04-04 10:30:53,616 >> Saving model checkpoint to M2M-100/baseline/en-ig\n","[INFO|configuration_utils.py:423] 2025-04-04 10:30:53,619 >> Configuration saved in M2M-100/baseline/en-ig/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:30:53,621 >> Configuration saved in M2M-100/baseline/en-ig/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:31:02,479 >> Model weights saved in M2M-100/baseline/en-ig/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:31:02,486 >> tokenizer config file saved in M2M-100/baseline/en-ig/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:31:02,488 >> Special tokens file saved in M2M-100/baseline/en-ig/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:31:02,489 >> added tokens file saved in M2M-100/baseline/en-ig/added_tokens.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4260] 2025-04-04 10:31:02,644 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-04-04 10:31:02,645 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-04-04 10:31:02,647 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3268988GF\n","  train_loss               =     1.7888\n","  train_runtime            = 0:53:47.09\n","  train_samples            =       9998\n","  train_samples_per_second =      9.294\n","  train_steps_per_second   =      1.162\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Predict ***\n","[INFO|trainer.py:4260] 2025-04-04 10:40:22,802 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-04-04 10:40:22,802 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-04-04 10:40:22,804 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =    10.9085\n","  eval_chrf               =    36.6315\n","  eval_gen_len            =    46.5416\n","  eval_loss               =      2.693\n","  eval_runtime            = 0:09:20.14\n","  eval_samples            =        997\n","  eval_samples_per_second =       1.78\n","  eval_steps_per_second   =      0.223\n","***** predict metrics *****\n","  predict_bleu               =    11.1604\n","  predict_chrf               =    36.6716\n","  predict_gen_len            =    48.6779\n","  predict_loss               =     2.6771\n","  predict_runtime            = 0:09:59.42\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.688\n","  predict_steps_per_second   =      0.212\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:449] 2025-04-04 10:50:37,897 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 10.9085}]}\n","[INFO|training_args.py:2206] 2025-04-04 10:50:37,933 >> PyTorch: setting up devices\n","[INFO|training_args.py:1877] 2025-04-04 10:50:37,963 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","WARNING:__main__:Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/en-yo/runs/Apr04_10-50-37_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline/en-yo,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline/en-yo,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-eb95fe19beb6c01e\n","INFO:datasets.builder:Using custom data configuration default-eb95fe19beb6c01e\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","INFO:datasets.builder:Generating dataset json (/root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","INFO:datasets.builder:Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Generating train split\n","INFO:datasets.builder:Generating train split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d68fec237bb94e84836918bd11245422"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating validation split\n","INFO:datasets.builder:Generating validation split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7aefb6db6c134089b01f39894e1019ff"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Generating test split\n","INFO:datasets.builder:Generating test split\n"]},{"output_type":"display_data","data":{"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8a9ae8f374841dd87c308b437d95077"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Unable to verify splits sizes.\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","INFO:datasets.builder:Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-04-04 10:50:38,507 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 10:50:38,509 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-04-04 10:50:38,719 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 10:50:38,722 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,725 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,726 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,727 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,729 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,730 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,732 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-04-04 10:50:38,734 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-04-04 10:50:38,736 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-04-04 10:50:38,738 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-04-04 10:50:39,639 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-04-04 10:50:39,704 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-04-04 10:50:39,806 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|safetensors_conversion.py:61] 2025-04-04 10:50:39,807 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4980] 2025-04-04 10:50:39,808 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-04-04 10:50:39,969 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-04-04 10:50:39,971 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-04-04 10:50:40,261 >> Safetensors PR exists\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on train dataset:   0%|          | 0/9746 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5539c2c3cc5429fa6a3da10631c7f4c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3f038dcc71edbb09.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3f038dcc71edbb09.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on validation dataset:   0%|          | 0/997 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6b9a927f0f34279943874855d5fb5fd"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1a7321e63c9f63a9.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1a7321e63c9f63a9.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Running tokenizer on prediction dataset:   0%|          | 0/1012 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad695ce74d2a4d0495e319839dc24831"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8c333511a9ca8f6d.arrow\n","INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/json/default-eb95fe19beb6c01e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8c333511a9ca8f6d.arrow\n","[INFO|trainer.py:2407] 2025-04-04 10:50:53,913 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-04-04 10:50:53,914 >>   Num examples = 9,746\n","[INFO|trainer.py:2409] 2025-04-04 10:50:53,915 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-04-04 10:50:53,917 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-04-04 10:50:53,919 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-04-04 10:50:53,920 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-04-04 10:50:53,922 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-04-04 10:50:53,923 >>   Total optimization steps = 3,657\n","[INFO|trainer.py:2416] 2025-04-04 10:50:53,926 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-04-04 10:50:53,933 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3657' max='3657' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3657/3657 58:10, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.982300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>2.199600</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>1.846200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>1.639600</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>1.518800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>1.339600</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>1.290200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["[INFO|trainer.py:3944] 2025-04-04 10:58:31,341 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-04-04 10:58:31,347 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 10:58:31,349 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 10:58:35,785 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 10:58:35,791 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 10:58:35,793 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 10:58:35,795 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:06:26,527 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-04-04 11:06:26,531 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:06:26,533 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:06:30,895 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:06:30,902 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:06:30,906 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:06:30,909 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:14:22,195 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-04-04 11:14:22,199 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:14:22,201 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:14:26,609 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:14:26,617 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:14:26,619 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:14:26,621 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:22:17,939 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-04-04 11:22:17,943 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:22:17,945 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:22:22,322 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:22:22,334 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:22:22,337 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:22:22,340 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:30:13,974 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-04-04 11:30:13,978 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:30:13,980 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:30:18,416 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:30:18,422 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:30:18,424 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:30:18,427 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:38:09,240 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-04-04 11:38:09,244 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:38:09,247 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:38:13,337 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:38:13,347 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:38:13,350 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:38:13,353 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:46:05,761 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-04-04 11:46:05,765 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:46:05,767 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:46:10,334 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:46:10,340 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:46:10,344 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:46:10,346 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","[INFO|trainer.py:3944] 2025-04-04 11:48:46,674 >> Saving model checkpoint to M2M-100/baseline/en-yo/checkpoint-3657\n","[INFO|configuration_utils.py:423] 2025-04-04 11:48:46,679 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3657/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:48:46,681 >> Configuration saved in M2M-100/baseline/en-yo/checkpoint-3657/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:48:51,242 >> Model weights saved in M2M-100/baseline/en-yo/checkpoint-3657/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:48:51,250 >> tokenizer config file saved in M2M-100/baseline/en-yo/checkpoint-3657/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:48:51,252 >> Special tokens file saved in M2M-100/baseline/en-yo/checkpoint-3657/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:48:51,254 >> added tokens file saved in M2M-100/baseline/en-yo/checkpoint-3657/added_tokens.json\n","[INFO|trainer.py:2659] 2025-04-04 11:49:05,274 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","[INFO|trainer.py:3944] 2025-04-04 11:49:05,281 >> Saving model checkpoint to M2M-100/baseline/en-yo\n","[INFO|configuration_utils.py:423] 2025-04-04 11:49:05,285 >> Configuration saved in M2M-100/baseline/en-yo/config.json\n","[INFO|configuration_utils.py:909] 2025-04-04 11:49:05,287 >> Configuration saved in M2M-100/baseline/en-yo/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-04-04 11:49:13,851 >> Model weights saved in M2M-100/baseline/en-yo/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-04-04 11:49:13,860 >> tokenizer config file saved in M2M-100/baseline/en-yo/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-04-04 11:49:13,862 >> Special tokens file saved in M2M-100/baseline/en-yo/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-04-04 11:49:13,864 >> added tokens file saved in M2M-100/baseline/en-yo/added_tokens.json\n","INFO:__main__:*** Evaluate ***\n","[INFO|trainer.py:4260] 2025-04-04 11:49:14,019 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-04-04 11:49:14,020 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-04-04 11:49:14,022 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3555661GF\n","  train_loss               =     1.8065\n","  train_runtime            = 0:58:11.34\n","  train_samples            =       9746\n","  train_samples_per_second =      8.374\n","  train_steps_per_second   =      1.047\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["INFO:__main__:*** Predict ***\n","[INFO|trainer.py:4260] 2025-04-04 12:03:54,734 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-04-04 12:03:54,735 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-04-04 12:03:54,736 >>   Batch size = 8\n"]},{"output_type":"stream","name":"stdout","text":["***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     5.7155\n","  eval_chrf               =    26.1312\n","  eval_gen_len            =    72.0802\n","  eval_loss               =     3.3789\n","  eval_runtime            = 0:14:40.70\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.132\n","  eval_steps_per_second   =      0.142\n","***** predict metrics *****\n","  predict_bleu               =      5.801\n","  predict_chrf               =    25.8441\n","  predict_gen_len            =    73.7885\n","  predict_loss               =     3.3359\n","  predict_runtime            = 0:15:22.17\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.097\n","  predict_steps_per_second   =      0.138\n"]},{"output_type":"stream","name":"stderr","text":["[INFO|modelcard.py:449] 2025-04-04 12:19:34,269 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 5.7155}]}\n"]}]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"en-sw\"]  # Add more as needed\n","text_nums = [1000 * 2 ** i for i in range(6)]\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    for num in text_nums:\n","        # Initialize WandB\n","        wandb.init(project=\"machine translation\", name=f\"africomet_{tgt}_{num}\")\n","\n","        sys.argv = [\n","            \"run_translation.py\",\n","            \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","            \"--do_train\", \"--do_eval\", \"--do_predict\",\n","            \"--source_lang\", src,\n","            \"--target_lang\", tgt,\n","            \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","            \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","            \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","            \"--num_beams\", \"10\",\n","            \"--output_dir\", f\"M2M-100/{lang_pair}/africomet_{num}\",\n","            \"--per_device_train_batch_size=4\",\n","            \"--per_device_eval_batch_size=4\",\n","            \"--overwrite_output_dir\",\n","            \"--predict_with_generate\"\n","        ]\n","\n","        runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"id":"LtdDrpwllWjA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"fr-sw\"]  # Add more as needed\n","text_nums = [1000 * 2 ** i for i in range(6)]\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    for num in text_nums:\n","        # Initialize WandB\n","        wandb.init(project=\"machine translation\", name=f\"africomet_{tgt}_{num}\")\n","\n","        sys.argv = [\n","            \"run_translation.py\",\n","            \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","            \"--do_train\", \"--do_eval\", \"--do_predict\",\n","            \"--source_lang\", src,\n","            \"--target_lang\", tgt,\n","            \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","            \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","            \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","            \"--num_beams\", \"10\",\n","            \"--output_dir\", f\"M2M-100/{lang_pair}/africomet_{num}\",\n","            \"--per_device_train_batch_size=4\",\n","            \"--per_device_eval_batch_size=4\",\n","            \"--overwrite_output_dir\",\n","            \"--predict_with_generate\"\n","        ]\n","\n","        runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"id":"Wj9pOEquhQzQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"en-ig\"]  # Add more as needed\n","text_nums = [1000 * 2 ** i for i in range(6)]\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    for num in text_nums:\n","        # Initialize WandB\n","        wandb.init(project=\"machine translation\", name=f\"africomet_{tgt}_{num}\")\n","\n","        sys.argv = [\n","            \"run_translation.py\",\n","            \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","            \"--do_train\", \"--do_eval\", \"--do_predict\",\n","            \"--source_lang\", src,\n","            \"--target_lang\", tgt,\n","            \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","            \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","            \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","            \"--num_beams\", \"10\",\n","            \"--output_dir\", f\"M2M-100/{lang_pair}/africomet_{num}\",\n","            \"--per_device_train_batch_size=4\",\n","            \"--per_device_eval_batch_size=4\",\n","            \"--overwrite_output_dir\",\n","            \"--predict_with_generate\"\n","        ]\n","\n","        runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"id":"ZAtbcC8MhUKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"en-ha\"]  # Add more as needed\n","text_nums = [1000 * 2 ** i for i in range(6)]\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    for num in text_nums:\n","        # Initialize WandB\n","        wandb.init(project=\"machine translation\", name=f\"africomet_{tgt}_{num}\")\n","\n","        sys.argv = [\n","            \"run_translation.py\",\n","            \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","            \"--do_train\", \"--do_eval\", \"--do_predict\",\n","            \"--source_lang\", src,\n","            \"--target_lang\", tgt,\n","            \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","            \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","            \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","            \"--num_beams\", \"10\",\n","            \"--output_dir\", f\"M2M-100/{lang_pair}/africomet_{num}\",\n","            \"--per_device_train_batch_size=4\",\n","            \"--per_device_eval_batch_size=4\",\n","            \"--overwrite_output_dir\",\n","            \"--predict_with_generate\"\n","        ]\n","\n","        runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"id":"j9m7mblChW-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys\n","import os\n","import runpy\n","\n","language_pairs = [\"en-yo\"]  # Add more as needed\n","text_nums = [1000 * 2 ** i for i in range(6)]\n","env = os.environ.copy()\n","env[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n","\n","for lang_pair in language_pairs:\n","    src, tgt = lang_pair.split(\"-\")\n","\n","    for num in text_nums:\n","        # Initialize WandB\n","        wandb.init(project=\"machine translation\", name=f\"africomet_{tgt}_{num}\")\n","\n","        sys.argv = [\n","            \"run_translation.py\",\n","            \"--model_name_or_path\", \"facebook/m2m100_418M\",\n","            \"--do_train\", \"--do_eval\", \"--do_predict\",\n","            \"--source_lang\", src,\n","            \"--target_lang\", tgt,\n","            \"--train_file\", f\"/content/AIMS-NLP-Project/data/mafand/{lang_pair}/merged.json\",\n","            \"--validation_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/dev.json\",\n","            \"--test_file\", f\"/content/AIMS-NLP-Project/data/flores/{lang_pair}/devtest.json\",\n","            \"--num_beams\", \"10\",\n","            \"--output_dir\", f\"M2M-100/{lang_pair}/africomet_{num}\",\n","            \"--per_device_train_batch_size=4\",\n","            \"--per_device_eval_batch_size=4\",\n","            \"--overwrite_output_dir\",\n","            \"--predict_with_generate\"\n","        ]\n","\n","        runpy.run_path(\"/content/AIMS-NLP-Project/run_translation.py\", run_name=\"__main__\")"],"metadata":{"id":"nrtfYMP8hZwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"59U0AtgohcsR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mUfwafIhhcoZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gGPBqgYNhclh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dGhnKPO9hciW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UUOk2jEXhce-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"elapsed":12867,"status":"ok","timestamp":1742633941883,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"aggyfHIUR2zp","outputId":"bf1462d2-74be-4094-d305-ebc5aa0d39a2"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250322_085854-0njzblna</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna' target=\"_blank\">baseline</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Log in with your API key\n","wandb.login(key=\"7f13d9fe09d0856f7c12099a27ccda7aa15c8afd\")\n","\n","# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"baseline_{language}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1874933,"status":"ok","timestamp":1742637345127,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"VvM-Zf4jUO81","outputId":"342ba6d4-0c7f-4ffa-f7a4-5ac29cda097e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 09:00:54.631515: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 09:00:54.653331: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 09:00:54.660040: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 09:00:54.676194: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 09:00:55.669976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 09:00:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 09:00:58 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/baseline/runs/Mar22_09-00-57_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/baseline,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/baseline,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-fcf11d994dda434e\n","03/22/2025 09:00:58 - INFO - datasets.builder - Using custom data configuration default-fcf11d994dda434e\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 09:00:58 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 09:00:58 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 09:00:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 09:00:58 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 09:00:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 09:00:58,508 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:00:58,510 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 09:00:58,595 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:00:58,596 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,596 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,596 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,597 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,597 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,597 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,597 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:00:58,597 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 09:00:58,597 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:00:58,598 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 09:00:59,550 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|safetensors_conversion.py:61] 2025-03-22 09:00:59,735 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-22 09:01:00,105 >> Safetensors PR exists\n","[INFO|configuration_utils.py:1140] 2025-03-22 09:01:00,192 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-22 09:01:00,363 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 09:01:00,363 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 09:01:00,453 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 09:01:00,454 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-500813e1b41c1f29.arrow\n","03/22/2025 09:01:01 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-500813e1b41c1f29.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-24d83da570939502.arrow\n","03/22/2025 09:01:03 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-24d83da570939502.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c4510aa2c36da9e3.arrow\n","03/22/2025 09:01:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-fcf11d994dda434e/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c4510aa2c36da9e3.arrow\n","Downloading builder script: 100% 9.01k/9.01k [00:00<00:00, 15.4MB/s]\n","[INFO|trainer.py:2407] 2025-03-22 09:01:14,521 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 09:01:14,521 >>   Num examples = 5,737\n","[INFO|trainer.py:2409] 2025-03-22 09:01:14,521 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 09:01:14,521 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 09:01:14,521 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 09:01:14,521 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 09:01:14,521 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 09:01:14,521 >>   Total optimization steps = 2,154\n","[INFO|trainer.py:2416] 2025-03-22 09:01:14,522 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 09:01:14,529 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_090114-yu3f7j7b\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/baseline\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/yu3f7j7b\u001b[0m\n","  0% 0/2154 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.6395, 'grad_norm': 6.515448093414307, 'learning_rate': 3.8393686165273915e-05, 'epoch': 0.7}\n"," 23% 500/2154 [07:26<23:44,  1.16it/s][INFO|trainer.py:3944] 2025-03-22 09:08:41,635 >> Saving model checkpoint to M2M-100/baseline/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 09:08:41,644 >> Configuration saved in M2M-100/baseline/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:08:41,645 >> Configuration saved in M2M-100/baseline/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:08:53,122 >> Model weights saved in M2M-100/baseline/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:08:53,126 >> tokenizer config file saved in M2M-100/baseline/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:08:53,127 >> Special tokens file saved in M2M-100/baseline/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:08:53,127 >> added tokens file saved in M2M-100/baseline/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7846, 'grad_norm': 6.764095783233643, 'learning_rate': 2.678737233054782e-05, 'epoch': 1.39}\n"," 46% 1000/2154 [15:24<15:48,  1.22it/s][INFO|trainer.py:3944] 2025-03-22 09:16:39,965 >> Saving model checkpoint to M2M-100/baseline/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 09:16:39,970 >> Configuration saved in M2M-100/baseline/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:16:39,971 >> Configuration saved in M2M-100/baseline/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:16:51,462 >> Model weights saved in M2M-100/baseline/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:16:51,465 >> tokenizer config file saved in M2M-100/baseline/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:16:51,466 >> Special tokens file saved in M2M-100/baseline/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:16:51,466 >> added tokens file saved in M2M-100/baseline/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3359, 'grad_norm': 6.238084316253662, 'learning_rate': 1.518105849582173e-05, 'epoch': 2.09}\n"," 70% 1500/2154 [23:24<09:20,  1.17it/s][INFO|trainer.py:3944] 2025-03-22 09:24:39,800 >> Saving model checkpoint to M2M-100/baseline/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-22 09:24:39,809 >> Configuration saved in M2M-100/baseline/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:24:39,810 >> Configuration saved in M2M-100/baseline/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:24:51,286 >> Model weights saved in M2M-100/baseline/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:24:51,288 >> tokenizer config file saved in M2M-100/baseline/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:24:51,289 >> Special tokens file saved in M2M-100/baseline/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:24:51,289 >> added tokens file saved in M2M-100/baseline/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9657, 'grad_norm': 6.731072425842285, 'learning_rate': 3.574744661095636e-06, 'epoch': 2.79}\n"," 93% 2000/2154 [31:22<02:20,  1.10it/s][INFO|trainer.py:3944] 2025-03-22 09:32:38,220 >> Saving model checkpoint to M2M-100/baseline/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 09:32:38,225 >> Configuration saved in M2M-100/baseline/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:32:38,226 >> Configuration saved in M2M-100/baseline/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:32:49,793 >> Model weights saved in M2M-100/baseline/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:32:49,797 >> tokenizer config file saved in M2M-100/baseline/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:32:49,798 >> Special tokens file saved in M2M-100/baseline/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:32:49,798 >> added tokens file saved in M2M-100/baseline/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 2154/2154 [34:09<00:00,  1.51it/s][INFO|trainer.py:3944] 2025-03-22 09:35:24,559 >> Saving model checkpoint to M2M-100/baseline/checkpoint-2154\n","[INFO|configuration_utils.py:423] 2025-03-22 09:35:24,562 >> Configuration saved in M2M-100/baseline/checkpoint-2154/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:35:24,563 >> Configuration saved in M2M-100/baseline/checkpoint-2154/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:35:36,155 >> Model weights saved in M2M-100/baseline/checkpoint-2154/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:35:36,158 >> tokenizer config file saved in M2M-100/baseline/checkpoint-2154/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:35:36,159 >> Special tokens file saved in M2M-100/baseline/checkpoint-2154/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:35:36,159 >> added tokens file saved in M2M-100/baseline/checkpoint-2154/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 09:35:54,195 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2079.6733, 'train_samples_per_second': 8.276, 'train_steps_per_second': 1.036, 'train_loss': 2.626155800141996, 'epoch': 3.0}\n","100% 2154/2154 [34:38<00:00,  1.04it/s]\n","[INFO|trainer.py:3944] 2025-03-22 09:35:54,204 >> Saving model checkpoint to M2M-100/baseline\n","[INFO|configuration_utils.py:423] 2025-03-22 09:35:54,205 >> Configuration saved in M2M-100/baseline/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 09:35:54,206 >> Configuration saved in M2M-100/baseline/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 09:36:05,773 >> Model weights saved in M2M-100/baseline/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 09:36:05,776 >> tokenizer config file saved in M2M-100/baseline/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 09:36:05,776 >> Special tokens file saved in M2M-100/baseline/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 09:36:05,777 >> added tokens file saved in M2M-100/baseline/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  2504202GF\n","  train_loss               =     2.6262\n","  train_runtime            = 0:34:39.67\n","  train_samples            =       5737\n","  train_samples_per_second =      8.276\n","  train_steps_per_second   =      1.036\n","03/22/2025 09:36:05 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 09:36:05,916 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 09:36:05,916 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 09:36:05,916 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:10<00:00,  4.40s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =      7.053\n","  eval_chrf               =    41.9664\n","  eval_gen_len            =    46.8676\n","  eval_loss               =     2.5353\n","  eval_runtime            = 0:09:16.35\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.792\n","  eval_steps_per_second   =      0.225\n","03/22/2025 09:45:22 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 09:45:22,277 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 09:45:22,277 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 09:45:22,278 >>   Batch size = 8\n","100% 127/127 [09:48<00:00,  4.63s/it]\n","***** predict metrics *****\n","  predict_bleu               =     7.2825\n","  predict_chrf               =    41.7196\n","  predict_gen_len            =    48.5593\n","  predict_loss               =     2.5738\n","  predict_runtime            = 0:09:55.51\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.699\n","  predict_steps_per_second   =      0.213\n","[INFO|modelcard.py:449] 2025-03-22 09:55:33,296 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 7.053}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/mafand/en-zu/merged.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/baseline \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"markdown","metadata":{"id":"1OEaIczVafcf"},"source":["# Africomet with top 1000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"elapsed":648,"status":"ok","timestamp":1742637406571,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"Mp6AahGfufdK","outputId":"c1457e4e-1886-4351-af51-e7abef95c143"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-1000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1353332,"status":"ok","timestamp":1742639311479,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"hbNrB5boVIgU","outputId":"1fe98c73-6580-46b2-ee67-fef61d3771e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 09:56:56.806833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 09:56:56.828987: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 09:56:56.836168: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 09:56:56.852748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 09:56:57.914509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 09:57:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 09:57:00 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-1000/runs/Mar22_09-57-00_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-1000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-1000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-d22542853ecd2369\n","03/22/2025 09:57:00 - INFO - datasets.builder - Using custom data configuration default-d22542853ecd2369\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 09:57:00 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 09:57:00 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 09:57:00 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 09:57:00 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 09:57:00 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 09:57:01,010 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:57:01,011 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 09:57:01,095 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:57:01,096 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 09:57:01,097 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 09:57:01,097 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 09:57:01,098 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 09:57:02,147 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 09:57:02,217 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-22 09:57:02,254 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-22 09:57:02,327 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 09:57:02,327 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 09:57:02,411 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 09:57:02,412 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-22 09:57:02,688 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e70b427f4acd1a90.arrow\n","03/22/2025 09:57:03 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e70b427f4acd1a90.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1e1e9cb1ba5e0af7.arrow\n","03/22/2025 09:57:05 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1e1e9cb1ba5e0af7.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-b37e93e0dc9f95ce.arrow\n","03/22/2025 09:57:06 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d22542853ecd2369/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-b37e93e0dc9f95ce.arrow\n","[INFO|trainer.py:2407] 2025-03-22 09:57:16,033 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 09:57:16,033 >>   Num examples = 1,000\n","[INFO|trainer.py:2409] 2025-03-22 09:57:16,033 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 09:57:16,033 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 09:57:16,033 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 09:57:16,033 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 09:57:16,033 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 09:57:16,033 >>   Total optimization steps = 375\n","[INFO|trainer.py:2416] 2025-03-22 09:57:16,034 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 09:57:16,047 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_095716-zqoky06s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-1000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/zqoky06s\u001b[0m\n","  0% 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 375/375 [04:32<00:00,  1.41it/s][INFO|trainer.py:3944] 2025-03-22 10:01:49,415 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 10:01:49,424 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 10:01:49,425 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 10:02:01,112 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 10:02:01,116 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 10:02:01,116 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 10:02:01,117 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-1000/checkpoint-375/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 10:02:18,962 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 302.9291, 'train_samples_per_second': 9.903, 'train_steps_per_second': 1.238, 'train_loss': 3.718626627604167, 'epoch': 3.0}\n","100% 375/375 [05:02<00:00,  1.24it/s]\n","[INFO|trainer.py:3944] 2025-03-22 10:02:18,966 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 10:02:18,968 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 10:02:18,968 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 10:02:30,512 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 10:02:30,516 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 10:02:30,516 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 10:02:30,517 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-1000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   205627GF\n","  train_loss               =     3.7186\n","  train_runtime            = 0:05:02.92\n","  train_samples            =       1000\n","  train_samples_per_second =      9.903\n","  train_steps_per_second   =      1.238\n","03/22/2025 10:02:30 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 10:02:30,660 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 10:02:30,660 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 10:02:30,661 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [12:24<00:00,  5.96s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     2.1764\n","  eval_chrf               =     20.964\n","  eval_gen_len            =    55.7432\n","  eval_loss               =     3.9585\n","  eval_runtime            = 0:12:31.81\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.326\n","  eval_steps_per_second   =      0.166\n","03/22/2025 10:15:02 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 10:15:02,488 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 10:15:02,488 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 10:15:02,488 >>   Batch size = 8\n","100% 127/127 [13:01<00:00,  6.15s/it]\n","***** predict metrics *****\n","  predict_bleu               =     1.7597\n","  predict_chrf               =    20.5157\n","  predict_gen_len            =       57.0\n","  predict_loss               =     3.9932\n","  predict_runtime            = 0:13:10.13\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.281\n","  predict_steps_per_second   =      0.161\n","[INFO|modelcard.py:449] 2025-03-22 10:28:28,622 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 2.1764}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_1000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-1000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"elapsed":1552,"status":"ok","timestamp":1742639474702,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"hNlChp_8JQJr","outputId":"8f6ab5e6-85a9-43a7-9853-48d28d0f6ff3"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-1000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":869476,"status":"ok","timestamp":1742643222135,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"XCaK_LmtJbGp","outputId":"58942fe0-0f64-4d52-a41f-fbb018ef354e"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 10:31:54.836387: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 10:31:54.858128: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 10:31:54.864716: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 10:31:54.883951: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 10:31:55.950268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 10:31:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 10:31:58 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-1000/runs/Mar22_10-31-58_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-1000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-1000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-d09fb30739d7f4ef\n","03/22/2025 10:31:58 - INFO - datasets.builder - Using custom data configuration default-d09fb30739d7f4ef\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 10:31:58 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 10:31:58 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 10:31:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 10:31:58 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 10:31:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 10:31:58,960 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 10:31:58,961 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 10:31:59,046 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 10:31:59,046 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 10:31:59,047 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 10:31:59,048 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 10:31:59,048 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 10:31:59,966 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 10:32:00,035 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-22 10:32:00,077 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-22 10:32:00,139 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 10:32:00,139 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 10:32:00,230 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 10:32:00,231 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-22 10:32:00,459 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23e62197603ff7b5.arrow\n","03/22/2025 10:32:01 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23e62197603ff7b5.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0d3debe34b3fe7c6.arrow\n","03/22/2025 10:32:02 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0d3debe34b3fe7c6.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7608692f880482db.arrow\n","03/22/2025 10:32:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-d09fb30739d7f4ef/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7608692f880482db.arrow\n","[INFO|trainer.py:2407] 2025-03-22 10:32:09,639 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 10:32:09,639 >>   Num examples = 6,737\n","[INFO|trainer.py:2409] 2025-03-22 10:32:09,639 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 10:32:09,639 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 10:32:09,639 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 10:32:09,639 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 10:32:09,639 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 10:32:09,639 >>   Total optimization steps = 2,529\n","[INFO|trainer.py:2416] 2025-03-22 10:32:09,641 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 10:32:09,647 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_103209-0toqe8lw\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-1000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/0toqe8lw\u001b[0m\n","  0% 0/2529 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.7582, 'grad_norm': 5.092475414276123, 'learning_rate': 4.011466982997232e-05, 'epoch': 0.59}\n"," 20% 500/2529 [07:27<30:42,  1.10it/s][INFO|trainer.py:3944] 2025-03-22 10:39:38,039 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 10:39:38,044 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 10:39:38,045 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 10:39:49,478 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 10:39:49,481 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 10:39:49,482 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 10:39:49,482 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9769, 'grad_norm': 5.819267272949219, 'learning_rate': 3.0229339659944645e-05, 'epoch': 1.19}\n"," 40% 1000/2529 [15:23<22:59,  1.11it/s][INFO|trainer.py:3944] 2025-03-22 10:47:33,653 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 10:47:33,656 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 10:47:33,657 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 10:47:45,177 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 10:47:45,182 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 10:47:45,182 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 10:47:45,183 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4669, 'grad_norm': 5.872149467468262, 'learning_rate': 2.0344009489916967e-05, 'epoch': 1.78}\n"," 59% 1500/2529 [23:19<15:47,  1.09it/s][INFO|trainer.py:3944] 2025-03-22 10:55:30,146 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-22 10:55:30,151 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 10:55:30,151 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 10:55:41,735 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 10:55:41,739 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 10:55:41,740 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 10:55:41,740 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.13, 'grad_norm': 6.943439960479736, 'learning_rate': 1.0458679319889285e-05, 'epoch': 2.37}\n"," 79% 2000/2529 [31:16<07:47,  1.13it/s][INFO|trainer.py:3944] 2025-03-22 11:03:26,797 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 11:03:26,802 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:03:26,803 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:03:38,366 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:03:38,369 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:03:38,370 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:03:38,370 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9484, 'grad_norm': 5.667131423950195, 'learning_rate': 5.733491498616055e-07, 'epoch': 2.97}\n"," 99% 2500/2529 [39:12<00:25,  1.14it/s][INFO|trainer.py:3944] 2025-03-22 11:11:22,975 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-22 11:11:22,980 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:11:22,980 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:11:34,485 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:11:34,489 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:11:34,490 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:11:34,491 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 2529/2529 [40:07<00:00,  1.36it/s][INFO|trainer.py:3944] 2025-03-22 11:12:17,646 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529\n","[INFO|configuration_utils.py:423] 2025-03-22 11:12:17,649 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:12:17,650 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:12:29,343 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:12:29,347 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:12:29,348 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:12:29,348 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/checkpoint-2529/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 11:12:47,583 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2437.9438, 'train_samples_per_second': 8.29, 'train_steps_per_second': 1.037, 'train_loss': 2.647326598010925, 'epoch': 3.0}\n","100% 2529/2529 [40:36<00:00,  1.04it/s]\n","[INFO|trainer.py:3944] 2025-03-22 11:12:47,591 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 11:12:47,593 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:12:47,593 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:12:59,040 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:12:59,043 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:12:59,043 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:12:59,044 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-1000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  2830543GF\n","  train_loss               =     2.6473\n","  train_runtime            = 0:40:37.94\n","  train_samples            =       6737\n","  train_samples_per_second =       8.29\n","  train_steps_per_second   =      1.037\n","03/22/2025 11:12:59 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 11:12:59,190 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 11:12:59,190 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 11:12:59,190 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:47<00:00,  4.70s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     7.5784\n","  eval_chrf               =    42.7323\n","  eval_gen_len            =    47.5797\n","  eval_loss               =      2.476\n","  eval_runtime            = 0:09:53.81\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.679\n","  eval_steps_per_second   =      0.211\n","03/22/2025 11:22:53 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 11:22:53,016 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 11:22:53,016 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 11:22:53,017 >>   Batch size = 8\n","100% 127/127 [10:22<00:00,  4.90s/it]\n","***** predict metrics *****\n","  predict_bleu               =     6.9985\n","  predict_chrf               =    41.5549\n","  predict_gen_len            =    49.2016\n","  predict_loss               =     2.5135\n","  predict_runtime            = 0:10:30.58\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.605\n","  predict_steps_per_second   =      0.201\n","[INFO|modelcard.py:449] 2025-03-22 11:33:39,797 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 7.5784}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_1000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-1000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":159},"id":"X0K_kEpR-cgY","executionInfo":{"status":"ok","timestamp":1743356478323,"user_tz":-120,"elapsed":11746,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"2fb34bba-ee91-4e48-b0b6-42c46c4d509b"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250330_174112-9bxwgip2</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2' target=\"_blank\">random_Zulu-1000</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b679423d7e0>"]},"metadata":{},"execution_count":9}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-1000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGRpKh00-cgY","executionInfo":{"status":"ok","timestamp":1743358200112,"user_tz":-120,"elapsed":1721791,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"1bd6a0fc-81f5-4223-b82f-99421ed1ea71"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-30 17:41:22.635866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-30 17:41:22.658811: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-30 17:41:22.665990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-30 17:41:22.683032: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-30 17:41:23.821471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/30/2025 17:41:26 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/30/2025 17:41:26 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-1000/runs/Mar30_17-41-26_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-1000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-1000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-7d701d019c733fab\n","03/30/2025 17:41:26 - INFO - datasets.builder - Using custom data configuration default-7d701d019c733fab\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/30/2025 17:41:26 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/30/2025 17:41:26 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/30/2025 17:41:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/30/2025 17:41:26 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/30/2025 17:41:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-30 17:41:26,992 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 17:41:26,994 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-30 17:41:27,230 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 17:41:27,231 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,231 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,231 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,231 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,232 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,232 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,232 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 17:41:27,232 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-30 17:41:27,232 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 17:41:27,233 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-30 17:41:28,177 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-30 17:41:28,243 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-30 17:41:28,347 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-30 17:41:28,347 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|safetensors_conversion.py:61] 2025-03-30 17:41:28,376 >> Attempting to create safetensors variant\n","[INFO|configuration_utils.py:1095] 2025-03-30 17:41:28,439 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-30 17:41:28,439 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-30 17:41:29,430 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-181f53cfe6d05509.arrow\n","03/30/2025 17:41:29 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-181f53cfe6d05509.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23729c6b9c405866.arrow\n","03/30/2025 17:41:31 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23729c6b9c405866.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c600cbc9cf8be93d.arrow\n","03/30/2025 17:41:32 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7d701d019c733fab/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c600cbc9cf8be93d.arrow\n","[INFO|trainer.py:2407] 2025-03-30 17:41:38,380 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-30 17:41:38,380 >>   Num examples = 1,000\n","[INFO|trainer.py:2409] 2025-03-30 17:41:38,380 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-30 17:41:38,380 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-30 17:41:38,380 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-30 17:41:38,380 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-30 17:41:38,381 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-30 17:41:38,381 >>   Total optimization steps = 375\n","[INFO|trainer.py:2416] 2025-03-30 17:41:38,382 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-30 17:41:38,387 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250330_174138-ax6cytue\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-1000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/ax6cytue\u001b[0m\n","  0% 0/375 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 375/375 [04:33<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-03-30 17:46:12,187 >> Saving model checkpoint to M2M-100/random-1000/checkpoint-375\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-30 17:46:12,190 >> Configuration saved in M2M-100/random-1000/checkpoint-375/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 17:46:12,191 >> Configuration saved in M2M-100/random-1000/checkpoint-375/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 17:46:17,212 >> Model weights saved in M2M-100/random-1000/checkpoint-375/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 17:46:17,215 >> tokenizer config file saved in M2M-100/random-1000/checkpoint-375/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 17:46:17,216 >> Special tokens file saved in M2M-100/random-1000/checkpoint-375/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 17:46:17,216 >> added tokens file saved in M2M-100/random-1000/checkpoint-375/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-30 17:46:30,809 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 292.428, 'train_samples_per_second': 10.259, 'train_steps_per_second': 1.282, 'train_loss': 3.98108984375, 'epoch': 3.0}\n","100% 375/375 [04:51<00:00,  1.29it/s]\n","[INFO|trainer.py:3944] 2025-03-30 17:46:30,813 >> Saving model checkpoint to M2M-100/random-1000\n","[INFO|configuration_utils.py:423] 2025-03-30 17:46:30,815 >> Configuration saved in M2M-100/random-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 17:46:30,815 >> Configuration saved in M2M-100/random-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 17:46:39,811 >> Model weights saved in M2M-100/random-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 17:46:39,815 >> tokenizer config file saved in M2M-100/random-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 17:46:39,815 >> Special tokens file saved in M2M-100/random-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 17:46:39,815 >> added tokens file saved in M2M-100/random-1000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   192130GF\n","  train_loss               =     3.9811\n","  train_runtime            = 0:04:52.42\n","  train_samples            =       1000\n","  train_samples_per_second =     10.259\n","  train_steps_per_second   =      1.282\n","03/30/2025 17:46:39 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-30 17:46:39,964 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-30 17:46:39,964 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-30 17:46:39,965 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [11:06<00:00,  5.33s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     2.4117\n","  eval_chrf               =    21.5491\n","  eval_gen_len            =    53.2678\n","  eval_loss               =     4.0696\n","  eval_runtime            = 0:11:11.82\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.484\n","  eval_steps_per_second   =      0.186\n","03/30/2025 17:57:51 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-30 17:57:51,796 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-30 17:57:51,796 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-30 17:57:51,796 >>   Batch size = 8\n","100% 127/127 [11:41<00:00,  5.52s/it]\n","***** predict metrics *****\n","  predict_bleu               =     2.0257\n","  predict_chrf               =    20.5138\n","  predict_gen_len            =    54.9526\n","  predict_loss               =     4.1337\n","  predict_runtime            = 0:11:49.20\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.427\n","  predict_steps_per_second   =      0.179\n","[INFO|modelcard.py:449] 2025-03-30 18:09:57,188 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 2.4117}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_1000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-1000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"elapsed":592,"status":"ok","timestamp":1742643238911,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"oAhoqvCbuk06","outputId":"7ca2308e-1f3c-46dd-f52f-dad773deea17"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-2000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1854023,"status":"ok","timestamp":1742645413262,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"S0Vip1YNtpQn","outputId":"8bef0194-7dec-47d9-d889-9d1e5bff57d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 11:34:07.492651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 11:34:07.514254: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 11:34:07.520847: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 11:34:07.536833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 11:34:08.551261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 11:34:10 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 11:34:10 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-2000/runs/Mar22_11-34-10_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-2000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-2000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-63fa3ea70d279152\n","03/22/2025 11:34:11 - INFO - datasets.builder - Using custom data configuration default-63fa3ea70d279152\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 11:34:11 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 11:34:11 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 11:34:11 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 11:34:11 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 11:34:11 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 11:34:11,355 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 11:34:11,357 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 11:34:11,440 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 11:34:11,441 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 11:34:11,442 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 11:34:11,442 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 11:34:11,443 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 11:34:12,314 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 11:34:12,378 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-22 11:34:12,427 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-22 11:34:12,483 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 11:34:12,483 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 11:34:12,569 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 11:34:12,569 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-22 11:34:12,891 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-239a0c8168036379.arrow\n","03/22/2025 11:34:13 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-239a0c8168036379.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4e37c8bc3d2bbba6.arrow\n","03/22/2025 11:34:15 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4e37c8bc3d2bbba6.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-283cd450680fa67d.arrow\n","03/22/2025 11:34:16 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-63fa3ea70d279152/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-283cd450680fa67d.arrow\n","[INFO|trainer.py:2407] 2025-03-22 11:34:19,466 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 11:34:19,466 >>   Num examples = 2,000\n","[INFO|trainer.py:2409] 2025-03-22 11:34:19,466 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 11:34:19,466 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 11:34:19,466 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 11:34:19,466 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 11:34:19,466 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 11:34:19,466 >>   Total optimization steps = 750\n","[INFO|trainer.py:2416] 2025-03-22 11:34:19,467 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 11:34:19,478 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_113419-oj48qc4m\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-2000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/oj48qc4m\u001b[0m\n","  0% 0/750 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.0068, 'grad_norm': 9.566374778747559, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 500/750 [06:08<03:02,  1.37it/s][INFO|trainer.py:3944] 2025-03-22 11:40:28,779 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 11:40:28,784 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:40:28,785 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:40:40,273 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:40:40,276 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:40:40,276 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:40:40,277 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 750/750 [09:41<00:00,  1.37it/s][INFO|trainer.py:3944] 2025-03-22 11:44:02,043 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750\n","[INFO|configuration_utils.py:423] 2025-03-22 11:44:02,046 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:44:02,046 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:44:13,808 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:44:13,813 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:44:13,813 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:44:13,814 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/checkpoint-750/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 11:44:32,070 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 612.603, 'train_samples_per_second': 9.794, 'train_steps_per_second': 1.224, 'train_loss': 3.6032134602864585, 'epoch': 3.0}\n","100% 750/750 [10:11<00:00,  1.23it/s]\n","[INFO|trainer.py:3944] 2025-03-22 11:44:32,078 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 11:44:32,080 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 11:44:32,080 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 11:44:43,632 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 11:44:43,635 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 11:44:43,635 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 11:44:43,636 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-2000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   409031GF\n","  train_loss               =     3.6032\n","  train_runtime            = 0:10:12.60\n","  train_samples            =       2000\n","  train_samples_per_second =      9.794\n","  train_steps_per_second   =      1.224\n","03/22/2025 11:44:43 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 11:44:43,776 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 11:44:43,776 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 11:44:43,776 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [11:53<00:00,  5.71s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     2.8885\n","  eval_chrf               =    24.2956\n","  eval_gen_len            =    54.0822\n","  eval_loss               =     3.7205\n","  eval_runtime            = 0:12:02.26\n","  eval_samples            =        997\n","  eval_samples_per_second =       1.38\n","  eval_steps_per_second   =      0.173\n","03/22/2025 11:56:46 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 11:56:46,052 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 11:56:46,052 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 11:56:46,052 >>   Batch size = 8\n","100% 127/127 [13:00<00:00,  6.14s/it]\n","***** predict metrics *****\n","  predict_bleu               =     2.5867\n","  predict_chrf               =    23.9403\n","  predict_gen_len            =    55.6423\n","  predict_loss               =     3.7725\n","  predict_runtime            = 0:13:08.91\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.283\n","  predict_steps_per_second   =      0.161\n","[INFO|modelcard.py:449] 2025-03-22 12:10:10,690 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 2.8885}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_2000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-2000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"elapsed":215,"status":"ok","timestamp":1742645413263,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"NRaFN03_pcfD","outputId":"7a20afbb-9ed7-4e98-dfd9-e6525e71490d"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-2000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2465846,"status":"ok","timestamp":1742649304176,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"sEJT63ZLpVl-","outputId":"5b9e554f-64e5-4bd2-e072-0a25a4676489"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 12:10:16.914157: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 12:10:16.936412: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 12:10:16.943127: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 12:10:16.959268: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 12:10:17.957737: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 12:10:20 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 12:10:20 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-2000/runs/Mar22_12-10-20_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-2000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-2000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-00c1f33ddcf7c443\n","03/22/2025 12:10:20 - INFO - datasets.builder - Using custom data configuration default-00c1f33ddcf7c443\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 12:10:20 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 12:10:20 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 12:10:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 12:10:20 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 12:10:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 12:10:20,738 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 12:10:20,739 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 12:10:20,828 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 12:10:20,829 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,829 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,829 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,829 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,829 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,830 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,830 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 12:10:20,830 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 12:10:20,830 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 12:10:20,831 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 12:10:21,993 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 12:10:22,058 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-22 12:10:22,159 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 12:10:22,159 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|safetensors_conversion.py:61] 2025-03-22 12:10:22,233 >> Attempting to create safetensors variant\n","[INFO|configuration_utils.py:1095] 2025-03-22 12:10:22,252 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 12:10:22,252 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-22 12:10:22,771 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d9db24e4ea92c1e2.arrow\n","03/22/2025 12:10:23 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d9db24e4ea92c1e2.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9e62119e384f3dba.arrow\n","03/22/2025 12:10:24 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9e62119e384f3dba.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2488e0046852a6d9.arrow\n","03/22/2025 12:10:26 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-00c1f33ddcf7c443/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2488e0046852a6d9.arrow\n","[INFO|trainer.py:2407] 2025-03-22 12:10:28,846 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 12:10:28,846 >>   Num examples = 7,737\n","[INFO|trainer.py:2409] 2025-03-22 12:10:28,846 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 12:10:28,846 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 12:10:28,846 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 12:10:28,846 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 12:10:28,846 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 12:10:28,846 >>   Total optimization steps = 2,904\n","[INFO|trainer.py:2416] 2025-03-22 12:10:28,847 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 12:10:28,854 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_121028-xdtr0l5a\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-2000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/xdtr0l5a\u001b[0m\n","  0% 0/2904 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.8378, 'grad_norm': 5.276322841644287, 'learning_rate': 4.139118457300275e-05, 'epoch': 0.52}\n"," 17% 500/2904 [07:21<36:08,  1.11it/s][INFO|trainer.py:3944] 2025-03-22 12:17:50,743 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 12:17:50,746 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:17:50,747 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:17:55,568 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:17:55,571 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:17:55,572 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:17:55,572 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1627, 'grad_norm': 5.931947231292725, 'learning_rate': 3.278236914600551e-05, 'epoch': 1.03}\n"," 34% 1000/2904 [14:58<28:36,  1.11it/s][INFO|trainer.py:3944] 2025-03-22 12:25:27,745 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 12:25:27,747 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:25:27,747 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:25:32,664 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:25:32,667 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:25:32,668 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:25:32,668 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5523, 'grad_norm': 5.885161876678467, 'learning_rate': 2.4173553719008264e-05, 'epoch': 1.55}\n"," 52% 1500/2904 [22:33<20:29,  1.14it/s][INFO|trainer.py:3944] 2025-03-22 12:33:03,687 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-22 12:33:03,689 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:33:03,690 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:33:08,539 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:33:08,542 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:33:08,543 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:33:08,543 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3528, 'grad_norm': 6.115939617156982, 'learning_rate': 1.5564738292011018e-05, 'epoch': 2.07}\n"," 69% 2000/2904 [30:10<13:14,  1.14it/s][INFO|trainer.py:3944] 2025-03-22 12:40:39,945 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 12:40:39,947 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:40:39,947 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:40:44,829 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:40:44,832 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:40:44,832 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:40:44,833 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9936, 'grad_norm': 6.911382675170898, 'learning_rate': 6.955922865013774e-06, 'epoch': 2.58}\n"," 86% 2500/2904 [37:50<05:38,  1.19it/s][INFO|trainer.py:3944] 2025-03-22 12:48:20,187 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-22 12:48:20,188 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:48:20,189 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:48:25,111 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:48:25,114 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:48:25,115 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:48:25,115 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 2904/2904 [43:58<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-03-22 12:54:27,744 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904\n","[INFO|configuration_utils.py:423] 2025-03-22 12:54:27,746 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:54:27,747 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:54:32,793 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:54:32,795 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:54:32,796 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:54:32,796 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/checkpoint-2904/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 12:54:46,617 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2657.7704, 'train_samples_per_second': 8.733, 'train_steps_per_second': 1.093, 'train_loss': 2.66652855991332, 'epoch': 3.0}\n","100% 2904/2904 [44:16<00:00,  1.09it/s]\n","[INFO|trainer.py:3944] 2025-03-22 12:54:46,622 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 12:54:46,624 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 12:54:46,625 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 12:54:55,583 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 12:54:55,587 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 12:54:55,588 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 12:54:55,588 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-2000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3124969GF\n","  train_loss               =     2.6665\n","  train_runtime            = 0:44:17.77\n","  train_samples            =       7737\n","  train_samples_per_second =      8.733\n","  train_steps_per_second   =      1.093\n","03/22/2025 12:54:55 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 12:54:55,729 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 12:54:55,729 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 12:54:55,729 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:20<00:00,  4.48s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =      7.606\n","  eval_chrf               =    42.7291\n","  eval_gen_len            =    46.9649\n","  eval_loss               =     2.4326\n","  eval_runtime            = 0:09:26.32\n","  eval_samples            =        997\n","  eval_samples_per_second =       1.76\n","  eval_steps_per_second   =      0.221\n","03/22/2025 13:04:22 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 13:04:22,064 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 13:04:22,064 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 13:04:22,065 >>   Batch size = 8\n","100% 127/127 [10:13<00:00,  4.83s/it]\n","***** predict metrics *****\n","  predict_bleu               =     7.5372\n","  predict_chrf               =    42.2996\n","  predict_gen_len            =     48.833\n","  predict_loss               =     2.4674\n","  predict_runtime            = 0:10:20.33\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.631\n","  predict_steps_per_second   =      0.205\n","[INFO|modelcard.py:449] 2025-03-22 13:14:58,109 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 7.606}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_2000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-2000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"id":"5SFZ2Tgf-cgZ","executionInfo":{"status":"ok","timestamp":1743358200112,"user_tz":-120,"elapsed":5,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"24d12420-c984-4103-f004-1d951d56f7c1"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b679423d7e0>"]},"metadata":{},"execution_count":11}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-2000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyAWS4Th-cgZ","executionInfo":{"status":"ok","timestamp":1743360221653,"user_tz":-120,"elapsed":2021544,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"2164a560-8f60-456d-87b5-c7bf9f878ac7"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-30 18:10:04.130615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-30 18:10:04.154283: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-30 18:10:04.160891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-30 18:10:04.177458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-30 18:10:05.241079: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/30/2025 18:10:07 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/30/2025 18:10:07 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-2000/runs/Mar30_18-10-07_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-2000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-2000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-abfb6442294b2a02\n","03/30/2025 18:10:07 - INFO - datasets.builder - Using custom data configuration default-abfb6442294b2a02\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/30/2025 18:10:07 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/30/2025 18:10:08 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/30/2025 18:10:08 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/30/2025 18:10:08 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/30/2025 18:10:08 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/30/2025 18:10:08 - INFO - datasets.builder - Generating train split\n","Generating train split: 2000 examples [00:00, 284349.95 examples/s]\n","Generating validation split\n","03/30/2025 18:10:08 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 184087.04 examples/s]\n","Generating test split\n","03/30/2025 18:10:08 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 154891.10 examples/s]\n","Unable to verify splits sizes.\n","03/30/2025 18:10:08 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/30/2025 18:10:08 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-30 18:10:08,157 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:10:08,158 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-30 18:10:08,246 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:10:08,247 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,247 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:10:08,248 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-30 18:10:08,248 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:10:08,249 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-30 18:10:09,158 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-30 18:10:09,224 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-30 18:10:09,273 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-30 18:10:09,329 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-30 18:10:09,329 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-30 18:10:09,417 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-30 18:10:09,417 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-30 18:10:09,623 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/2000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d164242d5ee95325.arrow\n","03/30/2025 18:10:11 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d164242d5ee95325.arrow\n","Running tokenizer on train dataset: 100% 2000/2000 [00:00<00:00, 3471.55 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dae72072bf78191b.arrow\n","03/30/2025 18:10:13 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-dae72072bf78191b.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1724.41 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-70e4e56bb2ffecb3.arrow\n","03/30/2025 18:10:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-abfb6442294b2a02/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-70e4e56bb2ffecb3.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1751.33 examples/s]\n","[INFO|trainer.py:2407] 2025-03-30 18:10:17,949 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-30 18:10:17,949 >>   Num examples = 2,000\n","[INFO|trainer.py:2409] 2025-03-30 18:10:17,949 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-30 18:10:17,949 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-30 18:10:17,949 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-30 18:10:17,949 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-30 18:10:17,949 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-30 18:10:17,950 >>   Total optimization steps = 750\n","[INFO|trainer.py:2416] 2025-03-30 18:10:17,951 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-30 18:10:17,956 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250330_181018-uahrxvte\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-2000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/uahrxvte\u001b[0m\n","  0% 0/750 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.2317, 'grad_norm': 8.773533821105957, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 500/750 [06:04<03:00,  1.38it/s][INFO|trainer.py:3944] 2025-03-30 18:16:23,226 >> Saving model checkpoint to M2M-100/random-2000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-30 18:16:23,229 >> Configuration saved in M2M-100/random-2000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 18:16:23,230 >> Configuration saved in M2M-100/random-2000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 18:16:28,141 >> Model weights saved in M2M-100/random-2000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 18:16:28,144 >> tokenizer config file saved in M2M-100/random-2000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 18:16:28,145 >> Special tokens file saved in M2M-100/random-2000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 18:16:28,145 >> added tokens file saved in M2M-100/random-2000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 750/750 [09:24<00:00,  1.38it/s][INFO|trainer.py:3944] 2025-03-30 18:19:43,302 >> Saving model checkpoint to M2M-100/random-2000/checkpoint-750\n","[INFO|configuration_utils.py:423] 2025-03-30 18:19:43,304 >> Configuration saved in M2M-100/random-2000/checkpoint-750/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 18:19:43,305 >> Configuration saved in M2M-100/random-2000/checkpoint-750/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 18:19:48,381 >> Model weights saved in M2M-100/random-2000/checkpoint-750/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 18:19:48,384 >> tokenizer config file saved in M2M-100/random-2000/checkpoint-750/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 18:19:48,385 >> Special tokens file saved in M2M-100/random-2000/checkpoint-750/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 18:19:48,385 >> added tokens file saved in M2M-100/random-2000/checkpoint-750/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-30 18:20:02,039 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 584.0883, 'train_samples_per_second': 10.272, 'train_steps_per_second': 1.284, 'train_loss': 3.8185546875, 'epoch': 3.0}\n","100% 750/750 [09:43<00:00,  1.29it/s]\n","[INFO|trainer.py:3944] 2025-03-30 18:20:02,049 >> Saving model checkpoint to M2M-100/random-2000\n","[INFO|configuration_utils.py:423] 2025-03-30 18:20:02,051 >> Configuration saved in M2M-100/random-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 18:20:02,052 >> Configuration saved in M2M-100/random-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 18:20:10,988 >> Model weights saved in M2M-100/random-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 18:20:10,992 >> tokenizer config file saved in M2M-100/random-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 18:20:10,993 >> Special tokens file saved in M2M-100/random-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 18:20:10,993 >> added tokens file saved in M2M-100/random-2000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   381075GF\n","  train_loss               =     3.8186\n","  train_runtime            = 0:09:44.08\n","  train_samples            =       2000\n","  train_samples_per_second =     10.272\n","  train_steps_per_second   =      1.284\n","03/30/2025 18:20:11 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-30 18:20:11,146 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-30 18:20:11,147 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-30 18:20:11,147 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [11:03<00:00,  5.31s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     2.7377\n","  eval_chrf               =    22.8372\n","  eval_gen_len            =    53.7472\n","  eval_loss               =     3.7827\n","  eval_runtime            = 0:11:10.29\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.487\n","  eval_steps_per_second   =      0.186\n","03/30/2025 18:31:21 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-30 18:31:21,443 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-30 18:31:21,443 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-30 18:31:21,443 >>   Batch size = 8\n","100% 127/127 [11:52<00:00,  5.61s/it]\n","***** predict metrics *****\n","  predict_bleu               =     2.5838\n","  predict_chrf               =     22.243\n","  predict_gen_len            =    55.1621\n","  predict_loss               =     3.8327\n","  predict_runtime            = 0:12:00.53\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.405\n","  predict_steps_per_second   =      0.176\n","[INFO|modelcard.py:449] 2025-03-30 18:43:38,393 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 2.7377}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_2000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-2000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1435,"status":"ok","timestamp":1742649366291,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"0v4YeYRgumqu","outputId":"aef268cc-af4b-4a8d-c6a0-87c8aa83c6d0"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-4000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":315259,"status":"ok","timestamp":1742651990496,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"yGUYnc2wtrby","outputId":"97b59ec9-0741-4582-8899-f451dd2e5fa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 13:16:13.983970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 13:16:14.005927: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 13:16:14.013098: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 13:16:14.030972: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 13:16:15.362446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 13:16:18 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 13:16:18 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-4000/runs/Mar22_13-16-18_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-4000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-4000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-2c18f5caf6d15f80\n","03/22/2025 13:16:18 - INFO - datasets.builder - Using custom data configuration default-2c18f5caf6d15f80\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 13:16:18 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/22/2025 13:16:18 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 13:16:18 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 13:16:18 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/22/2025 13:16:18 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-22 13:16:18,687 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 13:16:18,688 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 13:16:18,894 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 13:16:18,895 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 13:16:18,896 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 13:16:18,896 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 13:16:18,897 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 13:16:19,894 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 13:16:19,970 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-22 13:16:20,006 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-22 13:16:20,075 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 13:16:20,075 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 13:16:20,163 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 13:16:20,164 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-22 13:16:20,400 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-b3e5c8b83b5f5d81.arrow\n","03/22/2025 13:16:21 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-b3e5c8b83b5f5d81.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d80ea2e702926f3c.arrow\n","03/22/2025 13:16:22 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d80ea2e702926f3c.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-94a06ef0cd1537df.arrow\n","03/22/2025 13:16:24 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-2c18f5caf6d15f80/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-94a06ef0cd1537df.arrow\n","[INFO|trainer.py:2407] 2025-03-22 13:16:26,887 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 13:16:26,887 >>   Num examples = 4,000\n","[INFO|trainer.py:2409] 2025-03-22 13:16:26,887 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 13:16:26,887 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 13:16:26,887 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 13:16:26,887 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 13:16:26,887 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 13:16:26,887 >>   Total optimization steps = 1,500\n","[INFO|trainer.py:2416] 2025-03-22 13:16:26,888 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 13:16:26,899 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_131627-yxsftebf\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-4000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/yxsftebf\u001b[0m\n","  0% 0/1500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.3832, 'grad_norm': 6.679620265960693, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 500/1500 [06:12<12:41,  1.31it/s][INFO|trainer.py:3944] 2025-03-22 13:22:40,359 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 13:22:40,365 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 13:22:40,366 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 13:22:51,898 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 13:22:51,904 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 13:22:51,904 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 13:22:51,905 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.2835, 'grad_norm': 7.958261489868164, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 1000/1500 [12:53<06:44,  1.24it/s][INFO|trainer.py:3944] 2025-03-22 13:29:21,123 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 13:29:21,126 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 13:29:21,127 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 13:29:32,646 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 13:29:32,650 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 13:29:32,650 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 13:29:32,650 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.6419, 'grad_norm': 9.801591873168945, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 1500/1500 [19:34<00:00,  1.37it/s][INFO|trainer.py:3944] 2025-03-22 13:36:02,341 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-22 13:36:02,345 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 13:36:02,346 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 13:36:13,868 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 13:36:13,872 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 13:36:13,873 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 13:36:13,873 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/checkpoint-1500/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 13:36:31,709 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 1204.8211, 'train_samples_per_second': 9.96, 'train_steps_per_second': 1.245, 'train_loss': 3.436231201171875, 'epoch': 3.0}\n","100% 1500/1500 [20:03<00:00,  1.25it/s]\n","[INFO|trainer.py:3944] 2025-03-22 13:36:31,712 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-4000\n","[INFO|configuration_utils.py:423] 2025-03-22 13:36:31,714 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 13:36:31,715 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 13:36:43,184 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 13:36:43,188 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 13:36:43,188 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 13:36:43,189 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-4000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   849267GF\n","  train_loss               =     3.4362\n","  train_runtime            = 0:20:04.82\n","  train_samples            =       4000\n","  train_samples_per_second =       9.96\n","  train_steps_per_second   =      1.245\n","03/22/2025 13:36:43 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 13:36:43,327 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 13:36:43,327 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 13:36:43,328 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [10:49<00:00,  5.20s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     3.7529\n","  eval_chrf               =    28.1439\n","  eval_gen_len            =    49.7332\n","  eval_loss               =     3.3484\n","  eval_runtime            = 0:10:58.37\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.514\n","  eval_steps_per_second   =       0.19\n","03/22/2025 13:47:41 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 13:47:41,708 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 13:47:41,708 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 13:47:41,708 >>   Batch size = 8\n","100% 127/127 [11:42<00:00,  5.53s/it]\n","***** predict metrics *****\n","  predict_bleu               =      3.384\n","  predict_chrf               =    27.3592\n","  predict_gen_len            =    51.6087\n","  predict_loss               =     3.4078\n","  predict_runtime            = 0:11:51.00\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.423\n","  predict_steps_per_second   =      0.179\n","[INFO|modelcard.py:449] 2025-03-22 13:59:48,360 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 3.7529}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_4000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-4000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1742656189031,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"NbZGn4hdAM3V","outputId":"2f954fa1-4b78-4494-c05a-796be1d8f31c"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/0njzblna?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7a7e2df34250>"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-4000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2013339,"status":"ok","timestamp":1742660701508,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"pC_AF5g-AVy3","outputId":"336fc9ce-e522-4e59-8bd1-33efb7d085e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-22 15:09:56.838909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-22 15:09:56.860287: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-22 15:09:56.866879: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-22 15:09:56.882884: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-22 15:09:57.914709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/22/2025 15:10:00 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/22/2025 15:10:00 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-4000/runs/Mar22_15-10-00_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-4000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-4000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-f3c362cd2250520f\n","03/22/2025 15:10:00 - INFO - datasets.builder - Using custom data configuration default-f3c362cd2250520f\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/22/2025 15:10:00 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/22/2025 15:10:00 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/22/2025 15:10:00 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/22/2025 15:10:00 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/22/2025 15:10:00 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/22/2025 15:10:00 - INFO - datasets.builder - Generating train split\n","Generating train split: 9737 examples [00:00, 207328.27 examples/s]\n","Generating validation split\n","03/22/2025 15:10:00 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 218047.82 examples/s]\n","Generating test split\n","03/22/2025 15:10:00 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 234756.69 examples/s]\n","Unable to verify splits sizes.\n","03/22/2025 15:10:00 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/22/2025 15:10:00 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-22 15:10:00,804 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 15:10:00,806 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-22 15:10:00,905 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 15:10:00,905 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-22 15:10:00,906 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-22 15:10:00,907 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-22 15:10:00,907 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-22 15:10:01,817 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-22 15:10:01,881 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-22 15:10:01,977 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-22 15:10:01,977 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-22 15:10:02,067 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-22 15:10:02,067 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-22 15:10:02,748 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-22 15:10:03,168 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/9737 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a84d01f0e3c506e2.arrow\n","03/22/2025 15:10:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a84d01f0e3c506e2.arrow\n","Running tokenizer on train dataset: 100% 9737/9737 [00:04<00:00, 2147.16 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ba84a83df7f0235.arrow\n","03/22/2025 15:10:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ba84a83df7f0235.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1854.50 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6ca21061951ac471.arrow\n","03/22/2025 15:10:11 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-f3c362cd2250520f/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6ca21061951ac471.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1856.60 examples/s]\n","[INFO|trainer.py:2407] 2025-03-22 15:10:15,163 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-22 15:10:15,163 >>   Num examples = 9,737\n","[INFO|trainer.py:2409] 2025-03-22 15:10:15,163 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-22 15:10:15,163 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-22 15:10:15,163 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-22 15:10:15,164 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-22 15:10:15,164 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-22 15:10:15,164 >>   Total optimization steps = 3,654\n","[INFO|trainer.py:2416] 2025-03-22 15:10:15,165 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-22 15:10:15,170 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250322_151015-tpjlmnb0\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-4000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/tpjlmnb0\u001b[0m\n","  0% 0/3654 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.949, 'grad_norm': 8.702216148376465, 'learning_rate': 4.315818281335523e-05, 'epoch': 0.41}\n"," 14% 500/3654 [07:09<42:47,  1.23it/s][INFO|trainer.py:3944] 2025-03-22 15:17:26,301 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-22 15:17:26,304 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:17:26,305 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:17:31,194 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:17:31,197 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:17:31,197 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:17:31,198 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.3469, 'grad_norm': 7.719375133514404, 'learning_rate': 3.6316365626710456e-05, 'epoch': 0.82}\n"," 27% 1000/3654 [14:39<39:48,  1.11it/s][INFO|trainer.py:3944] 2025-03-22 15:24:55,714 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-22 15:24:55,716 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:24:55,717 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:25:00,711 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:25:00,714 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:25:00,714 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:25:00,715 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8412, 'grad_norm': 6.0307440757751465, 'learning_rate': 2.947454844006568e-05, 'epoch': 1.23}\n"," 41% 1500/3654 [22:06<28:17,  1.27it/s][INFO|trainer.py:3944] 2025-03-22 15:32:22,783 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-22 15:32:22,784 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:32:22,785 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:32:27,716 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:32:27,720 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:32:27,720 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:32:27,721 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5354, 'grad_norm': 5.58447790145874, 'learning_rate': 2.263273125342091e-05, 'epoch': 1.64}\n"," 55% 2000/3654 [29:35<23:13,  1.19it/s][INFO|trainer.py:3944] 2025-03-22 15:39:51,869 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-22 15:39:51,871 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:39:51,872 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:39:56,733 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:39:56,736 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:39:56,736 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:39:56,737 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3739, 'grad_norm': 5.18902587890625, 'learning_rate': 1.5790914066776137e-05, 'epoch': 2.05}\n"," 68% 2500/3654 [37:04<16:35,  1.16it/s][INFO|trainer.py:3944] 2025-03-22 15:47:21,098 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-22 15:47:21,100 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:47:21,101 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:47:26,014 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:47:26,017 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:47:26,018 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:47:26,018 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.025, 'grad_norm': 6.271111488342285, 'learning_rate': 8.949096880131364e-06, 'epoch': 2.46}\n"," 82% 3000/3654 [44:34<09:10,  1.19it/s][INFO|trainer.py:3944] 2025-03-22 15:54:51,017 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-22 15:54:51,019 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 15:54:51,020 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 15:54:55,934 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 15:54:55,937 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 15:54:55,938 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 15:54:55,938 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9933, 'grad_norm': 6.618305683135986, 'learning_rate': 2.1072796934865904e-06, 'epoch': 2.87}\n"," 96% 3500/3654 [52:05<02:09,  1.19it/s][INFO|trainer.py:3944] 2025-03-22 16:02:22,253 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-22 16:02:22,255 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 16:02:22,256 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 16:02:27,145 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 16:02:27,149 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 16:02:27,150 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 16:02:27,150 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 3654/3654 [54:35<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-03-22 16:04:51,818 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654\n","[INFO|configuration_utils.py:423] 2025-03-22 16:04:51,819 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 16:04:51,820 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 16:04:56,840 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 16:04:56,843 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 16:04:56,843 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 16:04:56,844 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/checkpoint-3654/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-22 16:05:10,707 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 3295.5424, 'train_samples_per_second': 8.864, 'train_steps_per_second': 1.109, 'train_loss': 2.6922839435646293, 'epoch': 3.0}\n","100% 3654/3654 [54:54<00:00,  1.11it/s]\n","[INFO|trainer.py:3944] 2025-03-22 16:05:10,716 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-4000\n","[INFO|configuration_utils.py:423] 2025-03-22 16:05:10,718 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-22 16:05:10,719 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-22 16:05:19,653 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-22 16:05:19,657 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-22 16:05:19,658 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-22 16:05:19,658 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-4000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3718749GF\n","  train_loss               =     2.6923\n","  train_runtime            = 0:54:55.54\n","  train_samples            =       9737\n","  train_samples_per_second =      8.864\n","  train_steps_per_second   =      1.109\n","03/22/2025 16:05:19 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-22 16:05:19,820 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-22 16:05:19,821 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-22 16:05:19,821 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:19<00:00,  4.47s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     8.3068\n","  eval_chrf               =    43.7736\n","  eval_gen_len            =    46.2227\n","  eval_loss               =      2.353\n","  eval_runtime            = 0:09:25.60\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.763\n","  eval_steps_per_second   =      0.221\n","03/22/2025 16:14:45 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-22 16:14:45,430 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-22 16:14:45,430 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-22 16:14:45,430 >>   Batch size = 8\n","100% 127/127 [09:50<00:00,  4.65s/it]\n","***** predict metrics *****\n","  predict_bleu               =     7.9085\n","  predict_chrf               =    43.2905\n","  predict_gen_len            =     48.083\n","  predict_loss               =     2.3917\n","  predict_runtime            = 0:09:58.16\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.692\n","  predict_steps_per_second   =      0.212\n","[INFO|modelcard.py:449] 2025-03-22 16:24:58,942 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 8.3068}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_4000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-4000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1743360283754,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"vccJW8nKsBGP","outputId":"f1c23d26-711b-407c-85cd-205ea05a7bab"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b679423d7e0>"]},"metadata":{},"execution_count":13}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-4000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EXp3zJrE-cga","executionInfo":{"status":"ok","timestamp":1743362986095,"user_tz":-120,"elapsed":68570,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"2e81d960-f855-4a1d-fa6d-50e0b61ff137"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-30 18:44:55.033346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-30 18:44:55.055945: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-30 18:44:55.062667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-30 18:44:55.081604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-30 18:44:56.151155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/30/2025 18:44:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/30/2025 18:44:58 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-4000/runs/Mar30_18-44-58_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-4000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-4000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-6361c05cd5c4d1fe\n","03/30/2025 18:44:58 - INFO - datasets.builder - Using custom data configuration default-6361c05cd5c4d1fe\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/30/2025 18:44:58 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/30/2025 18:44:58 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/30/2025 18:44:58 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/30/2025 18:44:58 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/30/2025 18:44:58 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/30/2025 18:44:58 - INFO - datasets.builder - Generating train split\n","Generating train split: 4000 examples [00:00, 346036.14 examples/s]\n","Generating validation split\n","03/30/2025 18:44:58 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 144003.62 examples/s]\n","Generating test split\n","03/30/2025 18:44:58 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 226937.32 examples/s]\n","Unable to verify splits sizes.\n","03/30/2025 18:44:58 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/30/2025 18:44:58 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-30 18:44:59,058 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:44:59,060 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-30 18:44:59,249 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:44:59,250 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,251 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 18:44:59,252 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-30 18:44:59,252 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 18:44:59,253 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-30 18:45:00,146 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-30 18:45:00,212 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-30 18:45:00,312 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-30 18:45:00,312 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-30 18:45:00,401 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-30 18:45:00,402 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-30 18:45:00,535 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-30 18:45:00,959 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/4000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-57c1bd72abeb5017.arrow\n","03/30/2025 18:45:02 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-57c1bd72abeb5017.arrow\n","Running tokenizer on train dataset: 100% 4000/4000 [00:01<00:00, 3385.93 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-eb898b6e87d2b1e6.arrow\n","03/30/2025 18:45:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-eb898b6e87d2b1e6.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1794.62 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-09afcfda404ca6ce.arrow\n","03/30/2025 18:45:06 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6361c05cd5c4d1fe/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-09afcfda404ca6ce.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1758.17 examples/s]\n","[INFO|trainer.py:2407] 2025-03-30 18:45:10,502 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-30 18:45:10,502 >>   Num examples = 4,000\n","[INFO|trainer.py:2409] 2025-03-30 18:45:10,502 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-30 18:45:10,502 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-30 18:45:10,503 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-30 18:45:10,503 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-30 18:45:10,503 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-30 18:45:10,503 >>   Total optimization steps = 1,500\n","[INFO|trainer.py:2416] 2025-03-30 18:45:10,504 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-30 18:45:10,509 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250330_184510-8nj8wewp\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-4000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/8nj8wewp\u001b[0m\n","  0% 0/1500 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.6352, 'grad_norm': 9.24590015411377, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 500/1500 [06:06<12:03,  1.38it/s][INFO|trainer.py:3944] 2025-03-30 18:51:18,193 >> Saving model checkpoint to M2M-100/random-4000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-30 18:51:18,196 >> Configuration saved in M2M-100/random-4000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 18:51:18,197 >> Configuration saved in M2M-100/random-4000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 18:51:23,130 >> Model weights saved in M2M-100/random-4000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 18:51:23,134 >> tokenizer config file saved in M2M-100/random-4000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 18:51:23,134 >> Special tokens file saved in M2M-100/random-4000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 18:51:23,135 >> added tokens file saved in M2M-100/random-4000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.5598, 'grad_norm': 12.774005889892578, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 1000/1500 [12:31<06:10,  1.35it/s][INFO|trainer.py:3944] 2025-03-30 18:57:43,268 >> Saving model checkpoint to M2M-100/random-4000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-30 18:57:43,270 >> Configuration saved in M2M-100/random-4000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 18:57:43,271 >> Configuration saved in M2M-100/random-4000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 18:57:48,292 >> Model weights saved in M2M-100/random-4000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 18:57:48,296 >> tokenizer config file saved in M2M-100/random-4000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 18:57:48,296 >> Special tokens file saved in M2M-100/random-4000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 18:57:48,297 >> added tokens file saved in M2M-100/random-4000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8973, 'grad_norm': 7.80224609375, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 1500/1500 [18:56<00:00,  1.32it/s][INFO|trainer.py:3944] 2025-03-30 19:04:07,690 >> Saving model checkpoint to M2M-100/random-4000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-30 19:04:07,692 >> Configuration saved in M2M-100/random-4000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:04:07,696 >> Configuration saved in M2M-100/random-4000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:04:12,739 >> Model weights saved in M2M-100/random-4000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:04:12,743 >> tokenizer config file saved in M2M-100/random-4000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:04:12,743 >> Special tokens file saved in M2M-100/random-4000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:04:12,744 >> added tokens file saved in M2M-100/random-4000/checkpoint-1500/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-30 19:04:26,376 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 1155.8724, 'train_samples_per_second': 10.382, 'train_steps_per_second': 1.298, 'train_loss': 3.6974073893229167, 'epoch': 3.0}\n","100% 1500/1500 [19:15<00:00,  1.30it/s]\n","[INFO|trainer.py:3944] 2025-03-30 19:04:26,379 >> Saving model checkpoint to M2M-100/random-4000\n","[INFO|configuration_utils.py:423] 2025-03-30 19:04:26,381 >> Configuration saved in M2M-100/random-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:04:26,382 >> Configuration saved in M2M-100/random-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:04:35,304 >> Model weights saved in M2M-100/random-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:04:35,310 >> tokenizer config file saved in M2M-100/random-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:04:35,310 >> Special tokens file saved in M2M-100/random-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:04:35,310 >> added tokens file saved in M2M-100/random-4000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =   803020GF\n","  train_loss               =     3.6974\n","  train_runtime            = 0:19:15.87\n","  train_samples            =       4000\n","  train_samples_per_second =     10.382\n","  train_steps_per_second   =      1.298\n","03/30/2025 19:04:35 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-30 19:04:35,459 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-30 19:04:35,459 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-30 19:04:35,460 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [12:09<00:00,  5.83s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     2.7734\n","  eval_chrf               =    25.1543\n","  eval_gen_len            =    54.8736\n","  eval_loss               =      3.493\n","  eval_runtime            = 0:12:16.51\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.354\n","  eval_steps_per_second   =       0.17\n","03/30/2025 19:16:51 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-30 19:16:51,979 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-30 19:16:51,979 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-30 19:16:51,979 >>   Batch size = 8\n","100% 127/127 [12:28<00:00,  5.89s/it]\n","***** predict metrics *****\n","  predict_bleu               =     2.3806\n","  predict_chrf               =    24.2939\n","  predict_gen_len            =    55.8241\n","  predict_loss               =     3.5269\n","  predict_runtime            = 0:12:34.17\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.342\n","  predict_steps_per_second   =      0.168\n","[INFO|modelcard.py:449] 2025-03-30 19:29:43,058 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 2.7734}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_4000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-4000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"elapsed":11272,"status":"ok","timestamp":1742831225311,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"hKmXZ3xLuoYh","outputId":"db4f2486-1a48-4aad-cd30-deeadb09cbf4"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250324_154659-mgk6bytk</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk' target=\"_blank\">africomet-8000</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b0e028ec280>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-8000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3599131,"status":"ok","timestamp":1742834854630,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"TZSOQFxvttWv","outputId":"b8fd0cd6-07a1-461d-f6cb-7997b3d1f226"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-24 15:47:42.556798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-24 15:47:42.579116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-24 15:47:42.586255: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-24 15:47:42.602197: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-24 15:47:43.613935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/24/2025 15:47:48 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/24/2025 15:47:48 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-8000/runs/Mar24_15-47-48_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-8000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-8000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-5bc63a9eaf840ac0\n","03/24/2025 15:47:49 - INFO - datasets.builder - Using custom data configuration default-5bc63a9eaf840ac0\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/24/2025 15:47:49 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/24/2025 15:47:49 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/24/2025 15:47:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/24/2025 15:47:49 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/24/2025 15:47:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-24 15:47:49,388 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 15:47:49,390 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-24 15:47:49,529 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 15:47:49,530 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 15:47:49,532 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-24 15:47:49,532 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 15:47:49,533 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-24 15:47:50,525 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|safetensors_conversion.py:61] 2025-03-24 15:47:50,650 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-24 15:47:50,962 >> Safetensors PR exists\n","[INFO|configuration_utils.py:1140] 2025-03-24 15:47:51,270 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-24 15:47:51,469 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-24 15:47:51,470 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-24 15:47:51,560 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-24 15:47:51,560 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-805d80dbaf682edc.arrow\n","03/24/2025 15:47:52 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-805d80dbaf682edc.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8d35743ea3961495.arrow\n","03/24/2025 15:47:54 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8d35743ea3961495.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a687ca1a7df8988f.arrow\n","03/24/2025 15:47:55 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-5bc63a9eaf840ac0/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a687ca1a7df8988f.arrow\n","[INFO|trainer.py:2407] 2025-03-24 15:48:05,776 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-24 15:48:05,776 >>   Num examples = 8,000\n","[INFO|trainer.py:2409] 2025-03-24 15:48:05,776 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-24 15:48:05,776 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-24 15:48:05,776 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-24 15:48:05,776 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-24 15:48:05,776 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-24 15:48:05,776 >>   Total optimization steps = 3,000\n","[INFO|trainer.py:2416] 2025-03-24 15:48:05,778 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-24 15:48:05,793 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250324_154805-zjr5oxoa\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-8000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/zjr5oxoa\u001b[0m\n","  0% 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.3621, 'grad_norm': 8.457220077514648, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 500/3000 [06:06<30:17,  1.38it/s][INFO|trainer.py:3944] 2025-03-24 15:54:13,498 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-24 15:54:13,505 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 15:54:13,506 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 15:54:25,004 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 15:54:25,008 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 15:54:25,009 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 15:54:25,009 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.8407, 'grad_norm': 9.071094512939453, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 1000/3000 [12:43<24:41,  1.35it/s][INFO|trainer.py:3944] 2025-03-24 16:00:50,004 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-24 16:00:50,009 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:00:50,010 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:01:01,536 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:01:01,541 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:01:01,541 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:01:01,542 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0429, 'grad_norm': 8.176770210266113, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 1500/3000 [19:17<18:18,  1.37it/s][INFO|trainer.py:3944] 2025-03-24 16:07:24,307 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-24 16:07:24,310 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:07:24,311 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:07:35,807 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:07:35,812 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:07:35,812 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:07:35,813 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9449, 'grad_norm': 9.169672012329102, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 2000/3000 [25:53<11:47,  1.41it/s][INFO|trainer.py:3944] 2025-03-24 16:13:59,914 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-24 16:13:59,923 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:13:59,924 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:14:11,461 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:14:11,465 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:14:11,466 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:14:11,466 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4138, 'grad_norm': 8.797719955444336, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 2500/3000 [32:26<06:00,  1.39it/s][INFO|trainer.py:3944] 2025-03-24 16:20:33,110 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-24 16:20:33,115 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:20:33,116 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:20:44,611 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:20:44,614 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:20:44,615 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:20:44,615 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3627, 'grad_norm': 6.994338512420654, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 3000/3000 [39:03<00:00,  1.35it/s][INFO|trainer.py:3944] 2025-03-24 16:27:10,038 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-24 16:27:10,041 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:27:10,042 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:27:21,574 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:27:21,579 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:27:21,580 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:27:21,580 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/checkpoint-3000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-24 16:27:39,754 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2373.9765, 'train_samples_per_second': 10.11, 'train_steps_per_second': 1.264, 'train_loss': 3.1611649983723957, 'epoch': 3.0}\n","100% 3000/3000 [39:33<00:00,  1.26it/s]\n","[INFO|trainer.py:3944] 2025-03-24 16:27:39,762 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-8000\n","[INFO|configuration_utils.py:423] 2025-03-24 16:27:39,849 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:27:39,850 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:27:51,303 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:27:51,306 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:27:51,306 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:27:51,307 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-8000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  1672691GF\n","  train_loss               =     3.1612\n","  train_runtime            = 0:39:33.97\n","  train_samples            =       8000\n","  train_samples_per_second =      10.11\n","  train_steps_per_second   =      1.264\n","03/24/2025 16:27:51 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-24 16:27:51,450 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-24 16:27:51,450 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-24 16:27:51,450 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:13<00:00,  4.43s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     5.3249\n","  eval_chrf               =     34.754\n","  eval_gen_len            =    46.2387\n","  eval_loss               =     2.9513\n","  eval_runtime            = 0:09:19.31\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.783\n","  eval_steps_per_second   =      0.223\n","03/24/2025 16:37:10 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-24 16:37:10,774 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-24 16:37:10,774 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-24 16:37:10,775 >>   Batch size = 8\n","100% 127/127 [09:58<00:00,  4.71s/it]\n","***** predict metrics *****\n","  predict_bleu               =     4.8876\n","  predict_chrf               =    34.3485\n","  predict_gen_len            =    48.1611\n","  predict_loss               =     3.0137\n","  predict_runtime            = 0:10:04.74\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.673\n","  predict_steps_per_second   =       0.21\n","[INFO|modelcard.py:449] 2025-03-24 16:47:31,327 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 5.3249}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_8000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-8000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":40},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1742834858561,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"sCFvQq0b1sWB","outputId":"dd633172-28b0-4e5c-f06c-1a4d77405744"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b0e028ec280>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-8000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5607920,"status":"ok","timestamp":1742840474639,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"Anml0GjD1sU5","outputId":"49d4f8d0-c902-46dc-d9eb-ead4f8c7847d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-24 16:47:52.748131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-24 16:47:52.769848: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-24 16:47:52.776215: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-24 16:47:52.792682: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-24 16:47:53.846867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/24/2025 16:47:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/24/2025 16:47:58 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-8000/runs/Mar24_16-47-58_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-8000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-8000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-3a356ec34b2797b9\n","03/24/2025 16:47:58 - INFO - datasets.builder - Using custom data configuration default-3a356ec34b2797b9\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/24/2025 16:47:58 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/24/2025 16:47:58 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/24/2025 16:47:58 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/24/2025 16:47:58 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/24/2025 16:47:58 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/24/2025 16:47:58 - INFO - datasets.builder - Generating train split\n","Generating train split: 13737 examples [00:00, 358315.63 examples/s]\n","Generating validation split\n","03/24/2025 16:47:58 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 219121.83 examples/s]\n","Generating test split\n","03/24/2025 16:47:58 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 215059.82 examples/s]\n","Unable to verify splits sizes.\n","03/24/2025 16:47:58 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/24/2025 16:47:58 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-24 16:47:58,931 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 16:47:58,934 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-24 16:47:59,020 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 16:47:59,021 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 16:47:59,021 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-24 16:47:59,022 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 16:47:59,022 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-24 16:47:59,950 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-24 16:48:00,046 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-24 16:48:00,069 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-24 16:48:00,151 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-24 16:48:00,152 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-24 16:48:00,246 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-24 16:48:00,246 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-24 16:48:00,443 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/13737 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-53bb8f4edfeb1a46.arrow\n","03/24/2025 16:48:02 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-53bb8f4edfeb1a46.arrow\n","Running tokenizer on train dataset: 100% 13737/13737 [00:05<00:00, 2386.03 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9af310ba714072a1.arrow\n","03/24/2025 16:48:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9af310ba714072a1.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1914.40 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-710fb297dc06ba2d.arrow\n","03/24/2025 16:48:11 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-3a356ec34b2797b9/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-710fb297dc06ba2d.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1853.13 examples/s]\n","[INFO|trainer.py:2407] 2025-03-24 16:48:21,207 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-24 16:48:21,208 >>   Num examples = 13,737\n","[INFO|trainer.py:2409] 2025-03-24 16:48:21,208 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-24 16:48:21,208 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-24 16:48:21,208 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-24 16:48:21,208 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-24 16:48:21,208 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-24 16:48:21,208 >>   Total optimization steps = 5,154\n","[INFO|trainer.py:2416] 2025-03-24 16:48:21,209 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-24 16:48:21,214 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250324_164821-lisvz4vg\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-8000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/lisvz4vg\u001b[0m\n","  0% 0/5154 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.0866, 'grad_norm': 7.590505599975586, 'learning_rate': 4.514939852541715e-05, 'epoch': 0.29}\n"," 10% 500/5154 [06:53<1:00:37,  1.28it/s][INFO|trainer.py:3944] 2025-03-24 16:55:15,685 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-24 16:55:15,695 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 16:55:15,695 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 16:55:20,562 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 16:55:20,565 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 16:55:20,566 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 16:55:20,566 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.4869, 'grad_norm': 6.757532596588135, 'learning_rate': 4.02987970508343e-05, 'epoch': 0.58}\n"," 19% 1000/5154 [13:58<53:53,  1.28it/s][INFO|trainer.py:3944] 2025-03-24 17:02:20,913 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-24 17:02:20,915 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:02:20,916 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:02:25,789 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:02:25,791 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:02:25,792 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:02:25,792 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.2102, 'grad_norm': 5.204808235168457, 'learning_rate': 3.544819557625146e-05, 'epoch': 0.87}\n"," 29% 1500/5154 [21:08<49:33,  1.23it/s][INFO|trainer.py:3944] 2025-03-24 17:09:30,460 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-24 17:09:30,463 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:09:30,463 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:09:35,336 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:09:35,338 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:09:35,339 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:09:35,339 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7638, 'grad_norm': 6.48525333404541, 'learning_rate': 3.059759410166861e-05, 'epoch': 1.16}\n"," 39% 2000/5154 [28:18<43:22,  1.21it/s][INFO|trainer.py:3944] 2025-03-24 17:16:40,788 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-24 17:16:40,790 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:16:40,791 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:16:45,659 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:16:45,661 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:16:45,662 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:16:45,662 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5135, 'grad_norm': 5.433412075042725, 'learning_rate': 2.574699262708576e-05, 'epoch': 1.46}\n"," 49% 2500/5154 [35:27<36:50,  1.20it/s][INFO|trainer.py:3944] 2025-03-24 17:23:49,727 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-24 17:23:49,729 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:23:49,730 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:23:54,615 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:23:54,620 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:23:54,620 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:23:54,621 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4595, 'grad_norm': 6.525064945220947, 'learning_rate': 2.0896391152502913e-05, 'epoch': 1.75}\n"," 58% 3000/5154 [42:37<29:41,  1.21it/s][INFO|trainer.py:3944] 2025-03-24 17:30:59,238 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-24 17:30:59,240 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:30:59,241 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:31:04,157 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:31:04,160 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:31:04,161 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:31:04,161 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3655, 'grad_norm': 5.001039505004883, 'learning_rate': 1.6045789677920063e-05, 'epoch': 2.04}\n"," 68% 3500/5154 [49:46<23:17,  1.18it/s][INFO|trainer.py:3944] 2025-03-24 17:38:08,262 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-24 17:38:08,264 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:38:08,265 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:38:13,157 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:38:13,160 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:38:13,161 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:38:13,161 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0179, 'grad_norm': 6.524746894836426, 'learning_rate': 1.1195188203337214e-05, 'epoch': 2.33}\n"," 78% 4000/5154 [56:55<15:40,  1.23it/s][INFO|trainer.py:3944] 2025-03-24 17:45:17,679 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-24 17:45:17,681 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:45:17,681 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:45:22,611 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:45:22,614 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:45:22,615 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:45:22,615 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9669, 'grad_norm': 5.724503993988037, 'learning_rate': 6.344586728754366e-06, 'epoch': 2.62}\n"," 87% 4500/5154 [1:04:03<08:31,  1.28it/s][INFO|trainer.py:3944] 2025-03-24 17:52:25,973 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-24 17:52:25,975 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:52:25,976 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:52:30,886 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:52:30,889 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:52:30,890 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:52:30,890 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9482, 'grad_norm': 7.143683433532715, 'learning_rate': 1.4939852541715173e-06, 'epoch': 2.91}\n"," 97% 5000/5154 [1:11:13<02:09,  1.19it/s][INFO|trainer.py:3944] 2025-03-24 17:59:35,869 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-24 17:59:35,871 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 17:59:35,872 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 17:59:40,710 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 17:59:40,713 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 17:59:40,714 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 17:59:40,714 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 5154/5154 [1:13:37<00:00,  1.54it/s][INFO|trainer.py:3944] 2025-03-24 18:01:59,708 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154\n","[INFO|configuration_utils.py:423] 2025-03-24 18:01:59,710 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 18:01:59,711 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 18:02:04,739 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 18:02:04,742 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 18:02:04,742 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 18:02:04,743 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/checkpoint-5154/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-24 18:02:18,642 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 4437.4334, 'train_samples_per_second': 9.287, 'train_steps_per_second': 1.161, 'train_loss': 2.66027265377733, 'epoch': 3.0}\n","100% 5154/5154 [1:13:56<00:00,  1.16it/s]\n","[INFO|trainer.py:3944] 2025-03-24 18:02:18,653 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-8000\n","[INFO|configuration_utils.py:423] 2025-03-24 18:02:18,655 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 18:02:18,655 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 18:02:27,607 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 18:02:27,612 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 18:02:27,613 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 18:02:27,613 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-8000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  4774172GF\n","  train_loss               =     2.6603\n","  train_runtime            = 1:13:57.43\n","  train_samples            =      13737\n","  train_samples_per_second =      9.287\n","  train_steps_per_second   =      1.161\n","03/24/2025 18:02:27 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-24 18:02:27,758 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-24 18:02:27,758 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-24 18:02:27,758 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [08:39<00:00,  4.15s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =      8.703\n","  eval_chrf               =    44.9152\n","  eval_gen_len            =    46.2808\n","  eval_loss               =     2.2373\n","  eval_runtime            = 0:08:45.56\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.897\n","  eval_steps_per_second   =      0.238\n","03/24/2025 18:11:13 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-24 18:11:13,334 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-24 18:11:13,334 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-24 18:11:13,334 >>   Batch size = 8\n","100% 127/127 [09:34<00:00,  4.53s/it]\n","***** predict metrics *****\n","  predict_bleu               =      8.262\n","  predict_chrf               =    44.2729\n","  predict_gen_len            =     48.163\n","  predict_loss               =     2.2844\n","  predict_runtime            = 0:09:42.34\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.738\n","  predict_steps_per_second   =      0.218\n","[INFO|modelcard.py:449] 2025-03-24 18:21:11,197 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 8.703}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_8000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-8000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"id":"E1xlYKIs-cgb","executionInfo":{"status":"ok","timestamp":1743363007373,"user_tz":-120,"elapsed":4859,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"18647671-8d25-407b-e8b9-34020ce4e1ce"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/9bxwgip2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b679423d7e0>"]},"metadata":{},"execution_count":15}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-8000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7uSLk6YU-cgc","executionInfo":{"status":"ok","timestamp":1743366742030,"user_tz":-120,"elapsed":2737724,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"ec82ac15-7ba9-4af0-dea3-d00b4240e49e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-30 19:30:07.487148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-30 19:30:07.509697: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-30 19:30:07.516270: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-30 19:30:07.534927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-30 19:30:08.633777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/30/2025 19:30:11 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/30/2025 19:30:11 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-8000/runs/Mar30_19-30-11_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-8000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-8000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-9aab351d98ca9ad1\n","03/30/2025 19:30:12 - INFO - datasets.builder - Using custom data configuration default-9aab351d98ca9ad1\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/30/2025 19:30:12 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/30/2025 19:30:12 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/30/2025 19:30:12 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/30/2025 19:30:12 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/30/2025 19:30:12 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/30/2025 19:30:12 - INFO - datasets.builder - Generating train split\n","Generating train split: 8000 examples [00:00, 537257.74 examples/s]\n","Generating validation split\n","03/30/2025 19:30:12 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 154930.20 examples/s]\n","Generating test split\n","03/30/2025 19:30:12 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 236839.40 examples/s]\n","Unable to verify splits sizes.\n","03/30/2025 19:30:12 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/30/2025 19:30:12 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-30 19:30:12,288 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 19:30:12,289 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-30 19:30:13,071 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 19:30:13,072 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-30 19:30:13,073 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-30 19:30:13,073 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-30 19:30:13,074 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-30 19:30:13,960 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-30 19:30:14,024 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-30 19:30:14,122 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-30 19:30:14,122 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-30 19:30:14,203 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-30 19:30:14,204 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-30 19:30:14,767 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-30 19:30:15,336 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/8000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-284569fb64245418.arrow\n","03/30/2025 19:30:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-284569fb64245418.arrow\n","Running tokenizer on train dataset: 100% 8000/8000 [00:02<00:00, 3403.54 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8772d3ed20e80e28.arrow\n","03/30/2025 19:30:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-8772d3ed20e80e28.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1823.68 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23050beb2d5ee8c4.arrow\n","03/30/2025 19:30:21 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-9aab351d98ca9ad1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-23050beb2d5ee8c4.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1781.62 examples/s]\n","[INFO|trainer.py:2407] 2025-03-30 19:30:24,724 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-30 19:30:24,724 >>   Num examples = 8,000\n","[INFO|trainer.py:2409] 2025-03-30 19:30:24,724 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-30 19:30:24,724 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-30 19:30:24,724 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-30 19:30:24,724 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-30 19:30:24,724 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-30 19:30:24,724 >>   Total optimization steps = 3,000\n","[INFO|trainer.py:2416] 2025-03-30 19:30:24,725 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-30 19:30:24,730 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250330_193024-dxkpukll\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-8000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/dxkpukll\u001b[0m\n","  0% 0/3000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.6444, 'grad_norm': 7.45421028137207, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 500/3000 [06:08<30:35,  1.36it/s][INFO|trainer.py:3944] 2025-03-30 19:36:33,808 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-30 19:36:33,811 >> Configuration saved in M2M-100/random-8000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:36:33,812 >> Configuration saved in M2M-100/random-8000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:36:38,715 >> Model weights saved in M2M-100/random-8000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:36:38,718 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:36:38,718 >> Special tokens file saved in M2M-100/random-8000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:36:38,719 >> added tokens file saved in M2M-100/random-8000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.2111, 'grad_norm': 8.110698699951172, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 1000/3000 [12:33<24:31,  1.36it/s][INFO|trainer.py:3944] 2025-03-30 19:42:58,965 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-30 19:42:58,966 >> Configuration saved in M2M-100/random-8000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:42:58,967 >> Configuration saved in M2M-100/random-8000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:43:03,985 >> Model weights saved in M2M-100/random-8000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:43:03,988 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:43:03,989 >> Special tokens file saved in M2M-100/random-8000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:43:03,989 >> added tokens file saved in M2M-100/random-8000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.4312, 'grad_norm': 9.04136848449707, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 1500/3000 [18:58<18:13,  1.37it/s][INFO|trainer.py:3944] 2025-03-30 19:49:24,325 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-30 19:49:24,327 >> Configuration saved in M2M-100/random-8000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:49:24,327 >> Configuration saved in M2M-100/random-8000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:49:29,291 >> Model weights saved in M2M-100/random-8000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:49:29,294 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:49:29,294 >> Special tokens file saved in M2M-100/random-8000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:49:29,295 >> added tokens file saved in M2M-100/random-8000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.3026, 'grad_norm': 8.385252952575684, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 2000/3000 [25:23<12:10,  1.37it/s][INFO|trainer.py:3944] 2025-03-30 19:55:49,223 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-30 19:55:49,226 >> Configuration saved in M2M-100/random-8000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 19:55:49,227 >> Configuration saved in M2M-100/random-8000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 19:55:54,191 >> Model weights saved in M2M-100/random-8000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 19:55:54,194 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 19:55:54,194 >> Special tokens file saved in M2M-100/random-8000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 19:55:54,195 >> added tokens file saved in M2M-100/random-8000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.751, 'grad_norm': 9.6151762008667, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 2500/3000 [31:48<06:00,  1.39it/s][INFO|trainer.py:3944] 2025-03-30 20:02:13,916 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-30 20:02:13,918 >> Configuration saved in M2M-100/random-8000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 20:02:13,918 >> Configuration saved in M2M-100/random-8000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 20:02:18,850 >> Model weights saved in M2M-100/random-8000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 20:02:18,853 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 20:02:18,854 >> Special tokens file saved in M2M-100/random-8000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 20:02:18,854 >> added tokens file saved in M2M-100/random-8000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.6934, 'grad_norm': 6.1227006912231445, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 3000/3000 [38:14<00:00,  1.32it/s][INFO|trainer.py:3944] 2025-03-30 20:08:39,886 >> Saving model checkpoint to M2M-100/random-8000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-30 20:08:39,888 >> Configuration saved in M2M-100/random-8000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 20:08:39,889 >> Configuration saved in M2M-100/random-8000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 20:08:44,911 >> Model weights saved in M2M-100/random-8000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 20:08:44,914 >> tokenizer config file saved in M2M-100/random-8000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 20:08:44,914 >> Special tokens file saved in M2M-100/random-8000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 20:08:44,915 >> added tokens file saved in M2M-100/random-8000/checkpoint-3000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-30 20:08:58,509 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2313.7846, 'train_samples_per_second': 10.373, 'train_steps_per_second': 1.297, 'train_loss': 3.5056163330078123, 'epoch': 3.0}\n","100% 3000/3000 [38:32<00:00,  1.30it/s]\n","[INFO|trainer.py:3944] 2025-03-30 20:08:58,522 >> Saving model checkpoint to M2M-100/random-8000\n","[INFO|configuration_utils.py:423] 2025-03-30 20:08:58,524 >> Configuration saved in M2M-100/random-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-30 20:08:58,524 >> Configuration saved in M2M-100/random-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-30 20:09:07,477 >> Model weights saved in M2M-100/random-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-30 20:09:07,481 >> tokenizer config file saved in M2M-100/random-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-30 20:09:07,481 >> Special tokens file saved in M2M-100/random-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-30 20:09:07,482 >> added tokens file saved in M2M-100/random-8000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  1615391GF\n","  train_loss               =     3.5056\n","  train_runtime            = 0:38:33.78\n","  train_samples            =       8000\n","  train_samples_per_second =     10.373\n","  train_steps_per_second   =      1.297\n","03/30/2025 20:09:07 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-30 20:09:07,634 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-30 20:09:07,634 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-30 20:09:07,634 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [11:10<00:00,  5.36s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     4.2801\n","  eval_chrf               =    30.0596\n","  eval_gen_len            =    50.9358\n","  eval_loss               =     3.0828\n","  eval_runtime            = 0:11:15.98\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.475\n","  eval_steps_per_second   =      0.185\n","03/30/2025 20:20:23 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-30 20:20:23,629 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-30 20:20:23,629 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-30 20:20:23,629 >>   Batch size = 8\n","100% 127/127 [11:31<00:00,  5.44s/it]\n","***** predict metrics *****\n","  predict_bleu               =      3.464\n","  predict_chrf               =    29.5816\n","  predict_gen_len            =    52.4625\n","  predict_loss               =     3.1333\n","  predict_runtime            = 0:11:39.27\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.447\n","  predict_steps_per_second   =      0.182\n","[INFO|modelcard.py:449] 2025-03-30 20:32:18,831 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 4.2801}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_8000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-8000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":40},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1742841373006,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"50vt5hMgup68","outputId":"c15b6840-cc17-4795-9c5e-cd665ff7e771"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/mgk6bytk?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7b0e028ec280>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-16000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6040345,"status":"ok","timestamp":1742854293687,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"mlfAMTxMtvOi","outputId":"c4b6c114-bc82-417b-b43b-414cff0bfb11"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-24 20:30:59.240818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-24 20:30:59.262569: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-24 20:30:59.269096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-24 20:30:59.285716: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-24 20:31:00.377607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/24/2025 20:31:05 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/24/2025 20:31:05 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-16000/runs/Mar24_20-31-04_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-16000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-16000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-8dd97eb64194ed63\n","03/24/2025 20:31:05 - INFO - datasets.builder - Using custom data configuration default-8dd97eb64194ed63\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/24/2025 20:31:05 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/24/2025 20:31:05 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/24/2025 20:31:05 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/24/2025 20:31:05 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/24/2025 20:31:05 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-24 20:31:05,437 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 20:31:05,440 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-24 20:31:05,536 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 20:31:05,537 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,537 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,537 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,537 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,537 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,537 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,538 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-24 20:31:05,538 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-24 20:31:05,538 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-24 20:31:05,539 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-24 20:31:06,479 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-24 20:31:06,543 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-24 20:31:06,599 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-24 20:31:06,653 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-24 20:31:06,653 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-24 20:31:06,753 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-24 20:31:06,753 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4f73fd23cbbc2044.arrow\n","03/24/2025 20:31:08 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4f73fd23cbbc2044.arrow\n","[INFO|safetensors_conversion.py:74] 2025-03-24 20:31:08,156 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-61f573cc25eca874.arrow\n","03/24/2025 20:31:09 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-61f573cc25eca874.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-29c03a83c2242779.arrow\n","03/24/2025 20:31:10 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-8dd97eb64194ed63/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-29c03a83c2242779.arrow\n","[INFO|trainer.py:2407] 2025-03-24 20:31:20,529 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-24 20:31:20,529 >>   Num examples = 16,000\n","[INFO|trainer.py:2409] 2025-03-24 20:31:20,529 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-24 20:31:20,529 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-24 20:31:20,529 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-24 20:31:20,529 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-24 20:31:20,529 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-24 20:31:20,529 >>   Total optimization steps = 6,000\n","[INFO|trainer.py:2416] 2025-03-24 20:31:20,530 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-24 20:31:20,535 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250324_203120-9plrl2t2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-16000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/9plrl2t2\u001b[0m\n","  0% 0/6000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.4095, 'grad_norm': 7.838458061218262, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.25}\n","  8% 500/6000 [06:06<1:05:05,  1.41it/s][INFO|trainer.py:3944] 2025-03-24 20:37:27,987 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-24 20:37:27,993 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 20:37:27,994 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 20:37:39,577 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 20:37:39,581 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 20:37:39,581 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 20:37:39,582 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.8933, 'grad_norm': 7.528745174407959, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 1000/6000 [12:44<1:03:40,  1.31it/s][INFO|trainer.py:3944] 2025-03-24 20:44:05,802 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-24 20:44:05,804 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 20:44:05,805 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 20:44:17,372 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 20:44:17,377 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 20:44:17,377 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 20:44:17,378 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.595, 'grad_norm': 7.852253437042236, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.75}\n"," 25% 1500/6000 [19:19<55:10,  1.36it/s][INFO|trainer.py:3944] 2025-03-24 20:50:40,695 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-24 20:50:40,697 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 20:50:40,698 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 20:50:52,293 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 20:50:52,296 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 20:50:52,297 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 20:50:52,297 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.4125, 'grad_norm': 7.076495170593262, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 2000/6000 [25:56<49:34,  1.34it/s][INFO|trainer.py:3944] 2025-03-24 20:57:18,139 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-24 20:57:18,141 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 20:57:18,142 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 20:57:30,080 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 20:57:30,085 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 20:57:30,085 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 20:57:30,086 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8227, 'grad_norm': 7.7632927894592285, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n"," 42% 2500/6000 [32:32<42:15,  1.38it/s][INFO|trainer.py:3944] 2025-03-24 21:03:54,185 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-24 21:03:54,187 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:03:54,187 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:04:05,824 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:04:05,828 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:04:05,829 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:04:05,829 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7638, 'grad_norm': 5.975804805755615, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 3000/6000 [39:09<36:57,  1.35it/s][INFO|trainer.py:3944] 2025-03-24 21:10:30,609 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-24 21:10:30,611 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:10:30,612 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:10:42,195 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:10:42,200 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:10:42,200 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:10:42,201 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7293, 'grad_norm': 8.255613327026367, 'learning_rate': 2.0833333333333336e-05, 'epoch': 1.75}\n"," 58% 3500/6000 [45:46<30:21,  1.37it/s][INFO|trainer.py:3944] 2025-03-24 21:17:08,004 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-24 21:17:08,006 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:17:08,006 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:17:19,577 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:17:19,581 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:17:19,582 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:17:19,582 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.6633, 'grad_norm': 6.3068084716796875, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 4000/6000 [52:21<25:20,  1.32it/s][INFO|trainer.py:3944] 2025-03-24 21:23:42,892 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-24 21:23:42,893 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:23:42,894 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:23:54,487 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:23:54,491 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:23:54,492 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:23:54,492 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.2192, 'grad_norm': 6.925149440765381, 'learning_rate': 1.25e-05, 'epoch': 2.25}\n"," 75% 4500/6000 [58:58<18:14,  1.37it/s][INFO|trainer.py:3944] 2025-03-24 21:30:19,677 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-24 21:30:19,679 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:30:19,680 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:30:31,315 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:30:31,320 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:30:31,320 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:30:31,321 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.1985, 'grad_norm': 7.397052764892578, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 5000/6000 [1:05:35<12:11,  1.37it/s][INFO|trainer.py:3944] 2025-03-24 21:36:56,410 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-24 21:36:56,412 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:36:56,413 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:37:07,989 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:37:07,993 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:37:07,994 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:37:07,994 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.1924, 'grad_norm': 6.54964542388916, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.75}\n"," 92% 5500/6000 [1:12:10<05:54,  1.41it/s][INFO|trainer.py:3944] 2025-03-24 21:43:32,040 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-24 21:43:32,042 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:43:32,043 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:43:43,613 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:43:43,617 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:43:43,617 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:43:43,618 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.133, 'grad_norm': 7.093844413757324, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 6000/6000 [1:18:46<00:00,  1.37it/s][INFO|trainer.py:3944] 2025-03-24 21:50:08,325 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-24 21:50:08,327 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:50:08,328 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:50:19,860 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:50:19,864 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:50:19,865 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:50:19,865 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/checkpoint-6000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-24 21:50:37,813 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 4757.283, 'train_samples_per_second': 10.09, 'train_steps_per_second': 1.261, 'train_loss': 2.9193775431315103, 'epoch': 3.0}\n","100% 6000/6000 [1:19:16<00:00,  1.26it/s]\n","[INFO|trainer.py:3944] 2025-03-24 21:50:37,826 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-16000\n","[INFO|configuration_utils.py:423] 2025-03-24 21:50:37,874 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-24 21:50:37,875 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-16000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-24 21:50:49,389 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-16000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-24 21:50:49,392 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-24 21:50:49,393 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-24 21:50:49,393 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-16000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3307792GF\n","  train_loss               =     2.9194\n","  train_runtime            = 1:19:17.28\n","  train_samples            =      16000\n","  train_samples_per_second =      10.09\n","  train_steps_per_second   =      1.261\n","03/24/2025 21:50:49 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-24 21:50:49,539 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-24 21:50:49,539 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-24 21:50:49,540 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [10:05<00:00,  4.84s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =      6.828\n","  eval_chrf               =    39.3323\n","  eval_gen_len            =    47.6409\n","  eval_loss               =     2.5585\n","  eval_runtime            = 0:10:12.76\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.627\n","  eval_steps_per_second   =      0.204\n","03/24/2025 22:01:02 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-24 22:01:02,309 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-24 22:01:02,309 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-24 22:01:02,309 >>   Batch size = 8\n","100% 127/127 [10:05<00:00,  4.77s/it]\n","***** predict metrics *****\n","  predict_bleu               =     6.6496\n","  predict_chrf               =    39.2591\n","  predict_gen_len            =    48.7925\n","  predict_loss               =     2.6011\n","  predict_runtime            = 0:10:11.78\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.654\n","  predict_steps_per_second   =      0.208\n","[INFO|modelcard.py:449] 2025-03-24 22:11:30,043 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 6.828}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_16000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-16000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"elapsed":11866,"status":"ok","timestamp":1742911736304,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"XBleg4H92hdW","outputId":"c303b375-be90-43c3-fe3c-b380203f7d14"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250325_140850-izuqi7qg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg' target=\"_blank\">africomet-plus-16000</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eaef1840460>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-16000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7831119,"status":"ok","timestamp":1742919567410,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"gKyoQfzk2hcC","outputId":"94054959-4b8b-4cc0-8724-96461f72876d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-25 14:09:03.795306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-25 14:09:03.834865: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-25 14:09:03.847835: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-25 14:09:03.870450: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-25 14:09:05.011393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/25/2025 14:09:10 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/25/2025 14:09:10 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-16000/runs/Mar25_14-09-10_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-16000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-16000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-378fdd38804a47f4\n","03/25/2025 14:09:11 - INFO - datasets.builder - Using custom data configuration default-378fdd38804a47f4\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/25/2025 14:09:11 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/25/2025 14:09:11 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/25/2025 14:09:11 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/25/2025 14:09:11 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/25/2025 14:09:11 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/25/2025 14:09:11 - INFO - datasets.builder - Generating train split\n","Generating train split: 21737 examples [00:00, 312235.74 examples/s]\n","Generating validation split\n","03/25/2025 14:09:11 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 216366.80 examples/s]\n","Generating test split\n","03/25/2025 14:09:11 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 227582.20 examples/s]\n","Unable to verify splits sizes.\n","03/25/2025 14:09:11 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/25/2025 14:09:11 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-25 14:09:11,566 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 14:09:11,569 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-25 14:09:11,662 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 14:09:11,663 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 14:09:11,665 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-25 14:09:11,666 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 14:09:11,667 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-25 14:09:12,644 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-25 14:09:13,335 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|modeling_utils.py:4972] 2025-03-25 14:09:13,508 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-25 14:09:13,508 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-25 14:09:13,603 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-25 14:09:13,603 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-25 14:09:13,839 >> Attempting to create safetensors variant\n","[INFO|safetensors_conversion.py:74] 2025-03-25 14:09:14,339 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/21737 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-369fa5a20b3bb9bf.arrow\n","03/25/2025 14:09:15 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-369fa5a20b3bb9bf.arrow\n","Running tokenizer on train dataset: 100% 21737/21737 [00:08<00:00, 2537.58 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-ae57c68f2106ee19.arrow\n","03/25/2025 14:09:25 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-ae57c68f2106ee19.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1714.77 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c153cad90fccc4f5.arrow\n","03/25/2025 14:09:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-378fdd38804a47f4/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-c153cad90fccc4f5.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1741.90 examples/s]\n","[INFO|trainer.py:2407] 2025-03-25 14:09:37,563 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-25 14:09:37,563 >>   Num examples = 21,737\n","[INFO|trainer.py:2409] 2025-03-25 14:09:37,563 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-25 14:09:37,563 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-25 14:09:37,563 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-25 14:09:37,563 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-25 14:09:37,563 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-25 14:09:37,563 >>   Total optimization steps = 8,154\n","[INFO|trainer.py:2416] 2025-03-25 14:09:37,564 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-25 14:09:37,570 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250325_140937-wssz3oc8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-16000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/wssz3oc8\u001b[0m\n","  0% 0/8154 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.1998, 'grad_norm': 8.517952919006348, 'learning_rate': 4.6934020112828065e-05, 'epoch': 0.18}\n","  6% 500/8154 [06:30<1:34:11,  1.35it/s][INFO|trainer.py:3944] 2025-03-25 14:16:08,491 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-25 14:16:08,497 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:16:08,498 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:16:13,665 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:16:13,668 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:16:13,669 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:16:13,669 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.6407, 'grad_norm': 10.210153579711914, 'learning_rate': 4.386804022565612e-05, 'epoch': 0.37}\n"," 12% 1000/8154 [13:20<1:33:30,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 14:22:58,713 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-25 14:22:58,715 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:22:58,716 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:23:03,627 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:23:03,630 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:23:03,630 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:23:03,631 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.393, 'grad_norm': 6.730628490447998, 'learning_rate': 4.080206033848418e-05, 'epoch': 0.55}\n"," 18% 1500/8154 [20:09<1:19:15,  1.40it/s][INFO|trainer.py:3944] 2025-03-25 14:29:48,091 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-25 14:29:48,093 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:29:48,094 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:29:52,925 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:29:52,928 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:29:52,928 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:29:52,929 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1976, 'grad_norm': 8.2925386428833, 'learning_rate': 3.773608045131224e-05, 'epoch': 0.74}\n"," 25% 2000/8154 [26:56<1:15:08,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 14:36:34,573 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-25 14:36:34,575 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:36:34,575 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:36:39,578 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:36:39,584 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:36:39,586 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:36:39,586 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0706, 'grad_norm': 7.903889179229736, 'learning_rate': 3.46701005641403e-05, 'epoch': 0.92}\n"," 31% 2500/8154 [33:43<1:10:12,  1.34it/s][INFO|trainer.py:3944] 2025-03-25 14:43:22,230 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-25 14:43:22,232 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:43:22,233 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:43:27,092 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:43:27,095 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:43:27,095 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:43:27,096 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7313, 'grad_norm': 6.11224889755249, 'learning_rate': 3.160412067696836e-05, 'epoch': 1.1}\n"," 37% 3000/8154 [40:28<1:07:18,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 14:50:06,846 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-25 14:50:06,848 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:50:06,849 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:50:11,710 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:50:11,714 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:50:11,715 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:50:11,715 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5117, 'grad_norm': 6.583982467651367, 'learning_rate': 2.853814078979642e-05, 'epoch': 1.29}\n"," 43% 3500/8154 [47:14<58:55,  1.32it/s][INFO|trainer.py:3944] 2025-03-25 14:56:53,283 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-25 14:56:53,285 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 14:56:53,285 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 14:56:58,125 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 14:56:58,128 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 14:56:58,129 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 14:56:58,129 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4415, 'grad_norm': 6.475767612457275, 'learning_rate': 2.5472160902624482e-05, 'epoch': 1.47}\n"," 49% 4000/8154 [54:00<53:53,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 15:03:39,271 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-25 15:03:39,272 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:03:39,273 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:03:44,157 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:03:44,161 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:03:44,162 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:03:44,162 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4201, 'grad_norm': 6.162585735321045, 'learning_rate': 2.240618101545254e-05, 'epoch': 1.66}\n"," 55% 4500/8154 [1:00:52<46:53,  1.30it/s][INFO|trainer.py:3944] 2025-03-25 15:10:30,659 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-25 15:10:30,660 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:10:30,661 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:10:35,584 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:10:35,587 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:10:35,587 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:10:35,588 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.386, 'grad_norm': 6.274016857147217, 'learning_rate': 1.93402011282806e-05, 'epoch': 1.84}\n"," 61% 5000/8154 [1:07:42<42:07,  1.25it/s][INFO|trainer.py:3944] 2025-03-25 15:17:21,234 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-25 15:17:21,236 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:17:21,237 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:17:26,147 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:17:26,149 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:17:26,150 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:17:26,150 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.2919, 'grad_norm': 6.371399402618408, 'learning_rate': 1.627422124110866e-05, 'epoch': 2.02}\n"," 67% 5500/8154 [1:14:31<33:23,  1.32it/s][INFO|trainer.py:3944] 2025-03-25 15:24:09,536 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-25 15:24:09,537 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:24:09,538 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:24:14,427 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:24:14,431 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:24:14,432 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:24:14,432 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9772, 'grad_norm': 6.803675651550293, 'learning_rate': 1.3208241353936717e-05, 'epoch': 2.21}\n"," 74% 6000/8154 [1:21:23<29:54,  1.20it/s][INFO|trainer.py:3944] 2025-03-25 15:31:01,731 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-25 15:31:01,733 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:31:01,734 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:31:06,638 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:31:06,641 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:31:06,641 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:31:06,641 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9646, 'grad_norm': 5.226804733276367, 'learning_rate': 1.0142261466764778e-05, 'epoch': 2.39}\n"," 80% 6500/8154 [1:28:11<23:30,  1.17it/s][INFO|trainer.py:3944] 2025-03-25 15:37:49,931 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500\n","[INFO|configuration_utils.py:423] 2025-03-25 15:37:49,933 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:37:49,934 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:37:54,866 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:37:54,870 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:37:54,871 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:37:54,871 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-6500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.955, 'grad_norm': 7.372836589813232, 'learning_rate': 7.076281579592839e-06, 'epoch': 2.58}\n"," 86% 7000/8154 [1:34:59<16:05,  1.20it/s][INFO|trainer.py:3944] 2025-03-25 15:44:38,215 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000\n","[INFO|configuration_utils.py:423] 2025-03-25 15:44:38,217 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:44:38,218 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:44:43,089 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:44:43,092 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:44:43,093 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:44:43,093 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9332, 'grad_norm': 6.598888397216797, 'learning_rate': 4.0103016924208985e-06, 'epoch': 2.76}\n"," 92% 7500/8154 [1:41:47<08:02,  1.35it/s][INFO|trainer.py:3944] 2025-03-25 15:51:26,116 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500\n","[INFO|configuration_utils.py:423] 2025-03-25 15:51:26,118 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:51:26,118 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:51:31,069 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:51:31,072 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:51:31,073 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:51:31,074 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-7500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9073, 'grad_norm': 6.615671157836914, 'learning_rate': 9.443218052489575e-07, 'epoch': 2.94}\n"," 98% 8000/8154 [1:48:35<02:02,  1.26it/s][INFO|trainer.py:3944] 2025-03-25 15:58:14,327 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000\n","[INFO|configuration_utils.py:423] 2025-03-25 15:58:14,328 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 15:58:14,329 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 15:58:19,260 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 15:58:19,263 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 15:58:19,264 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 15:58:19,264 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 8154/8154 [1:50:53<00:00,  1.61it/s][INFO|trainer.py:3944] 2025-03-25 16:00:31,997 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154\n","[INFO|configuration_utils.py:423] 2025-03-25 16:00:31,999 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:00:32,000 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:00:37,217 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:00:37,221 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:00:37,221 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:00:37,222 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/checkpoint-8154/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-25 16:00:50,903 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 6673.3392, 'train_samples_per_second': 9.772, 'train_steps_per_second': 1.222, 'train_loss': 2.6130231530285655, 'epoch': 3.0}\n","100% 8154/8154 [1:51:12<00:00,  1.22it/s]\n","[INFO|trainer.py:3944] 2025-03-25 16:00:50,911 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-16000\n","[INFO|configuration_utils.py:423] 2025-03-25 16:00:50,913 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:00:50,914 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-16000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:00:59,894 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-16000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:00:59,897 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:00:59,898 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:00:59,898 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-16000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  6691516GF\n","  train_loss               =      2.613\n","  train_runtime            = 1:51:13.33\n","  train_samples            =      21737\n","  train_samples_per_second =      9.772\n","  train_steps_per_second   =      1.222\n","03/25/2025 16:01:00 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-25 16:01:00,053 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-25 16:01:00,054 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-25 16:01:00,054 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [08:45<00:00,  4.20s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     9.8859\n","  eval_chrf               =    47.0916\n","  eval_gen_len            =    45.9188\n","  eval_loss               =     2.0985\n","  eval_runtime            = 0:08:52.54\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.872\n","  eval_steps_per_second   =      0.235\n","03/25/2025 16:09:52 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-25 16:09:52,613 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-25 16:09:52,613 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-25 16:09:52,613 >>   Batch size = 8\n","100% 127/127 [09:09<00:00,  4.32s/it]\n","***** predict metrics *****\n","  predict_bleu               =     9.9987\n","  predict_chrf               =    47.1693\n","  predict_gen_len            =    47.2164\n","  predict_loss               =     2.1239\n","  predict_runtime            = 0:09:15.96\n","  predict_samples            =       1012\n","  predict_samples_per_second =       1.82\n","  predict_steps_per_second   =      0.228\n","[INFO|modelcard.py:449] 2025-03-25 16:19:23,949 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 9.8859}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_16000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-16000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":163},"id":"SlaWlrx1-cgd","executionInfo":{"status":"ok","timestamp":1743402379276,"user_tz":-120,"elapsed":11685,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"da43345a-ea40-4058-c3fa-a33dd138c893"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250331_062613-7ufkjmfg</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/paderborn-university/machine%20translation/runs/7ufkjmfg' target=\"_blank\">random_Zulu-16000</a></strong> to <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/paderborn-university/machine%20translation' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/paderborn-university/machine%20translation/runs/7ufkjmfg' target=\"_blank\">https://wandb.ai/paderborn-university/machine%20translation/runs/7ufkjmfg</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/7ufkjmfg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7d262234c460>"]},"metadata":{},"execution_count":5}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-16000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YMsO6Cm7-cgd","executionInfo":{"status":"ok","timestamp":1743408354561,"user_tz":-120,"elapsed":5975291,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"f8d667e4-cfb1-48b3-8087-24f57a9f3f62"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-31 06:26:22.935211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-31 06:26:22.956320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-31 06:26:22.962795: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-31 06:26:22.978875: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-31 06:26:23.974169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/31/2025 06:26:26 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/31/2025 06:26:26 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-16000/runs/Mar31_06-26-26_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-16000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-16000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-16d26a45df030302\n","03/31/2025 06:26:26 - INFO - datasets.builder - Using custom data configuration default-16d26a45df030302\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/31/2025 06:26:26 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/31/2025 06:26:26 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/31/2025 06:26:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/31/2025 06:26:26 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/31/2025 06:26:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-31 06:26:26,724 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 06:26:26,725 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-31 06:26:26,810 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 06:26:26,811 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 06:26:26,812 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-31 06:26:26,812 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 06:26:26,813 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-31 06:26:27,737 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-31 06:26:27,802 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-31 06:26:27,846 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-31 06:26:27,907 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-31 06:26:27,907 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-31 06:26:27,996 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-31 06:26:27,996 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-31 06:26:28,221 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9779f8177f1ce7e0.arrow\n","03/31/2025 06:26:29 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9779f8177f1ce7e0.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d2aa895a2e7cefa1.arrow\n","03/31/2025 06:26:30 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d2aa895a2e7cefa1.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e55de79c7bdd1130.arrow\n","03/31/2025 06:26:32 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-16d26a45df030302/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e55de79c7bdd1130.arrow\n","[INFO|trainer.py:2407] 2025-03-31 06:26:34,659 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-31 06:26:34,659 >>   Num examples = 16,000\n","[INFO|trainer.py:2409] 2025-03-31 06:26:34,659 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-31 06:26:34,659 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-31 06:26:34,659 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-31 06:26:34,659 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-31 06:26:34,659 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-31 06:26:34,659 >>   Total optimization steps = 6,000\n","[INFO|trainer.py:2416] 2025-03-31 06:26:34,661 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-31 06:26:34,666 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250331_062634-p2woxi35\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-16000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/p2woxi35\u001b[0m\n","  0% 0/6000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.6305, 'grad_norm': 9.240200996398926, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.25}\n","  8% 500/6000 [06:04<1:07:18,  1.36it/s][INFO|trainer.py:3944] 2025-03-31 06:32:39,851 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-31 06:32:39,858 >> Configuration saved in M2M-100/random-16000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 06:32:39,859 >> Configuration saved in M2M-100/random-16000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 06:32:51,271 >> Model weights saved in M2M-100/random-16000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 06:32:51,275 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 06:32:51,275 >> Special tokens file saved in M2M-100/random-16000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 06:32:51,276 >> added tokens file saved in M2M-100/random-16000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.233, 'grad_norm': 7.632014274597168, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 1000/6000 [12:36<58:31,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 06:39:12,155 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-31 06:39:12,159 >> Configuration saved in M2M-100/random-16000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 06:39:12,160 >> Configuration saved in M2M-100/random-16000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 06:39:23,707 >> Model weights saved in M2M-100/random-16000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 06:39:23,710 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 06:39:23,710 >> Special tokens file saved in M2M-100/random-16000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 06:39:23,711 >> added tokens file saved in M2M-100/random-16000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.0114, 'grad_norm': 6.470462799072266, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.75}\n"," 25% 1500/6000 [19:09<57:12,  1.31it/s][INFO|trainer.py:3944] 2025-03-31 06:45:44,520 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-31 06:45:44,524 >> Configuration saved in M2M-100/random-16000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 06:45:44,525 >> Configuration saved in M2M-100/random-16000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 06:45:55,978 >> Model weights saved in M2M-100/random-16000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 06:45:55,982 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 06:45:55,982 >> Special tokens file saved in M2M-100/random-16000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 06:45:55,982 >> added tokens file saved in M2M-100/random-16000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.8262, 'grad_norm': 8.481760025024414, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 2000/6000 [25:41<46:34,  1.43it/s][INFO|trainer.py:3944] 2025-03-31 06:52:16,506 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-31 06:52:16,511 >> Configuration saved in M2M-100/random-16000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 06:52:16,512 >> Configuration saved in M2M-100/random-16000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 06:52:28,027 >> Model weights saved in M2M-100/random-16000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 06:52:28,031 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 06:52:28,031 >> Special tokens file saved in M2M-100/random-16000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 06:52:28,032 >> added tokens file saved in M2M-100/random-16000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.201, 'grad_norm': 7.91462516784668, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n"," 42% 2500/6000 [32:14<39:59,  1.46it/s][INFO|trainer.py:3944] 2025-03-31 06:58:50,204 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-31 06:58:50,208 >> Configuration saved in M2M-100/random-16000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 06:58:50,209 >> Configuration saved in M2M-100/random-16000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 06:59:01,691 >> Model weights saved in M2M-100/random-16000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 06:59:01,696 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 06:59:01,696 >> Special tokens file saved in M2M-100/random-16000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 06:59:01,697 >> added tokens file saved in M2M-100/random-16000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1264, 'grad_norm': 7.752325534820557, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 3000/6000 [38:48<38:29,  1.30it/s][INFO|trainer.py:3944] 2025-03-31 07:05:23,492 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-31 07:05:23,497 >> Configuration saved in M2M-100/random-16000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:05:23,498 >> Configuration saved in M2M-100/random-16000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:05:34,985 >> Model weights saved in M2M-100/random-16000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:05:34,989 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:05:34,990 >> Special tokens file saved in M2M-100/random-16000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:05:34,990 >> added tokens file saved in M2M-100/random-16000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1255, 'grad_norm': 6.422542572021484, 'learning_rate': 2.0833333333333336e-05, 'epoch': 1.75}\n"," 58% 3500/6000 [45:19<29:26,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 07:11:54,451 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-31 07:11:54,454 >> Configuration saved in M2M-100/random-16000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:11:54,455 >> Configuration saved in M2M-100/random-16000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:12:05,997 >> Model weights saved in M2M-100/random-16000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:12:06,001 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:12:06,001 >> Special tokens file saved in M2M-100/random-16000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:12:06,001 >> added tokens file saved in M2M-100/random-16000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0861, 'grad_norm': 8.185125350952148, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 4000/6000 [51:50<23:29,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 07:18:25,517 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-31 07:18:25,523 >> Configuration saved in M2M-100/random-16000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:18:25,523 >> Configuration saved in M2M-100/random-16000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:18:37,031 >> Model weights saved in M2M-100/random-16000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:18:37,034 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:18:37,034 >> Special tokens file saved in M2M-100/random-16000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:18:37,035 >> added tokens file saved in M2M-100/random-16000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5829, 'grad_norm': 7.862451076507568, 'learning_rate': 1.25e-05, 'epoch': 2.25}\n"," 75% 4500/6000 [58:21<17:53,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 07:24:57,358 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-31 07:24:57,362 >> Configuration saved in M2M-100/random-16000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:24:57,363 >> Configuration saved in M2M-100/random-16000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:25:08,936 >> Model weights saved in M2M-100/random-16000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:25:08,939 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:25:08,940 >> Special tokens file saved in M2M-100/random-16000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:25:08,940 >> added tokens file saved in M2M-100/random-16000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5437, 'grad_norm': 7.11721658706665, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 5000/6000 [1:04:54<11:49,  1.41it/s][INFO|trainer.py:3944] 2025-03-31 07:31:29,487 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-31 07:31:29,489 >> Configuration saved in M2M-100/random-16000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:31:29,490 >> Configuration saved in M2M-100/random-16000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:31:41,061 >> Model weights saved in M2M-100/random-16000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:31:41,064 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:31:41,065 >> Special tokens file saved in M2M-100/random-16000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:31:41,065 >> added tokens file saved in M2M-100/random-16000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5542, 'grad_norm': 6.152076721191406, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.75}\n"," 92% 5500/6000 [1:11:25<06:01,  1.38it/s][INFO|trainer.py:3944] 2025-03-31 07:38:00,982 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-31 07:38:00,984 >> Configuration saved in M2M-100/random-16000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:38:00,985 >> Configuration saved in M2M-100/random-16000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:38:12,489 >> Model weights saved in M2M-100/random-16000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:38:12,492 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:38:12,492 >> Special tokens file saved in M2M-100/random-16000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:38:12,493 >> added tokens file saved in M2M-100/random-16000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5055, 'grad_norm': 8.891363143920898, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 6000/6000 [1:17:57<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 07:44:32,629 >> Saving model checkpoint to M2M-100/random-16000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-31 07:44:32,632 >> Configuration saved in M2M-100/random-16000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:44:32,633 >> Configuration saved in M2M-100/random-16000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:44:44,106 >> Model weights saved in M2M-100/random-16000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:44:44,110 >> tokenizer config file saved in M2M-100/random-16000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:44:44,111 >> Special tokens file saved in M2M-100/random-16000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:44:44,111 >> added tokens file saved in M2M-100/random-16000/checkpoint-6000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-31 07:45:02,345 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 4707.6841, 'train_samples_per_second': 10.196, 'train_steps_per_second': 1.275, 'train_loss': 3.2855466105143227, 'epoch': 3.0}\n","100% 6000/6000 [1:18:26<00:00,  1.27it/s]\n","[INFO|trainer.py:3944] 2025-03-31 07:45:02,354 >> Saving model checkpoint to M2M-100/random-16000\n","[INFO|configuration_utils.py:423] 2025-03-31 07:45:02,355 >> Configuration saved in M2M-100/random-16000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 07:45:02,356 >> Configuration saved in M2M-100/random-16000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 07:45:13,846 >> Model weights saved in M2M-100/random-16000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 07:45:13,849 >> tokenizer config file saved in M2M-100/random-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 07:45:13,849 >> Special tokens file saved in M2M-100/random-16000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 07:45:13,850 >> added tokens file saved in M2M-100/random-16000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  3146330GF\n","  train_loss               =     3.2855\n","  train_runtime            = 1:18:27.68\n","  train_samples            =      16000\n","  train_samples_per_second =     10.196\n","  train_steps_per_second   =      1.275\n","03/31/2025 07:45:13 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-31 07:45:14,004 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-31 07:45:14,004 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-31 07:45:14,004 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:34<00:00,  4.60s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =      5.921\n","  eval_chrf               =    36.9426\n","  eval_gen_len            =    46.7292\n","  eval_loss               =     2.7114\n","  eval_runtime            = 0:09:40.32\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.718\n","  eval_steps_per_second   =      0.215\n","03/31/2025 07:54:54 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-31 07:54:54,340 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-31 07:54:54,340 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-31 07:54:54,340 >>   Batch size = 8\n","100% 127/127 [10:35<00:00,  5.00s/it]\n","***** predict metrics *****\n","  predict_bleu               =     5.4841\n","  predict_chrf               =    35.9533\n","  predict_gen_len            =    48.8943\n","  predict_loss               =     2.7435\n","  predict_runtime            = 0:10:41.49\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.578\n","  predict_steps_per_second   =      0.198\n","[INFO|modelcard.py:449] 2025-03-31 08:05:51,173 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 5.921}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_16000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-16000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":40},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1742919567411,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"VcvXjtLvoqP4","outputId":"c5fd3b69-a4cf-4d3a-933e-192a767660b5"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eaef1840460>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-32000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10448520,"status":"ok","timestamp":1742930015924,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"xLXHxNu2o2rj","outputId":"9d11371a-6a95-4448-ebc8-ea91ca2d4994"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-25 16:19:33.341961: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-25 16:19:33.364116: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-25 16:19:33.370617: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-25 16:19:33.387447: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-25 16:19:34.497603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/25/2025 16:19:39 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/25/2025 16:19:39 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/africomet-qe-stl-1.1-32000/runs/Mar25_16-19-39_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/africomet-qe-stl-1.1-32000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/africomet-qe-stl-1.1-32000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-93c76eb23e51e985\n","03/25/2025 16:19:39 - INFO - datasets.builder - Using custom data configuration default-93c76eb23e51e985\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/25/2025 16:19:39 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","03/25/2025 16:19:39 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/25/2025 16:19:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/25/2025 16:19:39 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","03/25/2025 16:19:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-03-25 16:19:39,715 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 16:19:39,718 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-25 16:19:39,805 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 16:19:39,806 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 16:19:39,807 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-25 16:19:39,807 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 16:19:39,808 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-25 16:19:40,798 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-25 16:19:40,869 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-25 16:19:40,918 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-25 16:19:40,981 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-25 16:19:40,981 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-25 16:19:41,073 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-25 16:19:41,074 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-25 16:19:41,569 >> Safetensors PR exists\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e7e4ea04dc2a8f5f.arrow\n","03/25/2025 16:19:42 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e7e4ea04dc2a8f5f.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-caa473c3d2478b37.arrow\n","03/25/2025 16:19:43 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-caa473c3d2478b37.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1700a6a31f02dd2e.arrow\n","03/25/2025 16:19:45 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-93c76eb23e51e985/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-1700a6a31f02dd2e.arrow\n","[INFO|trainer.py:2407] 2025-03-25 16:19:55,010 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-25 16:19:55,010 >>   Num examples = 32,000\n","[INFO|trainer.py:2409] 2025-03-25 16:19:55,010 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-25 16:19:55,010 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-25 16:19:55,010 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-25 16:19:55,010 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-25 16:19:55,010 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-25 16:19:55,010 >>   Total optimization steps = 12,000\n","[INFO|trainer.py:2416] 2025-03-25 16:19:55,011 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-25 16:19:55,019 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250325_161955-ljrnw7bw\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/africomet-qe-stl-1.1-32000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/ljrnw7bw\u001b[0m\n","  0% 0/12000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.3917, 'grad_norm': 7.4095845222473145, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.12}\n","  4% 500/12000 [05:57<2:16:38,  1.40it/s][INFO|trainer.py:3944] 2025-03-25 16:25:53,660 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-25 16:25:53,668 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:25:53,669 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:26:05,121 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:26:05,125 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:26:05,125 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:26:05,125 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.8961, 'grad_norm': 7.585800647735596, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.25}\n","  8% 1000/12000 [12:24<2:14:20,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 16:32:20,156 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-25 16:32:20,167 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:32:20,167 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:32:31,762 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:32:31,766 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:32:31,766 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:32:31,767 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.6336, 'grad_norm': 6.686267375946045, 'learning_rate': 4.375e-05, 'epoch': 0.38}\n"," 12% 1500/12000 [18:51<1:59:50,  1.46it/s][INFO|trainer.py:3944] 2025-03-25 16:38:46,976 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-25 16:38:46,980 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:38:46,981 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:38:58,511 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:38:58,515 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:38:58,515 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:38:58,516 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.4467, 'grad_norm': 7.441803455352783, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 2000/12000 [25:19<1:58:44,  1.40it/s][INFO|trainer.py:3944] 2025-03-25 16:45:15,277 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-25 16:45:15,280 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:45:15,280 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:45:26,840 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:45:26,844 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:45:26,844 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:45:26,845 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.3128, 'grad_norm': 6.87680721282959, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.62}\n"," 21% 2500/12000 [31:43<1:48:00,  1.47it/s][INFO|trainer.py:3944] 2025-03-25 16:51:39,845 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-25 16:51:39,847 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:51:39,848 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:51:51,408 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:51:51,413 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:51:51,413 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:51:51,414 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.2138, 'grad_norm': 6.000250339508057, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.75}\n"," 25% 3000/12000 [38:09<1:46:24,  1.41it/s][INFO|trainer.py:3944] 2025-03-25 16:58:04,939 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-25 16:58:04,944 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 16:58:04,945 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 16:58:16,570 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 16:58:16,574 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 16:58:16,575 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 16:58:16,575 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1438, 'grad_norm': 6.375298976898193, 'learning_rate': 3.541666666666667e-05, 'epoch': 0.88}\n"," 29% 3500/12000 [44:35<1:46:42,  1.33it/s][INFO|trainer.py:3944] 2025-03-25 17:04:31,462 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-25 17:04:31,466 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:04:31,467 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:04:43,010 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:04:43,014 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:04:43,015 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:04:43,015 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0542, 'grad_norm': 5.641180992126465, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 4000/12000 [51:00<1:37:16,  1.37it/s][INFO|trainer.py:3944] 2025-03-25 17:10:56,415 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-25 17:10:56,418 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:10:56,418 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:11:07,911 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:11:07,915 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:11:07,916 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:11:07,916 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5598, 'grad_norm': 7.050191402435303, 'learning_rate': 3.125e-05, 'epoch': 1.12}\n"," 38% 4500/12000 [57:25<1:26:58,  1.44it/s][INFO|trainer.py:3944] 2025-03-25 17:17:21,366 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-25 17:17:21,371 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:17:21,372 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:17:32,881 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:17:32,885 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:17:32,885 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:17:32,885 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5932, 'grad_norm': 5.900742530822754, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n"," 42% 5000/12000 [1:03:49<1:24:13,  1.39it/s][INFO|trainer.py:3944] 2025-03-25 17:23:45,892 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-25 17:23:45,895 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:23:45,896 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:23:57,524 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:23:57,528 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:23:57,528 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:23:57,529 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.5722, 'grad_norm': 5.611404895782471, 'learning_rate': 2.7083333333333332e-05, 'epoch': 1.38}\n"," 46% 5500/12000 [1:10:15<1:23:04,  1.30it/s][INFO|trainer.py:3944] 2025-03-25 17:30:11,468 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-25 17:30:11,470 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:30:11,471 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:30:22,995 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:30:22,999 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:30:22,999 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:30:23,000 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.512, 'grad_norm': 6.898386478424072, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 6000/12000 [1:16:40<1:16:04,  1.31it/s][INFO|trainer.py:3944] 2025-03-25 17:36:36,072 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-25 17:36:36,081 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:36:36,082 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:36:47,675 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:36:47,679 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:36:47,680 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:36:47,680 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4927, 'grad_norm': 8.672322273254395, 'learning_rate': 2.2916666666666667e-05, 'epoch': 1.62}\n"," 54% 6500/12000 [1:23:01<1:03:26,  1.44it/s][INFO|trainer.py:3944] 2025-03-25 17:42:57,306 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500\n","[INFO|configuration_utils.py:423] 2025-03-25 17:42:57,310 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:42:57,311 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:43:08,823 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:43:08,827 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:43:08,827 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:43:08,828 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-6500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4865, 'grad_norm': 5.917010307312012, 'learning_rate': 2.0833333333333336e-05, 'epoch': 1.75}\n"," 58% 7000/12000 [1:29:26<1:00:32,  1.38it/s][INFO|trainer.py:3944] 2025-03-25 17:49:22,211 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000\n","[INFO|configuration_utils.py:423] 2025-03-25 17:49:22,213 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:49:22,214 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:49:33,727 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:49:33,731 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:49:33,731 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:49:33,732 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.455, 'grad_norm': 7.390806198120117, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}\n"," 62% 7500/12000 [1:35:52<54:19,  1.38it/s][INFO|trainer.py:3944] 2025-03-25 17:55:48,802 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500\n","[INFO|configuration_utils.py:423] 2025-03-25 17:55:48,807 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 17:55:48,807 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 17:56:00,361 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 17:56:00,365 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 17:56:00,366 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 17:56:00,366 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-7500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4068, 'grad_norm': 6.27310037612915, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 8000/12000 [1:42:20<45:00,  1.48it/s][INFO|trainer.py:3944] 2025-03-25 18:02:16,596 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:02:16,599 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:02:16,600 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:02:28,194 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:02:28,198 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:02:28,199 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:02:28,199 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0253, 'grad_norm': 7.235912322998047, 'learning_rate': 1.4583333333333335e-05, 'epoch': 2.12}\n"," 71% 8500/12000 [1:48:46<40:30,  1.44it/s][INFO|trainer.py:3944] 2025-03-25 18:08:42,766 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500\n","[INFO|configuration_utils.py:423] 2025-03-25 18:08:42,771 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:08:42,772 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:08:54,352 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:08:54,358 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:08:54,359 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:08:54,359 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-8500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0176, 'grad_norm': 5.883730411529541, 'learning_rate': 1.25e-05, 'epoch': 2.25}\n"," 75% 9000/12000 [1:55:12<33:59,  1.47it/s][INFO|trainer.py:3944] 2025-03-25 18:15:08,249 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:15:08,252 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:15:08,253 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:15:19,834 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:15:19,838 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:15:19,839 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:15:19,839 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0277, 'grad_norm': 6.255934238433838, 'learning_rate': 1.0416666666666668e-05, 'epoch': 2.38}\n"," 79% 9500/12000 [2:01:38<29:50,  1.40it/s][INFO|trainer.py:3944] 2025-03-25 18:21:34,871 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500\n","[INFO|configuration_utils.py:423] 2025-03-25 18:21:34,875 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:21:34,876 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:21:46,403 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:21:46,407 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:21:46,407 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:21:46,408 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-9500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0241, 'grad_norm': 7.130779266357422, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 10000/12000 [2:08:04<24:32,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 18:28:00,442 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:28:00,452 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:28:00,453 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:28:12,072 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:28:12,076 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:28:12,076 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:28:12,077 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.987, 'grad_norm': 6.365339756011963, 'learning_rate': 6.25e-06, 'epoch': 2.62}\n"," 88% 10500/12000 [2:14:30<18:01,  1.39it/s][INFO|trainer.py:3944] 2025-03-25 18:34:26,005 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500\n","[INFO|configuration_utils.py:423] 2025-03-25 18:34:26,007 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:34:26,008 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:34:37,592 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:34:37,596 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:34:37,597 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:34:37,597 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-10500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.0068, 'grad_norm': 5.302623748779297, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.75}\n"," 92% 11000/12000 [2:20:55<12:41,  1.31it/s][INFO|trainer.py:3944] 2025-03-25 18:40:51,821 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:40:51,824 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:40:51,825 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:41:03,398 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:41:03,403 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:41:03,403 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:41:03,404 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9606, 'grad_norm': 7.518202304840088, 'learning_rate': 2.0833333333333334e-06, 'epoch': 2.88}\n"," 96% 11500/12000 [2:27:20<05:39,  1.47it/s][INFO|trainer.py:3944] 2025-03-25 18:47:16,788 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500\n","[INFO|configuration_utils.py:423] 2025-03-25 18:47:16,790 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:47:16,791 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:47:28,359 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:47:28,363 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:47:28,364 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:47:28,364 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-11500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.978, 'grad_norm': 6.595338821411133, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 12000/12000 [2:33:46<00:00,  1.43it/s][INFO|trainer.py:3944] 2025-03-25 18:53:42,401 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:53:42,406 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:53:42,407 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:53:53,987 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:53:53,992 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:53:53,992 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:53:53,993 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/checkpoint-12000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-25 18:54:12,226 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 9257.2148, 'train_samples_per_second': 10.37, 'train_steps_per_second': 1.296, 'train_loss': 2.67492138671875, 'epoch': 3.0}\n","100% 12000/12000 [2:34:16<00:00,  1.30it/s]\n","[INFO|trainer.py:3944] 2025-03-25 18:54:12,234 >> Saving model checkpoint to M2M-100/africomet-qe-stl-1.1-32000\n","[INFO|configuration_utils.py:423] 2025-03-25 18:54:12,236 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 18:54:12,237 >> Configuration saved in M2M-100/africomet-qe-stl-1.1-32000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 18:54:23,876 >> Model weights saved in M2M-100/africomet-qe-stl-1.1-32000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 18:54:23,879 >> tokenizer config file saved in M2M-100/africomet-qe-stl-1.1-32000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 18:54:23,879 >> Special tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 18:54:23,880 >> added tokens file saved in M2M-100/africomet-qe-stl-1.1-32000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  6605052GF\n","  train_loss               =     2.6749\n","  train_runtime            = 2:34:17.21\n","  train_samples            =      32000\n","  train_samples_per_second =      10.37\n","  train_steps_per_second   =      1.296\n","03/25/2025 18:54:24 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-25 18:54:24,024 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-25 18:54:24,024 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-25 18:54:24,024 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:04<00:00,  4.35s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     9.0061\n","  eval_chrf               =     44.614\n","  eval_gen_len            =    45.3139\n","  eval_loss               =     2.2372\n","  eval_runtime            = 0:09:09.80\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.813\n","  eval_steps_per_second   =      0.227\n","03/25/2025 19:03:33 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-25 19:03:33,835 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-25 19:03:33,835 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-25 19:03:33,835 >>   Batch size = 8\n","100% 127/127 [09:36<00:00,  4.54s/it]\n","***** predict metrics *****\n","  predict_bleu               =     8.6982\n","  predict_chrf               =     44.371\n","  predict_gen_len            =    46.6621\n","  predict_loss               =     2.2735\n","  predict_runtime            = 0:09:43.34\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.735\n","  predict_steps_per_second   =      0.218\n","[INFO|modelcard.py:449] 2025-03-25 19:13:32,635 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 9.0061}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 python /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/train_32000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/africomet-qe-stl-1.1-32000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":40},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1742930015925,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"FJl5ZjM7oqOB","outputId":"ab18aaf9-3bf0-4456-9fbc-25b7198bcf8d"},"outputs":[{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/izuqi7qg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eaef1840460>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"africomet_{language}-plus-32000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12355548,"status":"ok","timestamp":1742942371463,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"},"user_tz":-120},"id":"N-_bLDUyo858","outputId":"7de3af99-28cf-4177-ee4d-c5aa33087be3"},"outputs":[{"name":"stdout","output_type":"stream","text":["2025-03-25 19:13:41.814633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-25 19:13:41.837092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-25 19:13:41.843644: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-25 19:13:41.859436: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-25 19:13:42.944176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/25/2025 19:13:47 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/25/2025 19:13:47 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/wmt22-cometkiwi-da-plus-32000/runs/Mar25_19-13-47_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/wmt22-cometkiwi-da-plus-32000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/wmt22-cometkiwi-da-plus-32000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-bfabaa4e2c76cc07\n","03/25/2025 19:13:47 - INFO - datasets.builder - Using custom data configuration default-bfabaa4e2c76cc07\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/25/2025 19:13:47 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/25/2025 19:13:47 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/25/2025 19:13:47 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/25/2025 19:13:47 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/25/2025 19:13:47 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/25/2025 19:13:47 - INFO - datasets.builder - Generating train split\n","Generating train split: 37737 examples [00:00, 482053.84 examples/s]\n","Generating validation split\n","03/25/2025 19:13:47 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 218059.19 examples/s]\n","Generating test split\n","03/25/2025 19:13:47 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 226139.35 examples/s]\n","Unable to verify splits sizes.\n","03/25/2025 19:13:47 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/25/2025 19:13:47 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-25 19:13:48,114 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 19:13:48,116 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-25 19:13:48,218 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 19:13:48,218 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,219 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-25 19:13:48,220 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-25 19:13:48,220 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-25 19:13:48,221 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-25 19:13:49,189 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-25 19:13:49,258 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-25 19:13:49,325 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-25 19:13:49,377 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-25 19:13:49,377 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-25 19:13:49,532 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-25 19:13:49,533 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-25 19:13:49,686 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/37737 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a66523ab1ce03dba.arrow\n","03/25/2025 19:13:51 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a66523ab1ce03dba.arrow\n","Running tokenizer on train dataset: 100% 37737/37737 [00:13<00:00, 2862.97 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6c75600c1f3c2124.arrow\n","03/25/2025 19:14:05 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-6c75600c1f3c2124.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1860.91 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0164deae71dec659.arrow\n","03/25/2025 19:14:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-bfabaa4e2c76cc07/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0164deae71dec659.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1790.32 examples/s]\n","[INFO|trainer.py:2407] 2025-03-25 19:14:17,710 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-25 19:14:17,710 >>   Num examples = 37,737\n","[INFO|trainer.py:2409] 2025-03-25 19:14:17,710 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-25 19:14:17,710 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-25 19:14:17,711 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-25 19:14:17,711 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-25 19:14:17,711 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-25 19:14:17,711 >>   Total optimization steps = 14,154\n","[INFO|trainer.py:2416] 2025-03-25 19:14:17,712 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-25 19:14:17,718 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250325_191417-306lsu1k\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/wmt22-cometkiwi-da-plus-32000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/306lsu1k\u001b[0m\n","  0% 0/14154 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.2975, 'grad_norm': 6.715846538543701, 'learning_rate': 4.8233714850925535e-05, 'epoch': 0.11}\n","  4% 500/14154 [06:16<2:38:33,  1.44it/s][INFO|trainer.py:3944] 2025-03-25 19:20:35,450 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-25 19:20:35,458 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:20:35,459 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:20:40,520 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:20:40,523 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:20:40,524 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:20:40,524 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.7687, 'grad_norm': 7.544182777404785, 'learning_rate': 4.646742970185107e-05, 'epoch': 0.21}\n","  7% 1000/14154 [12:51<2:50:48,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 19:27:09,857 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-25 19:27:09,858 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:27:09,859 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:27:14,800 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:27:14,803 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:27:14,803 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:27:14,804 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.5093, 'grad_norm': 8.106263160705566, 'learning_rate': 4.47011445527766e-05, 'epoch': 0.32}\n"," 11% 1500/14154 [19:27<2:31:33,  1.39it/s][INFO|trainer.py:3944] 2025-03-25 19:33:45,815 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-25 19:33:45,817 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:33:45,818 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:33:50,777 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:33:50,781 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:33:50,781 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:33:50,781 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.319, 'grad_norm': 5.6159892082214355, 'learning_rate': 4.293485940370214e-05, 'epoch': 0.42}\n"," 14% 2000/14154 [26:01<2:31:03,  1.34it/s][INFO|trainer.py:3944] 2025-03-25 19:40:20,157 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-25 19:40:20,159 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:40:20,159 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:40:25,167 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:40:25,170 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:40:25,170 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:40:25,171 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1969, 'grad_norm': 5.770010471343994, 'learning_rate': 4.1168574254627665e-05, 'epoch': 0.53}\n"," 18% 2500/14154 [32:40<2:33:13,  1.27it/s][INFO|trainer.py:3944] 2025-03-25 19:46:58,924 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-25 19:46:58,926 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:46:58,927 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:47:03,844 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:47:03,847 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:47:03,847 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:47:03,847 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0922, 'grad_norm': 6.036867618560791, 'learning_rate': 3.9402289105553204e-05, 'epoch': 0.64}\n"," 21% 3000/14154 [39:16<2:30:41,  1.23it/s][INFO|trainer.py:3944] 2025-03-25 19:53:34,749 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-25 19:53:34,750 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 19:53:34,751 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 19:53:39,718 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 19:53:39,721 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 19:53:39,722 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 19:53:39,722 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9954, 'grad_norm': 5.9100847244262695, 'learning_rate': 3.763600395647874e-05, 'epoch': 0.74}\n"," 25% 3500/14154 [45:54<2:12:00,  1.35it/s][INFO|trainer.py:3944] 2025-03-25 20:00:13,018 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-25 20:00:13,020 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:00:13,021 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:00:17,976 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:00:17,979 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:00:17,979 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:00:17,980 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9101, 'grad_norm': 6.589414119720459, 'learning_rate': 3.586971880740427e-05, 'epoch': 0.85}\n"," 28% 4000/14154 [52:32<2:04:45,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 20:06:51,121 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-25 20:06:51,123 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:06:51,124 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:06:56,084 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:06:56,087 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:06:56,087 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:06:56,088 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8448, 'grad_norm': 5.959824562072754, 'learning_rate': 3.41034336583298e-05, 'epoch': 0.95}\n"," 32% 4500/14154 [59:05<1:57:22,  1.37it/s][INFO|trainer.py:3944] 2025-03-25 20:13:24,118 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-25 20:13:24,120 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:13:24,121 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:13:29,052 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:13:29,055 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:13:29,056 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:13:29,056 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.632, 'grad_norm': 5.6130805015563965, 'learning_rate': 3.233714850925534e-05, 'epoch': 1.06}\n"," 35% 5000/14154 [1:05:42<1:54:35,  1.33it/s][INFO|trainer.py:3944] 2025-03-25 20:20:01,414 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-25 20:20:01,416 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:20:01,416 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:20:06,338 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:20:06,340 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:20:06,341 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:20:06,341 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4145, 'grad_norm': 5.4745402336120605, 'learning_rate': 3.057086336018087e-05, 'epoch': 1.17}\n"," 39% 5500/14154 [1:12:21<1:45:52,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 20:26:39,775 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-25 20:26:39,777 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:26:39,778 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:26:44,739 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:26:44,742 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:26:44,742 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:26:44,742 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3837, 'grad_norm': 6.860598564147949, 'learning_rate': 2.8804578211106403e-05, 'epoch': 1.27}\n"," 42% 6000/14154 [1:18:56<1:43:35,  1.31it/s][INFO|trainer.py:3944] 2025-03-25 20:33:15,545 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-25 20:33:15,547 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:33:15,548 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:33:20,569 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:33:20,572 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:33:20,573 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:33:20,573 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3654, 'grad_norm': 6.220436096191406, 'learning_rate': 2.7038293062031932e-05, 'epoch': 1.38}\n"," 46% 6500/14154 [1:25:31<1:29:57,  1.42it/s][INFO|trainer.py:3944] 2025-03-25 20:39:50,200 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500\n","[INFO|configuration_utils.py:423] 2025-03-25 20:39:50,201 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:39:50,202 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:39:55,151 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:39:55,154 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:39:55,154 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:39:55,154 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-6500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.352, 'grad_norm': 4.684757709503174, 'learning_rate': 2.5272007912957468e-05, 'epoch': 1.48}\n"," 49% 7000/14154 [1:32:07<1:33:26,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 20:46:26,397 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000\n","[INFO|configuration_utils.py:423] 2025-03-25 20:46:26,399 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:46:26,400 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:46:31,408 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:46:31,411 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:46:31,412 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:46:31,412 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3241, 'grad_norm': 5.857235431671143, 'learning_rate': 2.3505722763883004e-05, 'epoch': 1.59}\n"," 53% 7500/14154 [1:38:45<1:23:42,  1.32it/s][INFO|trainer.py:3944] 2025-03-25 20:53:04,473 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500\n","[INFO|configuration_utils.py:423] 2025-03-25 20:53:04,475 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:53:04,476 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:53:09,576 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:53:09,580 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:53:09,580 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:53:09,581 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-7500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3243, 'grad_norm': 6.37507438659668, 'learning_rate': 2.1739437614808536e-05, 'epoch': 1.7}\n"," 57% 8000/14154 [1:45:23<1:13:57,  1.39it/s][INFO|trainer.py:3944] 2025-03-25 20:59:42,421 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000\n","[INFO|configuration_utils.py:423] 2025-03-25 20:59:42,423 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 20:59:42,424 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 20:59:47,477 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 20:59:47,480 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 20:59:47,481 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 20:59:47,481 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.2824, 'grad_norm': 7.17487096786499, 'learning_rate': 1.997315246573407e-05, 'epoch': 1.8}\n"," 60% 8500/14154 [1:52:00<1:08:49,  1.37it/s][INFO|trainer.py:3944] 2025-03-25 21:06:19,318 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500\n","[INFO|configuration_utils.py:423] 2025-03-25 21:06:19,320 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:06:19,320 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:06:24,366 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:06:24,370 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:06:24,371 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:06:24,371 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-8500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.2445, 'grad_norm': 5.2771782875061035, 'learning_rate': 1.8206867316659605e-05, 'epoch': 1.91}\n"," 64% 9000/14154 [1:58:40<1:06:19,  1.30it/s][INFO|trainer.py:3944] 2025-03-25 21:12:58,804 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000\n","[INFO|configuration_utils.py:423] 2025-03-25 21:12:58,806 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:12:58,806 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:13:03,929 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:13:03,932 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:13:03,932 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:13:03,933 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.2237, 'grad_norm': 4.4121904373168945, 'learning_rate': 1.6440582167585137e-05, 'epoch': 2.01}\n"," 67% 9500/14154 [2:05:20<1:00:44,  1.28it/s][INFO|trainer.py:3944] 2025-03-25 21:19:38,677 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500\n","[INFO|configuration_utils.py:423] 2025-03-25 21:19:38,679 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:19:38,679 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:19:43,767 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:19:43,770 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:19:43,771 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:19:43,771 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-9500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9209, 'grad_norm': 6.2525529861450195, 'learning_rate': 1.4674297018510668e-05, 'epoch': 2.12}\n"," 71% 10000/14154 [2:11:58<49:07,  1.41it/s][INFO|trainer.py:3944] 2025-03-25 21:26:16,998 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000\n","[INFO|configuration_utils.py:423] 2025-03-25 21:26:17,000 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:26:17,001 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:26:21,999 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:26:22,002 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:26:22,003 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:26:22,003 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9225, 'grad_norm': 6.404486179351807, 'learning_rate': 1.29080118694362e-05, 'epoch': 2.23}\n"," 74% 10500/14154 [2:18:38<42:52,  1.42it/s][INFO|trainer.py:3944] 2025-03-25 21:32:56,881 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500\n","[INFO|configuration_utils.py:423] 2025-03-25 21:32:56,883 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:32:56,884 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:33:01,962 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:33:01,965 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:33:01,966 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:33:01,966 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-10500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.9089, 'grad_norm': 6.911657810211182, 'learning_rate': 1.1141726720361735e-05, 'epoch': 2.33}\n"," 78% 11000/14154 [2:25:15<38:57,  1.35it/s][INFO|trainer.py:3944] 2025-03-25 21:39:34,491 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000\n","[INFO|configuration_utils.py:423] 2025-03-25 21:39:34,493 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:39:34,494 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:39:39,541 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:39:39,545 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:39:39,545 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:39:39,546 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8582, 'grad_norm': 6.200482368469238, 'learning_rate': 9.375441571287269e-06, 'epoch': 2.44}\n"," 81% 11500/14154 [2:31:54<32:36,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 21:46:13,100 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500\n","[INFO|configuration_utils.py:423] 2025-03-25 21:46:13,102 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:46:13,102 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:46:18,178 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:46:18,181 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:46:18,182 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:46:18,182 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-11500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8793, 'grad_norm': 6.740275859832764, 'learning_rate': 7.609156422212803e-06, 'epoch': 2.54}\n"," 85% 12000/14154 [2:38:33<27:17,  1.32it/s][INFO|trainer.py:3944] 2025-03-25 21:52:51,772 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000\n","[INFO|configuration_utils.py:423] 2025-03-25 21:52:51,775 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:52:51,776 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:52:56,808 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:52:56,813 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:52:56,813 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:52:56,814 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8518, 'grad_norm': 5.539434432983398, 'learning_rate': 5.842871273138336e-06, 'epoch': 2.65}\n"," 88% 12500/14154 [2:45:13<21:10,  1.30it/s][INFO|trainer.py:3944] 2025-03-25 21:59:32,234 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500\n","[INFO|configuration_utils.py:423] 2025-03-25 21:59:32,236 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 21:59:32,236 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 21:59:37,372 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 21:59:37,375 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 21:59:37,376 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 21:59:37,377 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-12500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8459, 'grad_norm': 5.0667195320129395, 'learning_rate': 4.076586124063869e-06, 'epoch': 2.76}\n"," 92% 13000/14154 [2:51:50<14:25,  1.33it/s][INFO|trainer.py:3944] 2025-03-25 22:06:08,990 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000\n","[INFO|configuration_utils.py:423] 2025-03-25 22:06:08,992 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 22:06:08,992 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 22:06:13,997 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 22:06:14,001 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 22:06:14,001 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 22:06:14,002 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8555, 'grad_norm': 5.735628128051758, 'learning_rate': 2.3103009749894023e-06, 'epoch': 2.86}\n"," 95% 13500/14154 [2:58:24<07:59,  1.36it/s][INFO|trainer.py:3944] 2025-03-25 22:12:43,378 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500\n","[INFO|configuration_utils.py:423] 2025-03-25 22:12:43,380 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 22:12:43,381 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 22:12:48,442 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 22:12:48,446 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 22:12:48,447 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 22:12:48,447 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-13500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 1.8393, 'grad_norm': 6.125715732574463, 'learning_rate': 5.440158259149357e-07, 'epoch': 2.97}\n"," 99% 14000/14154 [3:04:57<01:52,  1.37it/s][INFO|trainer.py:3944] 2025-03-25 22:19:16,477 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000\n","[INFO|configuration_utils.py:423] 2025-03-25 22:19:16,479 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 22:19:16,480 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 22:19:21,509 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 22:19:21,512 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 22:19:21,513 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 22:19:21,513 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 14154/14154 [3:07:08<00:00,  1.65it/s][INFO|trainer.py:3944] 2025-03-25 22:21:27,567 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154\n","[INFO|configuration_utils.py:423] 2025-03-25 22:21:27,570 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 22:21:27,570 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 22:21:32,780 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 22:21:32,783 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 22:21:32,783 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 22:21:32,784 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/checkpoint-14154/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-25 22:21:46,635 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 11248.9232, 'train_samples_per_second': 10.064, 'train_steps_per_second': 1.258, 'train_loss': 2.505351406311406, 'epoch': 3.0}\n","100% 14154/14154 [3:07:28<00:00,  1.26it/s]\n","[INFO|trainer.py:3944] 2025-03-25 22:21:46,643 >> Saving model checkpoint to M2M-100/wmt22-cometkiwi-da-plus-32000\n","[INFO|configuration_utils.py:423] 2025-03-25 22:21:46,645 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-25 22:21:46,646 >> Configuration saved in M2M-100/wmt22-cometkiwi-da-plus-32000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-25 22:21:55,625 >> Model weights saved in M2M-100/wmt22-cometkiwi-da-plus-32000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-25 22:21:55,628 >> tokenizer config file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-25 22:21:55,629 >> Special tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-25 22:21:55,629 >> added tokens file saved in M2M-100/wmt22-cometkiwi-da-plus-32000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               = 10220982GF\n","  train_loss               =     2.5054\n","  train_runtime            = 3:07:28.92\n","  train_samples            =      37737\n","  train_samples_per_second =     10.064\n","  train_steps_per_second   =      1.258\n","03/25/2025 22:21:55 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-25 22:21:55,788 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-25 22:21:55,788 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-25 22:21:55,788 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [08:08<00:00,  3.91s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =    10.8442\n","  eval_chrf               =    49.2251\n","  eval_gen_len            =    44.5065\n","  eval_loss               =     1.9316\n","  eval_runtime            = 0:08:15.49\n","  eval_samples            =        997\n","  eval_samples_per_second =      2.012\n","  eval_steps_per_second   =      0.252\n","03/25/2025 22:30:11 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-25 22:30:11,290 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-25 22:30:11,291 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-25 22:30:11,291 >>   Batch size = 8\n","100% 127/127 [08:54<00:00,  4.21s/it]\n","***** predict metrics *****\n","  predict_bleu               =    10.8899\n","  predict_chrf               =     48.944\n","  predict_gen_len            =    46.2767\n","  predict_loss               =     1.9676\n","  predict_runtime            = 0:09:00.94\n","  predict_samples            =       1012\n","  predict_samples_per_second =      1.871\n","  predict_steps_per_second   =      0.235\n","[INFO|modelcard.py:449] 2025-03-25 22:39:28,064 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 10.8442}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/africomet-qe-stl-1.1/en-zu/trainer_32000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/wmt22-cometkiwi-da-plus-32000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_F_RGd3to84r","colab":{"base_uri":"https://localhost:8080/","height":40},"executionInfo":{"status":"ok","timestamp":1743408354562,"user_tz":-120,"elapsed":21,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"73543515-b004-454f-c3a5-934e7e0fd9d1"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/machine%20translation/runs/7ufkjmfg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7d262234c460>"]},"metadata":{},"execution_count":7}],"source":["# Initialize WandB\n","wandb.init(project=\"machine translation\", name=f\"random_{language}-32000\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"52Z6bMP_-cg-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743418754409,"user_tz":-120,"elapsed":10399858,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"b9f08315-e071-4afb-eb09-edaa1f603926"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-03-31 08:05:58.855876: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-03-31 08:05:58.878880: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-03-31 08:05:58.885356: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-03-31 08:05:58.901030: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2025-03-31 08:05:59.973204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","03/31/2025 08:06:02 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","03/31/2025 08:06:02 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/random-32000/runs/Mar31_08-06-02_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100/random-32000,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100/random-32000,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-1fbae27aa492ba1b\n","03/31/2025 08:06:02 - INFO - datasets.builder - Using custom data configuration default-1fbae27aa492ba1b\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","03/31/2025 08:06:02 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Generating dataset json (/root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","03/31/2025 08:06:02 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","03/31/2025 08:06:02 - INFO - datasets.builder - Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092...\n","Downloading took 0.0 min\n","03/31/2025 08:06:02 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","03/31/2025 08:06:02 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","03/31/2025 08:06:02 - INFO - datasets.builder - Generating train split\n","Generating train split: 32000 examples [00:00, 544343.66 examples/s]\n","Generating validation split\n","03/31/2025 08:06:02 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 997 examples [00:00, 223322.89 examples/s]\n","Generating test split\n","03/31/2025 08:06:02 - INFO - datasets.builder - Generating test split\n","Generating test split: 1012 examples [00:00, 230649.11 examples/s]\n","Unable to verify splits sizes.\n","03/31/2025 08:06:02 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","03/31/2025 08:06:02 - INFO - datasets.builder - Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:699] 2025-03-31 08:06:03,036 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 08:06:03,037 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-03-31 08:06:03,126 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 08:06:03,126 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-03-31 08:06:03,127 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-03-31 08:06:03,128 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-03-31 08:06:03,128 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-03-31 08:06:03,996 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|configuration_utils.py:1140] 2025-03-31 08:06:04,058 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:61] 2025-03-31 08:06:04,107 >> Attempting to create safetensors variant\n","[INFO|modeling_utils.py:4972] 2025-03-31 08:06:04,158 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-03-31 08:06:04,158 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-03-31 08:06:04,246 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-03-31 08:06:04,247 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-03-31 08:06:04,478 >> Safetensors PR exists\n","Running tokenizer on train dataset:   0% 0/32000 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9716fbe612bfe648.arrow\n","03/31/2025 08:06:05 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-9716fbe612bfe648.arrow\n","Running tokenizer on train dataset: 100% 32000/32000 [00:08<00:00, 3653.36 examples/s]\n","Running tokenizer on validation dataset:   0% 0/997 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-835b9eaef4a396f9.arrow\n","03/31/2025 08:06:16 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-835b9eaef4a396f9.arrow\n","Running tokenizer on validation dataset: 100% 997/997 [00:00<00:00, 1911.82 examples/s]\n","Running tokenizer on prediction dataset:   0% 0/1012 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0b30f2ab4e168709.arrow\n","03/31/2025 08:06:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-1fbae27aa492ba1b/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-0b30f2ab4e168709.arrow\n","Running tokenizer on prediction dataset: 100% 1012/1012 [00:00<00:00, 1880.86 examples/s]\n","[INFO|trainer.py:2407] 2025-03-31 08:06:20,556 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-03-31 08:06:20,556 >>   Num examples = 32,000\n","[INFO|trainer.py:2409] 2025-03-31 08:06:20,556 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-03-31 08:06:20,556 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-03-31 08:06:20,556 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-03-31 08:06:20,556 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-03-31 08:06:20,556 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-03-31 08:06:20,556 >>   Total optimization steps = 12,000\n","[INFO|trainer.py:2416] 2025-03-31 08:06:20,558 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-03-31 08:06:20,563 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250331_080620-ugfoguc1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100/random-32000\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/ugfoguc1\u001b[0m\n","  0% 0/12000 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.6767, 'grad_norm': 7.642849445343018, 'learning_rate': 4.791666666666667e-05, 'epoch': 0.12}\n","  4% 500/12000 [06:02<2:15:42,  1.41it/s][INFO|trainer.py:3944] 2025-03-31 08:12:24,272 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-03-31 08:12:24,281 >> Configuration saved in M2M-100/random-32000/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:12:24,282 >> Configuration saved in M2M-100/random-32000/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:12:29,050 >> Model weights saved in M2M-100/random-32000/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:12:29,053 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:12:29,053 >> Special tokens file saved in M2M-100/random-32000/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:12:29,054 >> added tokens file saved in M2M-100/random-32000/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.2675, 'grad_norm': 7.688738822937012, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.25}\n","  8% 1000/12000 [12:24<2:12:37,  1.38it/s][INFO|trainer.py:3944] 2025-03-31 08:18:45,512 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-03-31 08:18:45,514 >> Configuration saved in M2M-100/random-32000/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:18:45,515 >> Configuration saved in M2M-100/random-32000/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:18:50,446 >> Model weights saved in M2M-100/random-32000/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:18:50,448 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:18:50,449 >> Special tokens file saved in M2M-100/random-32000/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:18:50,449 >> added tokens file saved in M2M-100/random-32000/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.0105, 'grad_norm': 7.191985607147217, 'learning_rate': 4.375e-05, 'epoch': 0.38}\n"," 12% 1500/12000 [18:45<2:03:14,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 08:25:06,525 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-03-31 08:25:06,527 >> Configuration saved in M2M-100/random-32000/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:25:06,528 >> Configuration saved in M2M-100/random-32000/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:25:11,390 >> Model weights saved in M2M-100/random-32000/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:25:11,393 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:25:11,393 >> Special tokens file saved in M2M-100/random-32000/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:25:11,394 >> added tokens file saved in M2M-100/random-32000/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.9019, 'grad_norm': 6.867018222808838, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.5}\n"," 17% 2000/12000 [25:06<2:01:07,  1.38it/s][INFO|trainer.py:3944] 2025-03-31 08:31:28,165 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-03-31 08:31:28,167 >> Configuration saved in M2M-100/random-32000/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:31:28,168 >> Configuration saved in M2M-100/random-32000/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:31:33,032 >> Model weights saved in M2M-100/random-32000/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:31:33,036 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:31:33,037 >> Special tokens file saved in M2M-100/random-32000/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:31:33,037 >> added tokens file saved in M2M-100/random-32000/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.7419, 'grad_norm': 6.779980659484863, 'learning_rate': 3.958333333333333e-05, 'epoch': 0.62}\n"," 21% 2500/12000 [31:28<1:51:32,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 08:37:49,846 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-03-31 08:37:49,848 >> Configuration saved in M2M-100/random-32000/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:37:49,849 >> Configuration saved in M2M-100/random-32000/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:37:54,674 >> Model weights saved in M2M-100/random-32000/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:37:54,677 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:37:54,678 >> Special tokens file saved in M2M-100/random-32000/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:37:54,678 >> added tokens file saved in M2M-100/random-32000/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.6542, 'grad_norm': 7.58373498916626, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.75}\n"," 25% 3000/12000 [37:49<1:52:00,  1.34it/s][INFO|trainer.py:3944] 2025-03-31 08:44:11,342 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-03-31 08:44:11,344 >> Configuration saved in M2M-100/random-32000/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:44:11,345 >> Configuration saved in M2M-100/random-32000/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:44:16,359 >> Model weights saved in M2M-100/random-32000/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:44:16,362 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:44:16,363 >> Special tokens file saved in M2M-100/random-32000/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:44:16,363 >> added tokens file saved in M2M-100/random-32000/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.5648, 'grad_norm': 6.01732873916626, 'learning_rate': 3.541666666666667e-05, 'epoch': 0.88}\n"," 29% 3500/12000 [44:11<1:43:48,  1.36it/s][INFO|trainer.py:3944] 2025-03-31 08:50:33,256 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-03-31 08:50:33,258 >> Configuration saved in M2M-100/random-32000/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:50:33,259 >> Configuration saved in M2M-100/random-32000/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:50:38,202 >> Model weights saved in M2M-100/random-32000/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:50:38,205 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:50:38,206 >> Special tokens file saved in M2M-100/random-32000/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:50:38,206 >> added tokens file saved in M2M-100/random-32000/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.5069, 'grad_norm': 6.29356575012207, 'learning_rate': 3.3333333333333335e-05, 'epoch': 1.0}\n"," 33% 4000/12000 [50:32<1:34:29,  1.41it/s][INFO|trainer.py:3944] 2025-03-31 08:56:54,377 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-4000\n","[INFO|configuration_utils.py:423] 2025-03-31 08:56:54,379 >> Configuration saved in M2M-100/random-32000/checkpoint-4000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 08:56:54,379 >> Configuration saved in M2M-100/random-32000/checkpoint-4000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 08:56:59,245 >> Model weights saved in M2M-100/random-32000/checkpoint-4000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 08:56:59,248 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 08:56:59,249 >> Special tokens file saved in M2M-100/random-32000/checkpoint-4000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 08:56:59,249 >> added tokens file saved in M2M-100/random-32000/checkpoint-4000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.0285, 'grad_norm': 7.016903877258301, 'learning_rate': 3.125e-05, 'epoch': 1.12}\n"," 38% 4500/12000 [56:53<1:29:03,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 09:03:14,898 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-4500\n","[INFO|configuration_utils.py:423] 2025-03-31 09:03:14,900 >> Configuration saved in M2M-100/random-32000/checkpoint-4500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:03:14,901 >> Configuration saved in M2M-100/random-32000/checkpoint-4500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:03:19,778 >> Model weights saved in M2M-100/random-32000/checkpoint-4500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:03:19,782 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:03:19,783 >> Special tokens file saved in M2M-100/random-32000/checkpoint-4500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:03:19,783 >> added tokens file saved in M2M-100/random-32000/checkpoint-4500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9956, 'grad_norm': 6.125858783721924, 'learning_rate': 2.916666666666667e-05, 'epoch': 1.25}\n"," 42% 5000/12000 [1:03:15<1:23:03,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 09:09:36,569 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-5000\n","[INFO|configuration_utils.py:423] 2025-03-31 09:09:36,571 >> Configuration saved in M2M-100/random-32000/checkpoint-5000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:09:36,571 >> Configuration saved in M2M-100/random-32000/checkpoint-5000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:09:41,413 >> Model weights saved in M2M-100/random-32000/checkpoint-5000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:09:41,417 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:09:41,417 >> Special tokens file saved in M2M-100/random-32000/checkpoint-5000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:09:41,417 >> added tokens file saved in M2M-100/random-32000/checkpoint-5000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9293, 'grad_norm': 6.493515491485596, 'learning_rate': 2.7083333333333332e-05, 'epoch': 1.38}\n"," 46% 5500/12000 [1:09:37<1:17:37,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 09:15:58,423 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-5500\n","[INFO|configuration_utils.py:423] 2025-03-31 09:15:58,425 >> Configuration saved in M2M-100/random-32000/checkpoint-5500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:15:58,426 >> Configuration saved in M2M-100/random-32000/checkpoint-5500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:16:03,343 >> Model weights saved in M2M-100/random-32000/checkpoint-5500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:16:03,348 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:16:03,348 >> Special tokens file saved in M2M-100/random-32000/checkpoint-5500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:16:03,349 >> added tokens file saved in M2M-100/random-32000/checkpoint-5500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.922, 'grad_norm': 7.444250583648682, 'learning_rate': 2.5e-05, 'epoch': 1.5}\n"," 50% 6000/12000 [1:15:59<1:15:21,  1.33it/s][INFO|trainer.py:3944] 2025-03-31 09:22:20,778 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-6000\n","[INFO|configuration_utils.py:423] 2025-03-31 09:22:20,779 >> Configuration saved in M2M-100/random-32000/checkpoint-6000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:22:20,780 >> Configuration saved in M2M-100/random-32000/checkpoint-6000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:22:25,630 >> Model weights saved in M2M-100/random-32000/checkpoint-6000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:22:25,633 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:22:25,633 >> Special tokens file saved in M2M-100/random-32000/checkpoint-6000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:22:25,634 >> added tokens file saved in M2M-100/random-32000/checkpoint-6000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9114, 'grad_norm': 6.427191257476807, 'learning_rate': 2.2916666666666667e-05, 'epoch': 1.62}\n"," 54% 6500/12000 [1:22:20<1:07:42,  1.35it/s][INFO|trainer.py:3944] 2025-03-31 09:28:42,189 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-6500\n","[INFO|configuration_utils.py:423] 2025-03-31 09:28:42,190 >> Configuration saved in M2M-100/random-32000/checkpoint-6500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:28:42,191 >> Configuration saved in M2M-100/random-32000/checkpoint-6500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:28:47,136 >> Model weights saved in M2M-100/random-32000/checkpoint-6500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:28:47,138 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:28:47,139 >> Special tokens file saved in M2M-100/random-32000/checkpoint-6500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:28:47,139 >> added tokens file saved in M2M-100/random-32000/checkpoint-6500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.9171, 'grad_norm': 6.134252071380615, 'learning_rate': 2.0833333333333336e-05, 'epoch': 1.75}\n"," 58% 7000/12000 [1:28:42<1:00:18,  1.38it/s][INFO|trainer.py:3944] 2025-03-31 09:35:03,871 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-7000\n","[INFO|configuration_utils.py:423] 2025-03-31 09:35:03,872 >> Configuration saved in M2M-100/random-32000/checkpoint-7000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:35:03,873 >> Configuration saved in M2M-100/random-32000/checkpoint-7000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:35:08,732 >> Model weights saved in M2M-100/random-32000/checkpoint-7000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:35:08,736 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:35:08,737 >> Special tokens file saved in M2M-100/random-32000/checkpoint-7000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:35:08,737 >> added tokens file saved in M2M-100/random-32000/checkpoint-7000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8719, 'grad_norm': 6.546533584594727, 'learning_rate': 1.8750000000000002e-05, 'epoch': 1.88}\n"," 62% 7500/12000 [1:35:01<52:51,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 09:41:23,241 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-7500\n","[INFO|configuration_utils.py:423] 2025-03-31 09:41:23,243 >> Configuration saved in M2M-100/random-32000/checkpoint-7500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:41:23,244 >> Configuration saved in M2M-100/random-32000/checkpoint-7500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:41:28,126 >> Model weights saved in M2M-100/random-32000/checkpoint-7500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:41:28,129 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:41:28,129 >> Special tokens file saved in M2M-100/random-32000/checkpoint-7500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:41:28,130 >> added tokens file saved in M2M-100/random-32000/checkpoint-7500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.8843, 'grad_norm': 8.298301696777344, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 8000/12000 [1:41:22<46:52,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 09:47:44,138 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-8000\n","[INFO|configuration_utils.py:423] 2025-03-31 09:47:44,140 >> Configuration saved in M2M-100/random-32000/checkpoint-8000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:47:44,140 >> Configuration saved in M2M-100/random-32000/checkpoint-8000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:47:49,098 >> Model weights saved in M2M-100/random-32000/checkpoint-8000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:47:49,101 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:47:49,101 >> Special tokens file saved in M2M-100/random-32000/checkpoint-8000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:47:49,102 >> added tokens file saved in M2M-100/random-32000/checkpoint-8000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4031, 'grad_norm': 5.595266819000244, 'learning_rate': 1.4583333333333335e-05, 'epoch': 2.12}\n"," 71% 8500/12000 [1:47:42<43:22,  1.35it/s][INFO|trainer.py:3944] 2025-03-31 09:54:04,143 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-8500\n","[INFO|configuration_utils.py:423] 2025-03-31 09:54:04,145 >> Configuration saved in M2M-100/random-32000/checkpoint-8500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 09:54:04,146 >> Configuration saved in M2M-100/random-32000/checkpoint-8500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 09:54:09,157 >> Model weights saved in M2M-100/random-32000/checkpoint-8500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 09:54:09,160 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 09:54:09,161 >> Special tokens file saved in M2M-100/random-32000/checkpoint-8500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 09:54:09,162 >> added tokens file saved in M2M-100/random-32000/checkpoint-8500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.427, 'grad_norm': 7.713553428649902, 'learning_rate': 1.25e-05, 'epoch': 2.25}\n"," 75% 9000/12000 [1:54:03<36:01,  1.39it/s][INFO|trainer.py:3944] 2025-03-31 10:00:25,233 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-9000\n","[INFO|configuration_utils.py:423] 2025-03-31 10:00:25,235 >> Configuration saved in M2M-100/random-32000/checkpoint-9000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:00:25,235 >> Configuration saved in M2M-100/random-32000/checkpoint-9000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:00:30,091 >> Model weights saved in M2M-100/random-32000/checkpoint-9000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:00:30,094 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:00:30,095 >> Special tokens file saved in M2M-100/random-32000/checkpoint-9000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:00:30,095 >> added tokens file saved in M2M-100/random-32000/checkpoint-9000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4173, 'grad_norm': 8.388885498046875, 'learning_rate': 1.0416666666666668e-05, 'epoch': 2.38}\n"," 79% 9500/12000 [2:00:24<29:25,  1.42it/s][INFO|trainer.py:3944] 2025-03-31 10:06:46,331 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-9500\n","[INFO|configuration_utils.py:423] 2025-03-31 10:06:46,333 >> Configuration saved in M2M-100/random-32000/checkpoint-9500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:06:46,334 >> Configuration saved in M2M-100/random-32000/checkpoint-9500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:06:51,166 >> Model weights saved in M2M-100/random-32000/checkpoint-9500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:06:51,169 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:06:51,170 >> Special tokens file saved in M2M-100/random-32000/checkpoint-9500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:06:51,170 >> added tokens file saved in M2M-100/random-32000/checkpoint-9500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.4117, 'grad_norm': 6.098949432373047, 'learning_rate': 8.333333333333334e-06, 'epoch': 2.5}\n"," 83% 10000/12000 [2:06:47<24:14,  1.37it/s][INFO|trainer.py:3944] 2025-03-31 10:13:08,565 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-10000\n","[INFO|configuration_utils.py:423] 2025-03-31 10:13:08,567 >> Configuration saved in M2M-100/random-32000/checkpoint-10000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:13:08,568 >> Configuration saved in M2M-100/random-32000/checkpoint-10000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:13:13,421 >> Model weights saved in M2M-100/random-32000/checkpoint-10000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:13:13,424 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:13:13,424 >> Special tokens file saved in M2M-100/random-32000/checkpoint-10000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:13:13,425 >> added tokens file saved in M2M-100/random-32000/checkpoint-10000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3941, 'grad_norm': 7.282628059387207, 'learning_rate': 6.25e-06, 'epoch': 2.62}\n"," 88% 10500/12000 [2:13:12<18:46,  1.33it/s][INFO|trainer.py:3944] 2025-03-31 10:19:33,584 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-10500\n","[INFO|configuration_utils.py:423] 2025-03-31 10:19:33,586 >> Configuration saved in M2M-100/random-32000/checkpoint-10500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:19:33,587 >> Configuration saved in M2M-100/random-32000/checkpoint-10500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:19:38,545 >> Model weights saved in M2M-100/random-32000/checkpoint-10500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:19:38,548 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:19:38,548 >> Special tokens file saved in M2M-100/random-32000/checkpoint-10500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:19:38,548 >> added tokens file saved in M2M-100/random-32000/checkpoint-10500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3715, 'grad_norm': 7.465506553649902, 'learning_rate': 4.166666666666667e-06, 'epoch': 2.75}\n"," 92% 11000/12000 [2:19:33<11:40,  1.43it/s][INFO|trainer.py:3944] 2025-03-31 10:25:54,986 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-11000\n","[INFO|configuration_utils.py:423] 2025-03-31 10:25:54,988 >> Configuration saved in M2M-100/random-32000/checkpoint-11000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:25:54,988 >> Configuration saved in M2M-100/random-32000/checkpoint-11000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:25:59,866 >> Model weights saved in M2M-100/random-32000/checkpoint-11000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:25:59,869 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:25:59,869 >> Special tokens file saved in M2M-100/random-32000/checkpoint-11000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:25:59,870 >> added tokens file saved in M2M-100/random-32000/checkpoint-11000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3908, 'grad_norm': 7.392059326171875, 'learning_rate': 2.0833333333333334e-06, 'epoch': 2.88}\n"," 96% 11500/12000 [2:25:52<06:10,  1.35it/s][INFO|trainer.py:3944] 2025-03-31 10:32:14,065 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-11500\n","[INFO|configuration_utils.py:423] 2025-03-31 10:32:14,067 >> Configuration saved in M2M-100/random-32000/checkpoint-11500/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:32:14,068 >> Configuration saved in M2M-100/random-32000/checkpoint-11500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:32:18,920 >> Model weights saved in M2M-100/random-32000/checkpoint-11500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:32:18,924 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:32:18,924 >> Special tokens file saved in M2M-100/random-32000/checkpoint-11500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:32:18,924 >> added tokens file saved in M2M-100/random-32000/checkpoint-11500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.3838, 'grad_norm': 7.412503719329834, 'learning_rate': 0.0, 'epoch': 3.0}\n","100% 12000/12000 [2:32:14<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-03-31 10:38:35,639 >> Saving model checkpoint to M2M-100/random-32000/checkpoint-12000\n","[INFO|configuration_utils.py:423] 2025-03-31 10:38:35,641 >> Configuration saved in M2M-100/random-32000/checkpoint-12000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:38:35,642 >> Configuration saved in M2M-100/random-32000/checkpoint-12000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:38:40,493 >> Model weights saved in M2M-100/random-32000/checkpoint-12000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:38:40,497 >> tokenizer config file saved in M2M-100/random-32000/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:38:40,497 >> Special tokens file saved in M2M-100/random-32000/checkpoint-12000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:38:40,498 >> added tokens file saved in M2M-100/random-32000/checkpoint-12000/added_tokens.json\n","[INFO|trainer.py:2659] 2025-03-31 10:38:54,264 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 9153.7064, 'train_samples_per_second': 10.488, 'train_steps_per_second': 1.311, 'train_loss': 3.0826563212076823, 'epoch': 3.0}\n","100% 12000/12000 [2:32:32<00:00,  1.31it/s]\n","[INFO|trainer.py:3944] 2025-03-31 10:38:54,273 >> Saving model checkpoint to M2M-100/random-32000\n","[INFO|configuration_utils.py:423] 2025-03-31 10:38:54,275 >> Configuration saved in M2M-100/random-32000/config.json\n","[INFO|configuration_utils.py:909] 2025-03-31 10:38:54,276 >> Configuration saved in M2M-100/random-32000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-03-31 10:39:03,232 >> Model weights saved in M2M-100/random-32000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-03-31 10:39:03,235 >> tokenizer config file saved in M2M-100/random-32000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-03-31 10:39:03,236 >> Special tokens file saved in M2M-100/random-32000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-03-31 10:39:03,236 >> added tokens file saved in M2M-100/random-32000/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  6280220GF\n","  train_loss               =     3.0827\n","  train_runtime            = 2:32:33.70\n","  train_samples            =      32000\n","  train_samples_per_second =     10.488\n","  train_steps_per_second   =      1.311\n","03/31/2025 10:39:03 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-03-31 10:39:03,379 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-03-31 10:39:03,379 >>   Num examples = 997\n","[INFO|trainer.py:4265] 2025-03-31 10:39:03,380 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 125/125 [09:39<00:00,  4.64s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     7.2992\n","  eval_chrf               =    41.4763\n","  eval_gen_len            =    46.3952\n","  eval_loss               =     2.3766\n","  eval_runtime            = 0:09:46.26\n","  eval_samples            =        997\n","  eval_samples_per_second =      1.701\n","  eval_steps_per_second   =      0.213\n","03/31/2025 10:48:49 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-03-31 10:48:49,645 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-03-31 10:48:49,645 >>   Num examples = 1012\n","[INFO|trainer.py:4265] 2025-03-31 10:48:49,646 >>   Batch size = 8\n","100% 127/127 [09:59<00:00,  4.72s/it]\n","***** predict metrics *****\n","  predict_bleu               =     7.3328\n","  predict_chrf               =    40.8084\n","  predict_gen_len            =    47.4032\n","  predict_loss               =     2.4042\n","  predict_runtime            = 0:10:05.83\n","  predict_samples            =       1012\n","  predict_samples_per_second =       1.67\n","  predict_steps_per_second   =       0.21\n","[INFO|modelcard.py:449] 2025-03-31 10:59:11,019 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 7.2992}]}\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0,1 /content/AIMS-NLP-Project/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang zu \\\n","    --train_file /content/AIMS-NLP-Project/data/wmt22_african/random/en-zu/train_32000.json \\\n","    --validation_file /content/AIMS-NLP-Project/data/flores/en-zu/dev.json \\\n","    --test_file /content/AIMS-NLP-Project/data/flores/en-zu/devtest.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100/random-32000 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"18e354739b914b7ebde213663315212c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8f1b2a9394949e2b3b49f0efa6c1609","IPY_MODEL_b50d6b0327ba468693e68dd02ddc1ae9","IPY_MODEL_662cd99346404b32a9937c5c4f9c2f40"],"layout":"IPY_MODEL_9d6f41fdd80945afadbc3d1d40a4d621"}},"f8f1b2a9394949e2b3b49f0efa6c1609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ff38c13637442a798f9d9d8ba9f1c9d","placeholder":"","style":"IPY_MODEL_86a5f195e8664d068d6244009b3c13ae","value":"Generatingtrainsplit:"}},"b50d6b0327ba468693e68dd02ddc1ae9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3952ed20c57e4ecf9749766d6d0de90e","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee4d84b071c24252a096c8c7d1a70f25","value":1}},"662cd99346404b32a9937c5c4f9c2f40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d9ba0a3ce84d54a763a25bdeaef1df","placeholder":"","style":"IPY_MODEL_de2d8cc0ac4c432cb9b2905e445595cc","value":"5003/0[00:00&lt;00:00,140288.70examples/s]"}},"9d6f41fdd80945afadbc3d1d40a4d621":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ff38c13637442a798f9d9d8ba9f1c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a5f195e8664d068d6244009b3c13ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3952ed20c57e4ecf9749766d6d0de90e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ee4d84b071c24252a096c8c7d1a70f25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54d9ba0a3ce84d54a763a25bdeaef1df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de2d8cc0ac4c432cb9b2905e445595cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7584bafe63464729a6a2968ee16067a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_568ce92e79db4997b20e6e6a97cad1a8","IPY_MODEL_4aca65fd137343528d36de9644868cfb","IPY_MODEL_cd7025743bd34091b5e50a8b9979f473"],"layout":"IPY_MODEL_7a131a66986b46d1ae93c51a4d3339d5"}},"568ce92e79db4997b20e6e6a97cad1a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11c9982155c4410db25556466e0496a9","placeholder":"","style":"IPY_MODEL_610186b1e05d448ebc9622dbadbb1aea","value":"Generatingvalidationsplit:"}},"4aca65fd137343528d36de9644868cfb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fde9f14690814a05af333842f79d9cad","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_294d6a1afecc48809f59454dbc93ba34","value":1}},"cd7025743bd34091b5e50a8b9979f473":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32ac7484bbd14b8ea615bedfe71284c8","placeholder":"","style":"IPY_MODEL_7698b64d479c49d58a858aa2c55d2f8f","value":"997/0[00:00&lt;00:00,49050.72examples/s]"}},"7a131a66986b46d1ae93c51a4d3339d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11c9982155c4410db25556466e0496a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"610186b1e05d448ebc9622dbadbb1aea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fde9f14690814a05af333842f79d9cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"294d6a1afecc48809f59454dbc93ba34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32ac7484bbd14b8ea615bedfe71284c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7698b64d479c49d58a858aa2c55d2f8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48a77774f5f2406099135fd2845b6385":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c767385e1e44dda8784a663b7f96a7e","IPY_MODEL_7cacbd57017b4a47bb3cf338548fb407","IPY_MODEL_649793ca226448c58fe11f94f8290d45"],"layout":"IPY_MODEL_fab69dac7b1c4dc18e65b1737534246a"}},"2c767385e1e44dda8784a663b7f96a7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b71696d0b46b45c785e1c1c68fa18343","placeholder":"","style":"IPY_MODEL_e9210ff911bd43c29879fb1c879ab369","value":"Generatingtestsplit:"}},"7cacbd57017b4a47bb3cf338548fb407":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1ca98ac79644a97b801fe9f3502fff4","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5974fecde90e4576b0a029d7e9a0dc51","value":1}},"649793ca226448c58fe11f94f8290d45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_894463542cde43a280dab58d9c1c6c32","placeholder":"","style":"IPY_MODEL_ae2a4c7408e2467e8cb291557c8189d5","value":"1012/0[00:00&lt;00:00,46343.88examples/s]"}},"fab69dac7b1c4dc18e65b1737534246a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b71696d0b46b45c785e1c1c68fa18343":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9210ff911bd43c29879fb1c879ab369":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1ca98ac79644a97b801fe9f3502fff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"5974fecde90e4576b0a029d7e9a0dc51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"894463542cde43a280dab58d9c1c6c32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae2a4c7408e2467e8cb291557c8189d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5edb7abcd1f44bf09864800d70db7aa3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_060e5eb6ab664bc68bec198ca0d0bb20","IPY_MODEL_7f69cfaa2eca4d138f227a2a68d11876","IPY_MODEL_2406ee4be4784efd97003c3c34e83a1b"],"layout":"IPY_MODEL_a6ef119b783a41f08da51efe77730f08"}},"060e5eb6ab664bc68bec198ca0d0bb20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3104d6d92604fb5b700d7ddcc5dc28e","placeholder":"","style":"IPY_MODEL_9ad4c10900a04ed69db445f921f8acaa","value":"Runningtokenizerontraindataset:100%"}},"7f69cfaa2eca4d138f227a2a68d11876":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76b386edd779436d9c8bb488b09cd1e2","max":5003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7784e31f60ca4712929a251a16fd939a","value":5003}},"2406ee4be4784efd97003c3c34e83a1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8488896c2e804f6aa9b99262b24cffd8","placeholder":"","style":"IPY_MODEL_2ffe77c11b66401095222525561c31ff","value":"5003/5003[00:02&lt;00:00,2047.14examples/s]"}},"a6ef119b783a41f08da51efe77730f08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3104d6d92604fb5b700d7ddcc5dc28e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ad4c10900a04ed69db445f921f8acaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76b386edd779436d9c8bb488b09cd1e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7784e31f60ca4712929a251a16fd939a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8488896c2e804f6aa9b99262b24cffd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ffe77c11b66401095222525561c31ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e433c024240347eabe9857b62307a91e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad27bd64b4fe4513b14f1df61d6143cb","IPY_MODEL_3355e8642f43481cb05ec43966ea51a0","IPY_MODEL_e6fecc0792194b608412d1da1f7a3fba"],"layout":"IPY_MODEL_16ebb4602e2d4263a070c873375b83f4"}},"ad27bd64b4fe4513b14f1df61d6143cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a8d05edd52546ce9ab36a814e108545","placeholder":"","style":"IPY_MODEL_e97d316b8a6e4f2bb3f1192510459eea","value":"Runningtokenizeronvalidationdataset:100%"}},"3355e8642f43481cb05ec43966ea51a0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20599909f8594343ba156437b5c6cdf0","max":997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6ce8e0f20f234cab91e2b74eaced6971","value":997}},"e6fecc0792194b608412d1da1f7a3fba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0545ab591f214532bbd59b187e0ff1fc","placeholder":"","style":"IPY_MODEL_617dc0451d6d4b68ad364647e360fbab","value":"997/997[00:00&lt;00:00,1576.81examples/s]"}},"16ebb4602e2d4263a070c873375b83f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a8d05edd52546ce9ab36a814e108545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e97d316b8a6e4f2bb3f1192510459eea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20599909f8594343ba156437b5c6cdf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce8e0f20f234cab91e2b74eaced6971":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0545ab591f214532bbd59b187e0ff1fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"617dc0451d6d4b68ad364647e360fbab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7893ab2a24674c0eba1b192736dd6ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0631b86da1134a25abd04c5dd4e65f7e","IPY_MODEL_781d3fbaa2bc44df949d5ef7efa5e7c3","IPY_MODEL_6ff156e5635f4873b630fac7df4862d9"],"layout":"IPY_MODEL_ba4c53d525994c00ba76c974c415bb3c"}},"0631b86da1134a25abd04c5dd4e65f7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_235f9e8df2604d00a7340947098e0a0b","placeholder":"","style":"IPY_MODEL_4402f479752f4d18b6113fc834fea27b","value":"Runningtokenizeronpredictiondataset:100%"}},"781d3fbaa2bc44df949d5ef7efa5e7c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d534a3da51c448ac92620cd1b916db9d","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4f3a7beead8469497bc839f171c2c36","value":1012}},"6ff156e5635f4873b630fac7df4862d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56651c9f0c92424fa406e9b11e06bc25","placeholder":"","style":"IPY_MODEL_133c3f834cd54c6497705971cd3e16c4","value":"1012/1012[00:00&lt;00:00,1530.46examples/s]"}},"ba4c53d525994c00ba76c974c415bb3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"235f9e8df2604d00a7340947098e0a0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4402f479752f4d18b6113fc834fea27b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d534a3da51c448ac92620cd1b916db9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4f3a7beead8469497bc839f171c2c36":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56651c9f0c92424fa406e9b11e06bc25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"133c3f834cd54c6497705971cd3e16c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58b6126a528c4157af5681a379fdcc54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4170874c813f4447bddd1c823fe1345c","IPY_MODEL_2a0b8f5ecdf547e98cc2ae87e65ad854","IPY_MODEL_7727b0a0e093445f869a73f59b446e65"],"layout":"IPY_MODEL_bc9d1283f79d4b9ebbb8045adfcaf353"}},"4170874c813f4447bddd1c823fe1345c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70f6023c48454e679e39574cd6689a9d","placeholder":"","style":"IPY_MODEL_1601636eca2346a6b705e7403e9e963a","value":"Generatingtrainsplit:"}},"2a0b8f5ecdf547e98cc2ae87e65ad854":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c26f84227d064e86b9e79e08d3ca2938","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8258ceb5c6646c3a7bab4c4da1e8039","value":1}},"7727b0a0e093445f869a73f59b446e65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6bb6ebf376b74b99ba9c3354a107bdd6","placeholder":"","style":"IPY_MODEL_5ed7b66183844080b2db7b7eb8fe9877","value":"6121/0[00:00&lt;00:00,202642.09examples/s]"}},"bc9d1283f79d4b9ebbb8045adfcaf353":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f6023c48454e679e39574cd6689a9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1601636eca2346a6b705e7403e9e963a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c26f84227d064e86b9e79e08d3ca2938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f8258ceb5c6646c3a7bab4c4da1e8039":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6bb6ebf376b74b99ba9c3354a107bdd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ed7b66183844080b2db7b7eb8fe9877":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dc0bd3e71c7436092553482582b6aaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_161a9a25f1bd41aeae1fe689482ced2d","IPY_MODEL_b1b4a4c90efb462684b9aa9a79d8e9ab","IPY_MODEL_facbfab6a6bb4e2294323777f2c28847"],"layout":"IPY_MODEL_9fb175540bc04271a43f832170624740"}},"161a9a25f1bd41aeae1fe689482ced2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e3081900c4b428db3811593174d19c5","placeholder":"","style":"IPY_MODEL_eaffbd2bed9c47b4b160ed20a831eb6c","value":"Generatingvalidationsplit:"}},"b1b4a4c90efb462684b9aa9a79d8e9ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_242c8b6d58254584b5395774b0e71146","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a2e518b3bbce40679252ae16e5b55d18","value":1}},"facbfab6a6bb4e2294323777f2c28847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52ab29dc6b424f508ad182b417611d5c","placeholder":"","style":"IPY_MODEL_490126a62f114ad6a42ca8adcafa7d8e","value":"997/0[00:00&lt;00:00,47124.36examples/s]"}},"9fb175540bc04271a43f832170624740":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3081900c4b428db3811593174d19c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaffbd2bed9c47b4b160ed20a831eb6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"242c8b6d58254584b5395774b0e71146":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a2e518b3bbce40679252ae16e5b55d18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52ab29dc6b424f508ad182b417611d5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490126a62f114ad6a42ca8adcafa7d8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1a1c81d2ae84d7a9c6c0a9a72d5b2d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f964bfd73bc64096b64f8ace04a4d8b1","IPY_MODEL_3e22f377049641f7b00b17d5dc3dd667","IPY_MODEL_a6afaacfb61446778ec0c5b817ab509f"],"layout":"IPY_MODEL_e8e361559ee44ccea9486f85a71bdcef"}},"f964bfd73bc64096b64f8ace04a4d8b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_095c2b0dcef34b26ab8a3298560b1c41","placeholder":"","style":"IPY_MODEL_025dd055b4d04456acaa58a214e4a8f1","value":"Generatingtestsplit:"}},"3e22f377049641f7b00b17d5dc3dd667":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f6510a34a2c4413a4fe76a8f2d261c1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7713c2de056645b089dd26e96f513262","value":1}},"a6afaacfb61446778ec0c5b817ab509f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feccf55fe1264fb0a8b27036f4d1cd31","placeholder":"","style":"IPY_MODEL_d06b635e46db4d1b8f71d78905087c01","value":"1012/0[00:00&lt;00:00,51423.95examples/s]"}},"e8e361559ee44ccea9486f85a71bdcef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"095c2b0dcef34b26ab8a3298560b1c41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"025dd055b4d04456acaa58a214e4a8f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f6510a34a2c4413a4fe76a8f2d261c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7713c2de056645b089dd26e96f513262":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"feccf55fe1264fb0a8b27036f4d1cd31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d06b635e46db4d1b8f71d78905087c01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aed9217b9b014dd9894f774cad5cde3e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b7346b3d1ab4147bab02105bd3dff93","IPY_MODEL_60c6e771e8e94167aaa9ad27bef78c86","IPY_MODEL_771ed34cfad14015b9690c23e7428b27"],"layout":"IPY_MODEL_e97e8e8f103f4af5907057939efb44e7"}},"0b7346b3d1ab4147bab02105bd3dff93":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f0febe7586b482b81b4d1865d99fae6","placeholder":"","style":"IPY_MODEL_0870bed0d707449298deb6fc40241e1a","value":"Runningtokenizerontraindataset:100%"}},"60c6e771e8e94167aaa9ad27bef78c86":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a7017a2a9444efa710663d36368d4e","max":6121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_936060b009d04e0ca051324a3757fee5","value":6121}},"771ed34cfad14015b9690c23e7428b27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_143375c8d2d64c209fd8ffb9403c050a","placeholder":"","style":"IPY_MODEL_f1676a04c4534096b7fcebc5ff65c7a0","value":"6121/6121[00:04&lt;00:00,1397.40examples/s]"}},"e97e8e8f103f4af5907057939efb44e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f0febe7586b482b81b4d1865d99fae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0870bed0d707449298deb6fc40241e1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55a7017a2a9444efa710663d36368d4e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"936060b009d04e0ca051324a3757fee5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"143375c8d2d64c209fd8ffb9403c050a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1676a04c4534096b7fcebc5ff65c7a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bc27fd6a4a84f5b9d9f82c4016bea99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a9b2cb27d994577983dc8bca7a8b0eb","IPY_MODEL_0970b11e2ac4438da3f85e53831a4f65","IPY_MODEL_b6e454f1a6bf428f960a341dfc318323"],"layout":"IPY_MODEL_c68fcaa9c4654f789c0bf04e43f33754"}},"8a9b2cb27d994577983dc8bca7a8b0eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_315e7f389052463fafd1ea386d1b1a87","placeholder":"","style":"IPY_MODEL_1956205c963c487fab73f3b634eb7eb8","value":"Runningtokenizeronvalidationdataset:100%"}},"0970b11e2ac4438da3f85e53831a4f65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30abfbc51bdb4a65949e373be0c02687","max":997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_79034f04c5424f9cb1d75cf61ef8f969","value":997}},"b6e454f1a6bf428f960a341dfc318323":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c69d71bd8794d68a95a2a92aafae23e","placeholder":"","style":"IPY_MODEL_eb0b65641aa1413ba2ce95fdc3177410","value":"997/997[00:00&lt;00:00,1728.80examples/s]"}},"c68fcaa9c4654f789c0bf04e43f33754":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"315e7f389052463fafd1ea386d1b1a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1956205c963c487fab73f3b634eb7eb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30abfbc51bdb4a65949e373be0c02687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79034f04c5424f9cb1d75cf61ef8f969":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c69d71bd8794d68a95a2a92aafae23e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb0b65641aa1413ba2ce95fdc3177410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6887cd6d0b9746b586af15eba6e2e8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49cfa26cf06e42d8b17155d91518a127","IPY_MODEL_c55bfcadb69a42229f72ff26b7d0a28a","IPY_MODEL_f6562fb7589146a189129211742b98dd"],"layout":"IPY_MODEL_b61b64f0a536416b976d3c0e49aaa355"}},"49cfa26cf06e42d8b17155d91518a127":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfdd8fbe2eb548498a7055e21e38da1a","placeholder":"","style":"IPY_MODEL_61417713e8a24026af4c036c7ea745e5","value":"Runningtokenizeronpredictiondataset:100%"}},"c55bfcadb69a42229f72ff26b7d0a28a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fac2b737c1e04fcca7292f18a9796c6d","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_593f1f9ccf0c4107bfcdc5277d389003","value":1012}},"f6562fb7589146a189129211742b98dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b4a074d215a4305b083fe5710c4b12a","placeholder":"","style":"IPY_MODEL_5945a657e5e44bbc912255e804ce08cd","value":"1012/1012[00:00&lt;00:00,1653.83examples/s]"}},"b61b64f0a536416b976d3c0e49aaa355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfdd8fbe2eb548498a7055e21e38da1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61417713e8a24026af4c036c7ea745e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fac2b737c1e04fcca7292f18a9796c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"593f1f9ccf0c4107bfcdc5277d389003":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b4a074d215a4305b083fe5710c4b12a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5945a657e5e44bbc912255e804ce08cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a6b8610210040fe93a96bedb082ff68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be2a59005ca6481b8846b9f61791b0d5","IPY_MODEL_19e9fe6f06b0489b815e179035a3d4a5","IPY_MODEL_c6b8b86c4b974215b170a7f7b1b2c2ad"],"layout":"IPY_MODEL_56e86863ff8843a78f85a789ca8be6d3"}},"be2a59005ca6481b8846b9f61791b0d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_22ce6615f29f4fe2a7ac8f63503ab383","placeholder":"","style":"IPY_MODEL_756eb886d7a34f85b0f42d391abcf381","value":"Generatingtrainsplit:"}},"19e9fe6f06b0489b815e179035a3d4a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e34143948a0476ba5a731cfb92c8d04","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1b9a0d6500042fe8892cb4cc9b61aee","value":1}},"c6b8b86c4b974215b170a7f7b1b2c2ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_586a4c7004b04d00a44bf03de74901d2","placeholder":"","style":"IPY_MODEL_cf5f821056d6462cbe85870dcd8462fa","value":"8665/0[00:00&lt;00:00,249123.59examples/s]"}},"56e86863ff8843a78f85a789ca8be6d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22ce6615f29f4fe2a7ac8f63503ab383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"756eb886d7a34f85b0f42d391abcf381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e34143948a0476ba5a731cfb92c8d04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"c1b9a0d6500042fe8892cb4cc9b61aee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"586a4c7004b04d00a44bf03de74901d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf5f821056d6462cbe85870dcd8462fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd061ae80c174faea56692de3e376308":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_70a7b97e2dd24bd2b424ae905c7b0e41","IPY_MODEL_9e847f9f273a4df8b4dc28f234e63af4","IPY_MODEL_3278491357084d36b2dc97559d0869fd"],"layout":"IPY_MODEL_2e4b04b3155f463d9c9a3d8878366b52"}},"70a7b97e2dd24bd2b424ae905c7b0e41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_853c833465e144a9b70f8b04a5784c75","placeholder":"","style":"IPY_MODEL_0ad5839b9b054d809b56949515ea60e9","value":"Generatingvalidationsplit:"}},"9e847f9f273a4df8b4dc28f234e63af4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c91940103154430b34a03c77b46c06f","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7149d97d08ad4d55a734216d221e5959","value":1}},"3278491357084d36b2dc97559d0869fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c0f64bf34554de3aaad6ff463534b7d","placeholder":"","style":"IPY_MODEL_2121473a680a490c8836814940660f1a","value":"997/0[00:00&lt;00:00,48170.41examples/s]"}},"2e4b04b3155f463d9c9a3d8878366b52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"853c833465e144a9b70f8b04a5784c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ad5839b9b054d809b56949515ea60e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c91940103154430b34a03c77b46c06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"7149d97d08ad4d55a734216d221e5959":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c0f64bf34554de3aaad6ff463534b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2121473a680a490c8836814940660f1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a11ff0a9ba89464fb7ea81ee2fe2cbae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97a0e588734549f98bb2f55bfc372963","IPY_MODEL_643aad3a4d1b4971826e15b6ca98a00e","IPY_MODEL_c562ced07e034a8ea6327c67cc820239"],"layout":"IPY_MODEL_040c57119a3e4bef9b41ec9b83162a87"}},"97a0e588734549f98bb2f55bfc372963":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9590091ebdc4250a3577974683ae392","placeholder":"","style":"IPY_MODEL_f7b515d6cf4a43fd9e0dc00383c72556","value":"Generatingtestsplit:"}},"643aad3a4d1b4971826e15b6ca98a00e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbbfb826cf46403783312b3aa38a2145","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1ee2e1941762431b9931621c69a2b21a","value":1}},"c562ced07e034a8ea6327c67cc820239":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab06d47d3bee417ab29e73c9eab8a41e","placeholder":"","style":"IPY_MODEL_8f95991e5a8e4b9bb409b55aac771f24","value":"1012/0[00:00&lt;00:00,53880.29examples/s]"}},"040c57119a3e4bef9b41ec9b83162a87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9590091ebdc4250a3577974683ae392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7b515d6cf4a43fd9e0dc00383c72556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbbfb826cf46403783312b3aa38a2145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"1ee2e1941762431b9931621c69a2b21a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab06d47d3bee417ab29e73c9eab8a41e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f95991e5a8e4b9bb409b55aac771f24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"396d5d2f80474832850d52cff455493f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_17a73c3f09b743879e5de32cd3a4c00b","IPY_MODEL_831416f1365c4dd19c1ee8fedb3c8b4f","IPY_MODEL_d565f72da82f42d89b14ab4201de292a"],"layout":"IPY_MODEL_bfa4061e10f342e49f243c4bcc8142c6"}},"17a73c3f09b743879e5de32cd3a4c00b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38d8e4a99d6443dabdfb19235fb54efc","placeholder":"","style":"IPY_MODEL_7013c546fcb54229804ec365d21a0c69","value":"Runningtokenizerontraindataset:100%"}},"831416f1365c4dd19c1ee8fedb3c8b4f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_417b651761e345f59a8a3e95ff186bda","max":8665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b25138baf88497c91056f467ef5fa78","value":8665}},"d565f72da82f42d89b14ab4201de292a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0341432788714b458b581f6377e3c5bc","placeholder":"","style":"IPY_MODEL_c8179419a2654194a00a38741bcca8a6","value":"8665/8665[00:05&lt;00:00,1591.85examples/s]"}},"bfa4061e10f342e49f243c4bcc8142c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38d8e4a99d6443dabdfb19235fb54efc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7013c546fcb54229804ec365d21a0c69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"417b651761e345f59a8a3e95ff186bda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b25138baf88497c91056f467ef5fa78":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0341432788714b458b581f6377e3c5bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8179419a2654194a00a38741bcca8a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3444cacdf0f14324ba44568001756eed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5ea06aa9f11a44baaa50b40d6fb6d4bf","IPY_MODEL_6e58ac66baad4b9c912df21aeaf390c5","IPY_MODEL_b9c78fb067e04b898be3263cb930ceed"],"layout":"IPY_MODEL_fd514d9786f84b5c876df3bc0b28c9eb"}},"5ea06aa9f11a44baaa50b40d6fb6d4bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51b640fd793a4b83b4fb3123f0b28d18","placeholder":"","style":"IPY_MODEL_7e65bc45a5674e81a4ce6e6605f6354b","value":"Runningtokenizeronvalidationdataset:100%"}},"6e58ac66baad4b9c912df21aeaf390c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_928363012fbf47cf92c4cc0ee6d8c094","max":997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d167bf696d349a489bd54cd4b934637","value":997}},"b9c78fb067e04b898be3263cb930ceed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_438848ce708b40b7b909f8f341c0b3cd","placeholder":"","style":"IPY_MODEL_45b6f8d739294a5a814619dd033eba91","value":"997/997[00:00&lt;00:00,1852.62examples/s]"}},"fd514d9786f84b5c876df3bc0b28c9eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51b640fd793a4b83b4fb3123f0b28d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e65bc45a5674e81a4ce6e6605f6354b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"928363012fbf47cf92c4cc0ee6d8c094":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d167bf696d349a489bd54cd4b934637":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"438848ce708b40b7b909f8f341c0b3cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b6f8d739294a5a814619dd033eba91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d1b40e1a6a74b29a47c662eeade465f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91a741fa72ff4477b543a022318205f7","IPY_MODEL_59f8c2a0d76e448f8a41297c705cb147","IPY_MODEL_858eb26fcef343908c2577d1d450c5cd"],"layout":"IPY_MODEL_0223399acb0d4b289fe5dc44fa6994e0"}},"91a741fa72ff4477b543a022318205f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc0816f55db44baba346a39d861c859f","placeholder":"","style":"IPY_MODEL_f6ee0afcfae84daeb9369d6cda684225","value":"Runningtokenizeronpredictiondataset:100%"}},"59f8c2a0d76e448f8a41297c705cb147":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b48885248846d5af662b5307f6ab23","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71479537af01475b9bab888aa19311f4","value":1012}},"858eb26fcef343908c2577d1d450c5cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd61aa68f7a24542a474b1f8fbaf8db6","placeholder":"","style":"IPY_MODEL_a1b4b68551a348a4892ecd4da49318be","value":"1012/1012[00:00&lt;00:00,1808.93examples/s]"}},"0223399acb0d4b289fe5dc44fa6994e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc0816f55db44baba346a39d861c859f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ee0afcfae84daeb9369d6cda684225":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02b48885248846d5af662b5307f6ab23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71479537af01475b9bab888aa19311f4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cd61aa68f7a24542a474b1f8fbaf8db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1b4b68551a348a4892ecd4da49318be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52252d6da4824a989fbdc66354f61161":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab592135229d46ba99e46e9cab569463","IPY_MODEL_3c42a546761d4146a3ed09e8a6f469af","IPY_MODEL_a87a725a62e247699feb03e65f1ab8e0"],"layout":"IPY_MODEL_ee7e6578546a44f3a477f66254efc125"}},"ab592135229d46ba99e46e9cab569463":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4a874ac43b24ba69d8a72c333243a3f","placeholder":"","style":"IPY_MODEL_c9be883a5f794f949c58c4f39ef00f50","value":"Generatingtrainsplit:"}},"3c42a546761d4146a3ed09e8a6f469af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1a756c812324695b955dd46436376ca","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eef7765a78ac4d1daa0553b45925e3fc","value":1}},"a87a725a62e247699feb03e65f1ab8e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bd0e0f76002487383b6d8117ec96210","placeholder":"","style":"IPY_MODEL_cac4054ca1cb4b2da90becee13fa4b0a","value":"9998/0[00:00&lt;00:00,260998.64examples/s]"}},"ee7e6578546a44f3a477f66254efc125":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4a874ac43b24ba69d8a72c333243a3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9be883a5f794f949c58c4f39ef00f50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1a756c812324695b955dd46436376ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"eef7765a78ac4d1daa0553b45925e3fc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8bd0e0f76002487383b6d8117ec96210":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac4054ca1cb4b2da90becee13fa4b0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f264dbdc11684370bd9a2e40bb282a7e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_253b882ff7ef4f9fa10f48c286b80987","IPY_MODEL_2ac68027810543c9833e5317f17e074b","IPY_MODEL_9389e60b3d15472c9c213efbb79aa5a5"],"layout":"IPY_MODEL_4e1190a19d99402ebeff547509a1db25"}},"253b882ff7ef4f9fa10f48c286b80987":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5916cc4149d8444a83c5ff37bf5ee643","placeholder":"","style":"IPY_MODEL_e2be632b6dfe4fd987ae333525fc7a1a","value":"Generatingvalidationsplit:"}},"2ac68027810543c9833e5317f17e074b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51f7dfe6d6d54a16ae8b8bf64f03c2d9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4f0bd7a7ec84d41935826b7cd925739","value":1}},"9389e60b3d15472c9c213efbb79aa5a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26feee206a744090ba91d5a9ddf04b99","placeholder":"","style":"IPY_MODEL_2ac0f48294514b5f9df96132bc7f8ef2","value":"997/0[00:00&lt;00:00,48197.06examples/s]"}},"4e1190a19d99402ebeff547509a1db25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5916cc4149d8444a83c5ff37bf5ee643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2be632b6dfe4fd987ae333525fc7a1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51f7dfe6d6d54a16ae8b8bf64f03c2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"a4f0bd7a7ec84d41935826b7cd925739":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26feee206a744090ba91d5a9ddf04b99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ac0f48294514b5f9df96132bc7f8ef2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6752651b5a3b470b84414f4958411ce9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ef5b950ee194b8bb9a198661859c3bd","IPY_MODEL_6c2d4f3c4a934deca015e05e499fff52","IPY_MODEL_34ba435ba42f44d3bf1e05b4179a2866"],"layout":"IPY_MODEL_aa26496f37e647c9b6bdb31e82f3477d"}},"9ef5b950ee194b8bb9a198661859c3bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3a50d9d26f432c81a74707dcc4c037","placeholder":"","style":"IPY_MODEL_e049c83a9df0478297b8fd3ef8579865","value":"Generatingtestsplit:"}},"6c2d4f3c4a934deca015e05e499fff52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2211163a84fd4a83bda7f7938c68d4e5","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_726946aba15b4287a07f3490e91f6b88","value":1}},"34ba435ba42f44d3bf1e05b4179a2866":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21e69b4469cd4656a1c447cf1ce1bc02","placeholder":"","style":"IPY_MODEL_b911c45fb9b14d5fa7e144ec694097d8","value":"1012/0[00:00&lt;00:00,42633.09examples/s]"}},"aa26496f37e647c9b6bdb31e82f3477d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a3a50d9d26f432c81a74707dcc4c037":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e049c83a9df0478297b8fd3ef8579865":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2211163a84fd4a83bda7f7938c68d4e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"726946aba15b4287a07f3490e91f6b88":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21e69b4469cd4656a1c447cf1ce1bc02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b911c45fb9b14d5fa7e144ec694097d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"248f360bd35849398a577470ab4846c8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3dde59e58dfb45d2b2e1cb101fe3530b","IPY_MODEL_ee6c704e31c642beb40cb7fc9620c2c2","IPY_MODEL_72b341f25e154d669efe19f5ef12da17"],"layout":"IPY_MODEL_278ccfdc9f97468d8ad819c2376ed334"}},"3dde59e58dfb45d2b2e1cb101fe3530b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcff7952585840a293cd2ac390376c7c","placeholder":"","style":"IPY_MODEL_592da6a66c4442eab9e780039654d7d9","value":"Runningtokenizerontraindataset:100%"}},"ee6c704e31c642beb40cb7fc9620c2c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e9b8538dda4f7a97ecc036604fd465","max":9998,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0419bfc992e46c0bc9cabfbb14fdaff","value":9998}},"72b341f25e154d669efe19f5ef12da17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9bf68032d6ac4f9083ae48550867b148","placeholder":"","style":"IPY_MODEL_c20d078e499646db87eb9e715784522e","value":"9998/9998[00:04&lt;00:00,2200.05examples/s]"}},"278ccfdc9f97468d8ad819c2376ed334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcff7952585840a293cd2ac390376c7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"592da6a66c4442eab9e780039654d7d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81e9b8538dda4f7a97ecc036604fd465":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0419bfc992e46c0bc9cabfbb14fdaff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9bf68032d6ac4f9083ae48550867b148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c20d078e499646db87eb9e715784522e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"799da935d81c45a399335a62bc10e94c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c8914e05b19549009ecc9cef73b6847c","IPY_MODEL_da84f6d5ce074deabb8ee268d48bc2a6","IPY_MODEL_0afb2f0eb2b743ae8a7ce25a939b593b"],"layout":"IPY_MODEL_d7306b9076f4489284d8cf3ce6e40ad0"}},"c8914e05b19549009ecc9cef73b6847c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e5ac6894f924a9093aceb2092674c70","placeholder":"","style":"IPY_MODEL_57c0023a56264298be3a42e9ba63b466","value":"Runningtokenizeronvalidationdataset:100%"}},"da84f6d5ce074deabb8ee268d48bc2a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f64f18f94c3b44cc8828e763df93e480","max":997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b6c5f24eb2c44f44a31797d4c8d5f82d","value":997}},"0afb2f0eb2b743ae8a7ce25a939b593b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99e9880687ce44259e3af28b0df5d187","placeholder":"","style":"IPY_MODEL_0bb1b3ff6e4c4cfe987edc5afbfcd3b3","value":"997/997[00:00&lt;00:00,1801.31examples/s]"}},"d7306b9076f4489284d8cf3ce6e40ad0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5ac6894f924a9093aceb2092674c70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c0023a56264298be3a42e9ba63b466":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f64f18f94c3b44cc8828e763df93e480":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6c5f24eb2c44f44a31797d4c8d5f82d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99e9880687ce44259e3af28b0df5d187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0bb1b3ff6e4c4cfe987edc5afbfcd3b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d792ee661a524ec3b1155155721b3da7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1034928bf9854f0e87d502d748923697","IPY_MODEL_b1598f206510493ab56bf31e6568cd25","IPY_MODEL_1bb99aa4e8864a6380b5d13a8a24bbd1"],"layout":"IPY_MODEL_6f690735a69c44eaba08a66af5f5b69b"}},"1034928bf9854f0e87d502d748923697":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd363892dc1644318747ff0e006a0fac","placeholder":"","style":"IPY_MODEL_e49afd1083b24347aa5382680ba8a71b","value":"Runningtokenizeronpredictiondataset:100%"}},"b1598f206510493ab56bf31e6568cd25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d5fa13327de496f93abedcfd6e21999","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9d0480e0756a42e781cfc69de7e7f421","value":1012}},"1bb99aa4e8864a6380b5d13a8a24bbd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30e882558cd0404cac5fcbef8a87ed6a","placeholder":"","style":"IPY_MODEL_1ce8279221ae4aa9a9186a090696d54c","value":"1012/1012[00:00&lt;00:00,1733.48examples/s]"}},"6f690735a69c44eaba08a66af5f5b69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd363892dc1644318747ff0e006a0fac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e49afd1083b24347aa5382680ba8a71b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d5fa13327de496f93abedcfd6e21999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d0480e0756a42e781cfc69de7e7f421":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"30e882558cd0404cac5fcbef8a87ed6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ce8279221ae4aa9a9186a090696d54c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d68fec237bb94e84836918bd11245422":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5583b01abd8743769d5fee932e9cf3c6","IPY_MODEL_ad32ac6516684b61898e5313e52618af","IPY_MODEL_201697c34e4f44239bed6ce86d358085"],"layout":"IPY_MODEL_3edd9f47074e4b5e9f813b4c91d40537"}},"5583b01abd8743769d5fee932e9cf3c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3e54a10869f4fbe938c8521cc2d4f26","placeholder":"","style":"IPY_MODEL_a7355af0ea2e44a0a3ecddd8c03e6152","value":"Generatingtrainsplit:"}},"ad32ac6516684b61898e5313e52618af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5087ec0b0a345e4938b2aa1d3c2bc63","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80420145b0b940d2ba043bbe151ba467","value":1}},"201697c34e4f44239bed6ce86d358085":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f84ca03e7f77461880026207611e7687","placeholder":"","style":"IPY_MODEL_9e790c2125634710afcfd2c464daf17b","value":"9746/0[00:00&lt;00:00,151626.28examples/s]"}},"3edd9f47074e4b5e9f813b4c91d40537":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3e54a10869f4fbe938c8521cc2d4f26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7355af0ea2e44a0a3ecddd8c03e6152":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5087ec0b0a345e4938b2aa1d3c2bc63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"80420145b0b940d2ba043bbe151ba467":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f84ca03e7f77461880026207611e7687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e790c2125634710afcfd2c464daf17b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7aefb6db6c134089b01f39894e1019ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95ecef486878458d801765c581924791","IPY_MODEL_9164538d1dd54fbe8c0c4728f7738103","IPY_MODEL_07ccc2ee8c114c199ceadc4b14ddbb08"],"layout":"IPY_MODEL_3e595d72275b4c16a6c02e9b76a5e6c7"}},"95ecef486878458d801765c581924791":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62bf148dd1b54b19ba0f4a1b27c2f433","placeholder":"","style":"IPY_MODEL_a59636048ac74ef39f0926cedf97bfc8","value":"Generatingvalidationsplit:"}},"9164538d1dd54fbe8c0c4728f7738103":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_394f47b77a6f4813a969ae6dcc40c96d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f4cd0bb217b4664856788439f316e13","value":1}},"07ccc2ee8c114c199ceadc4b14ddbb08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ebd83a0ac3494d229c68e89d3b7b5ed9","placeholder":"","style":"IPY_MODEL_b4de2085fe8e400ebab370e5629012d4","value":"997/0[00:00&lt;00:00,47331.84examples/s]"}},"3e595d72275b4c16a6c02e9b76a5e6c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62bf148dd1b54b19ba0f4a1b27c2f433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a59636048ac74ef39f0926cedf97bfc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"394f47b77a6f4813a969ae6dcc40c96d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4f4cd0bb217b4664856788439f316e13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ebd83a0ac3494d229c68e89d3b7b5ed9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4de2085fe8e400ebab370e5629012d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8a9ae8f374841dd87c308b437d95077":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c91483c1a49478baa9dfe885d82cf0c","IPY_MODEL_656e0184748e412199f5b0b2162441da","IPY_MODEL_f5f82472948842d08ea0007ba0b6279f"],"layout":"IPY_MODEL_4d94b212d8fd4bc18beffd47c5ab275d"}},"7c91483c1a49478baa9dfe885d82cf0c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_200697e47b3248a3b55fb23aa44a2745","placeholder":"","style":"IPY_MODEL_f37b7d6fcee94aa198ecf9fa581f61fc","value":"Generatingtestsplit:"}},"656e0184748e412199f5b0b2162441da":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baae1b4441c64130b5d494554c1a0369","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9619d16d80e64b948668e3d979c46fcc","value":1}},"f5f82472948842d08ea0007ba0b6279f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71bb74baf43f447c9fe6e5593531613b","placeholder":"","style":"IPY_MODEL_022e191469004ad2adfa7f1c325c8769","value":"1012/0[00:00&lt;00:00,47464.81examples/s]"}},"4d94b212d8fd4bc18beffd47c5ab275d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"200697e47b3248a3b55fb23aa44a2745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f37b7d6fcee94aa198ecf9fa581f61fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baae1b4441c64130b5d494554c1a0369":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"9619d16d80e64b948668e3d979c46fcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"71bb74baf43f447c9fe6e5593531613b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"022e191469004ad2adfa7f1c325c8769":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5539c2c3cc5429fa6a3da10631c7f4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49507ce27ecc414ea48dda9728d379f7","IPY_MODEL_476a303e8121485a9dd5d1f32ad688cf","IPY_MODEL_c5e14a7d4628403b87dd25bf45c87e5e"],"layout":"IPY_MODEL_b22020e48e394fe4a18652fda8bc23e2"}},"49507ce27ecc414ea48dda9728d379f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4fa21d5199f428fb7d0ef75f3c4524b","placeholder":"","style":"IPY_MODEL_ce01bf43fa9d4aca82d8aec3a14113a4","value":"Runningtokenizerontraindataset:100%"}},"476a303e8121485a9dd5d1f32ad688cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e24557ca6e5d432caac03b37ce95780d","max":9746,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc249200899c49e0b78519b5ddab1215","value":9746}},"c5e14a7d4628403b87dd25bf45c87e5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5237dc272968482697f2b87eb072b629","placeholder":"","style":"IPY_MODEL_d2de7cdb7aae45b68c529202554e3af9","value":"9746/9746[00:06&lt;00:00,1563.65examples/s]"}},"b22020e48e394fe4a18652fda8bc23e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4fa21d5199f428fb7d0ef75f3c4524b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce01bf43fa9d4aca82d8aec3a14113a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e24557ca6e5d432caac03b37ce95780d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc249200899c49e0b78519b5ddab1215":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5237dc272968482697f2b87eb072b629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2de7cdb7aae45b68c529202554e3af9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6b9a927f0f34279943874855d5fb5fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c658c27f62848a4b86ad7526cd8b122","IPY_MODEL_0f064a02f859466489a7ee2a11f569cb","IPY_MODEL_88e449708243440ebd57608ad0553b59"],"layout":"IPY_MODEL_b5bc1a96413843b2adbc340febdb91f7"}},"8c658c27f62848a4b86ad7526cd8b122":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd65aa1df84143c89693a1da33bb42ba","placeholder":"","style":"IPY_MODEL_93d0ae0bdd0a440583fd6e7eda033207","value":"Runningtokenizeronvalidationdataset:100%"}},"0f064a02f859466489a7ee2a11f569cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_684abaf47da64300bda3d1a85d760241","max":997,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3086588e850a46c08a717fe6a5ed7873","value":997}},"88e449708243440ebd57608ad0553b59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b019e87daa164b32a318251da0385829","placeholder":"","style":"IPY_MODEL_7f03728d3b2a4d868ab4be884da05fba","value":"997/997[00:00&lt;00:00,1697.87examples/s]"}},"b5bc1a96413843b2adbc340febdb91f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd65aa1df84143c89693a1da33bb42ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93d0ae0bdd0a440583fd6e7eda033207":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"684abaf47da64300bda3d1a85d760241":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3086588e850a46c08a717fe6a5ed7873":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b019e87daa164b32a318251da0385829":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f03728d3b2a4d868ab4be884da05fba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad695ce74d2a4d0495e319839dc24831":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a2bf4d2223e48c58d415bb10e351393","IPY_MODEL_de2b04c4e86b40629fbf8da0f6572ed8","IPY_MODEL_3691bc4082d54753bec81be256d75c6f"],"layout":"IPY_MODEL_c1313549fce04ab7a8c949cf574b96a8"}},"6a2bf4d2223e48c58d415bb10e351393":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d055765b7984994897d23ffe1c7b36c","placeholder":"","style":"IPY_MODEL_ed635958bee64a7dbc32e6f33dfeb56b","value":"Runningtokenizeronpredictiondataset:100%"}},"de2b04c4e86b40629fbf8da0f6572ed8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4c913b08aad462c97dca91856e9e4c4","max":1012,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d63a0c0766b7413cb7a693ef12d5dbae","value":1012}},"3691bc4082d54753bec81be256d75c6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a482f0ebde4d9fa9fcefcdf9c46f1b","placeholder":"","style":"IPY_MODEL_67827431c6134a4ea986ac83c3e1e34e","value":"1012/1012[00:00&lt;00:00,1677.71examples/s]"}},"c1313549fce04ab7a8c949cf574b96a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d055765b7984994897d23ffe1c7b36c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed635958bee64a7dbc32e6f33dfeb56b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4c913b08aad462c97dca91856e9e4c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63a0c0766b7413cb7a693ef12d5dbae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04a482f0ebde4d9fa9fcefcdf9c46f1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67827431c6134a4ea986ac83c3e1e34e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}