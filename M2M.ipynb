{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmtN4egQXSDg0WsHWW1HLr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZW0rzDZuRN55"},"outputs":[],"source":["import jsonlines\n","import numpy as np\n","import heapq\n","import wandb\n","from huggingface_hub import login\n","from datasets import load_dataset, Dataset, DatasetDict, load_from_disk\n","from comet import download_model, load_from_checkpoint"]},{"cell_type":"code","source":["# Log in with your API key\n","wandb.login(key=\"7f13d9fe09d0856f7c12099a27ccda7aa15c8afd\")\n","\n","# Initialize WandB\n","wandb.init(project=\"translation_project\", name=\"prelims\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"aggyfHIUR2zp","executionInfo":{"status":"ok","timestamp":1740391798703,"user_tz":-120,"elapsed":168,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"bfcaa8a4-85c3-4498-b7a1-a0fbb348ef9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/paderborn-university/translation_project/runs/o6gycihd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7c4532e83bb0>"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["!CUDA_VISIBLE_DEVICES=0,1 python transformers/examples/pytorch/translation/run_translation.py \\\n","    --model_name_or_path facebook/m2m100_418M \\\n","    --do_train \\\n","    --do_eval \\\n","    --do_predict \\\n","    --source_lang en \\\n","    --target_lang xh \\\n","    --dataset_config_name eng-xho \\\n","    --train_file data/en-xh/trainset.json \\\n","    --validation_file data/en-xh/valset.json \\\n","    --test_file data/en-xh/testset.json \\\n","    --num_beams 10 \\\n","    --output_dir M2M-100 \\\n","    --per_device_train_batch_size=4 \\\n","    --per_device_eval_batch_size=4 \\\n","    --overwrite_output_dir \\\n","    --predict_with_generate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvM-Zf4jUO81","outputId":"86f3453e-6409-447b-ea6c-4b63bf775501","executionInfo":{"status":"ok","timestamp":1740396255533,"user_tz":-120,"elapsed":2117955,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["2025-02-24 10:10:02.626849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2025-02-24 10:10:02.648893: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2025-02-24 10:10:02.655627: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2025-02-24 10:10:03.710117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","02/24/2025 10:10:06 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2, distributed training: False, 16-bits training: False\n","02/24/2025 10:10:06 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=2,\n","accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","average_tokens_across_devices=False,\n","batch_eval_metrics=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","dataloader_prefetch_factor=None,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=True,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_do_concat_batches=True,\n","eval_on_start=False,\n","eval_steps=None,\n","eval_strategy=no,\n","eval_use_gather_object=False,\n","evaluation_strategy=None,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=None,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_for_metrics=[],\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=M2M-100/runs/Feb24_10-10-06_bcdd196dbaf2,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","optim_target_modules=None,\n","output_dir=M2M-100,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=4,\n","per_device_train_batch_size=4,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard', 'wandb'],\n","restore_callback_states_from_checkpoint=False,\n","resume_from_checkpoint=None,\n","run_name=M2M-100,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","split_batches=None,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torch_empty_cache_steps=None,\n","torchdynamo=None,\n","tp_size=0,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_liger_kernel=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-7f46d737aa0519c2\n","02/24/2025 10:10:06 - INFO - datasets.builder - Using custom data configuration default-7f46d737aa0519c2\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","02/24/2025 10:10:06 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","Overwrite dataset info from restored data version if exists.\n","02/24/2025 10:10:06 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","02/24/2025 10:10:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","02/24/2025 10:10:06 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n","Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","02/24/2025 10:10:06 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n","[INFO|configuration_utils.py:699] 2025-02-24 10:10:06,530 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-02-24 10:10:06,532 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|configuration_utils.py:699] 2025-02-24 10:10:06,618 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-02-24 10:10:06,619 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/vocab.json\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/sentencepiece.bpe.model\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file tokenizer.json from cache at None\n","[INFO|tokenization_utils_base.py:2050] 2025-02-24 10:10:06,620 >> loading file chat_template.jinja from cache at None\n","[INFO|configuration_utils.py:699] 2025-02-24 10:10:06,621 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/config.json\n","[INFO|configuration_utils.py:771] 2025-02-24 10:10:06,621 >> Model config M2M100Config {\n","  \"_name_or_path\": \"facebook/m2m100_418M\",\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"relu\",\n","  \"architectures\": [\n","    \"M2M100ForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.05,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.05,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"max_length\": 200,\n","  \"max_position_embeddings\": 1024,\n","  \"model_type\": \"m2m_100\",\n","  \"num_beams\": 5,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"scale_embedding\": true,\n","  \"transformers_version\": \"4.50.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 128112\n","}\n","\n","[INFO|modeling_utils.py:3984] 2025-02-24 10:10:07,535 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/pytorch_model.bin\n","[INFO|safetensors_conversion.py:61] 2025-02-24 10:10:07,721 >> Attempting to create safetensors variant\n","[INFO|configuration_utils.py:1140] 2025-02-24 10:10:08,005 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","[INFO|safetensors_conversion.py:74] 2025-02-24 10:10:08,058 >> Safetensors PR exists\n","[INFO|modeling_utils.py:4972] 2025-02-24 10:10:08,109 >> All model checkpoint weights were used when initializing M2M100ForConditionalGeneration.\n","\n","[INFO|modeling_utils.py:4980] 2025-02-24 10:10:08,110 >> All the weights of M2M100ForConditionalGeneration were initialized from the model checkpoint at facebook/m2m100_418M.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use M2M100ForConditionalGeneration for predictions without further training.\n","[INFO|configuration_utils.py:1095] 2025-02-24 10:10:08,196 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--m2m100_418M/snapshots/55c2e61bbf05dfb8d7abccdc3fae6fc8512fd636/generation_config.json\n","[INFO|configuration_utils.py:1140] 2025-02-24 10:10:08,197 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"decoder_start_token_id\": 2,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 2,\n","  \"max_length\": 200,\n","  \"num_beams\": 5,\n","  \"pad_token_id\": 1\n","}\n","\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-bd43a683a527c5cb.arrow\n","02/24/2025 10:10:09 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-bd43a683a527c5cb.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-fbeb42321e5f1938.arrow\n","02/24/2025 10:10:10 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-fbeb42321e5f1938.arrow\n","Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d83bac065efcc482.arrow\n","02/24/2025 10:10:12 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-7f46d737aa0519c2/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-d83bac065efcc482.arrow\n","[INFO|trainer.py:2407] 2025-02-24 10:10:21,268 >> ***** Running training *****\n","[INFO|trainer.py:2408] 2025-02-24 10:10:21,268 >>   Num examples = 10,000\n","[INFO|trainer.py:2409] 2025-02-24 10:10:21,268 >>   Num Epochs = 3\n","[INFO|trainer.py:2410] 2025-02-24 10:10:21,268 >>   Instantaneous batch size per device = 4\n","[INFO|trainer.py:2412] 2025-02-24 10:10:21,268 >>   Training with DataParallel so batch size has been adjusted to: 8\n","[INFO|trainer.py:2413] 2025-02-24 10:10:21,268 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n","[INFO|trainer.py:2414] 2025-02-24 10:10:21,268 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:2415] 2025-02-24 10:10:21,268 >>   Total optimization steps = 3,750\n","[INFO|trainer.py:2416] 2025-02-24 10:10:21,269 >>   Number of trainable parameters = 483,905,536\n","[INFO|integration_utils.py:817] 2025-02-24 10:10:21,274 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33memmanuelka\u001b[0m (\u001b[33mpaderborn-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250224_101021-8ooos6od\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mM2M-100\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/paderborn-university/huggingface/runs/8ooos6od\u001b[0m\n","  0% 0/3750 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 4.1321, 'grad_norm': 7.187342166900635, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.4}\n"," 13% 500/3750 [06:09<41:35,  1.30it/s][INFO|trainer.py:3944] 2025-02-24 10:16:31,711 >> Saving model checkpoint to M2M-100/checkpoint-500\n","/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2810: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n","[INFO|configuration_utils.py:423] 2025-02-24 10:16:31,718 >> Configuration saved in M2M-100/checkpoint-500/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:16:31,719 >> Configuration saved in M2M-100/checkpoint-500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:16:36,684 >> Model weights saved in M2M-100/checkpoint-500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:16:36,687 >> tokenizer config file saved in M2M-100/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:16:36,688 >> Special tokens file saved in M2M-100/checkpoint-500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:16:36,688 >> added tokens file saved in M2M-100/checkpoint-500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.6438, 'grad_norm': 8.27725601196289, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n"," 27% 1000/3750 [12:38<33:57,  1.35it/s][INFO|trainer.py:3944] 2025-02-24 10:23:00,388 >> Saving model checkpoint to M2M-100/checkpoint-1000\n","[INFO|configuration_utils.py:423] 2025-02-24 10:23:00,390 >> Configuration saved in M2M-100/checkpoint-1000/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:23:00,391 >> Configuration saved in M2M-100/checkpoint-1000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:23:05,263 >> Model weights saved in M2M-100/checkpoint-1000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:23:05,268 >> tokenizer config file saved in M2M-100/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:23:05,268 >> Special tokens file saved in M2M-100/checkpoint-1000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:23:05,269 >> added tokens file saved in M2M-100/checkpoint-1000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 3.1631, 'grad_norm': 7.271153450012207, 'learning_rate': 3e-05, 'epoch': 1.2}\n"," 40% 1500/3750 [19:07<27:26,  1.37it/s][INFO|trainer.py:3944] 2025-02-24 10:29:29,468 >> Saving model checkpoint to M2M-100/checkpoint-1500\n","[INFO|configuration_utils.py:423] 2025-02-24 10:29:29,470 >> Configuration saved in M2M-100/checkpoint-1500/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:29:29,471 >> Configuration saved in M2M-100/checkpoint-1500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:29:34,381 >> Model weights saved in M2M-100/checkpoint-1500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:29:34,384 >> tokenizer config file saved in M2M-100/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:29:34,385 >> Special tokens file saved in M2M-100/checkpoint-1500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:29:34,385 >> added tokens file saved in M2M-100/checkpoint-1500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.7562, 'grad_norm': 8.272632598876953, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n"," 53% 2000/3750 [25:35<21:46,  1.34it/s][INFO|trainer.py:3944] 2025-02-24 10:35:57,731 >> Saving model checkpoint to M2M-100/checkpoint-2000\n","[INFO|configuration_utils.py:423] 2025-02-24 10:35:57,733 >> Configuration saved in M2M-100/checkpoint-2000/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:35:57,734 >> Configuration saved in M2M-100/checkpoint-2000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:36:02,680 >> Model weights saved in M2M-100/checkpoint-2000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:36:02,683 >> tokenizer config file saved in M2M-100/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:36:02,684 >> Special tokens file saved in M2M-100/checkpoint-2000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:36:02,684 >> added tokens file saved in M2M-100/checkpoint-2000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.6604, 'grad_norm': 8.227195739746094, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.0}\n"," 67% 2500/3750 [32:04<14:51,  1.40it/s][INFO|trainer.py:3944] 2025-02-24 10:42:27,110 >> Saving model checkpoint to M2M-100/checkpoint-2500\n","[INFO|configuration_utils.py:423] 2025-02-24 10:42:27,112 >> Configuration saved in M2M-100/checkpoint-2500/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:42:27,113 >> Configuration saved in M2M-100/checkpoint-2500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:42:32,036 >> Model weights saved in M2M-100/checkpoint-2500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:42:32,039 >> tokenizer config file saved in M2M-100/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:42:32,040 >> Special tokens file saved in M2M-100/checkpoint-2500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:42:32,040 >> added tokens file saved in M2M-100/checkpoint-2500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.1626, 'grad_norm': 9.739245414733887, 'learning_rate': 1e-05, 'epoch': 2.4}\n"," 80% 3000/3750 [38:33<09:14,  1.35it/s][INFO|trainer.py:3944] 2025-02-24 10:48:55,898 >> Saving model checkpoint to M2M-100/checkpoint-3000\n","[INFO|configuration_utils.py:423] 2025-02-24 10:48:55,900 >> Configuration saved in M2M-100/checkpoint-3000/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:48:55,901 >> Configuration saved in M2M-100/checkpoint-3000/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:49:00,946 >> Model weights saved in M2M-100/checkpoint-3000/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:49:00,949 >> tokenizer config file saved in M2M-100/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:49:00,950 >> Special tokens file saved in M2M-100/checkpoint-3000/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:49:00,950 >> added tokens file saved in M2M-100/checkpoint-3000/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","{'loss': 2.1526, 'grad_norm': 7.952200889587402, 'learning_rate': 3.3333333333333333e-06, 'epoch': 2.8}\n"," 93% 3500/3750 [45:02<03:07,  1.33it/s][INFO|trainer.py:3944] 2025-02-24 10:55:24,640 >> Saving model checkpoint to M2M-100/checkpoint-3500\n","[INFO|configuration_utils.py:423] 2025-02-24 10:55:24,642 >> Configuration saved in M2M-100/checkpoint-3500/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:55:24,643 >> Configuration saved in M2M-100/checkpoint-3500/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:55:29,668 >> Model weights saved in M2M-100/checkpoint-3500/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:55:29,671 >> tokenizer config file saved in M2M-100/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:55:29,672 >> Special tokens file saved in M2M-100/checkpoint-3500/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:55:29,672 >> added tokens file saved in M2M-100/checkpoint-3500/added_tokens.json\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 3750/3750 [48:26<00:00,  1.40it/s][INFO|trainer.py:3944] 2025-02-24 10:58:48,480 >> Saving model checkpoint to M2M-100/checkpoint-3750\n","[INFO|configuration_utils.py:423] 2025-02-24 10:58:48,482 >> Configuration saved in M2M-100/checkpoint-3750/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:58:48,483 >> Configuration saved in M2M-100/checkpoint-3750/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:58:53,666 >> Model weights saved in M2M-100/checkpoint-3750/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:58:53,670 >> tokenizer config file saved in M2M-100/checkpoint-3750/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:58:53,670 >> Special tokens file saved in M2M-100/checkpoint-3750/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:58:53,671 >> added tokens file saved in M2M-100/checkpoint-3750/added_tokens.json\n","[INFO|trainer.py:2659] 2025-02-24 10:59:07,505 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 2926.2364, 'train_samples_per_second': 10.252, 'train_steps_per_second': 1.282, 'train_loss': 2.8964515787760416, 'epoch': 3.0}\n","100% 3750/3750 [48:45<00:00,  1.28it/s]\n","[INFO|trainer.py:3944] 2025-02-24 10:59:07,516 >> Saving model checkpoint to M2M-100\n","[INFO|configuration_utils.py:423] 2025-02-24 10:59:07,518 >> Configuration saved in M2M-100/config.json\n","[INFO|configuration_utils.py:909] 2025-02-24 10:59:07,519 >> Configuration saved in M2M-100/generation_config.json\n","[INFO|modeling_utils.py:3040] 2025-02-24 10:59:16,467 >> Model weights saved in M2M-100/model.safetensors\n","[INFO|tokenization_utils_base.py:2500] 2025-02-24 10:59:16,470 >> tokenizer config file saved in M2M-100/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2509] 2025-02-24 10:59:16,470 >> Special tokens file saved in M2M-100/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2562] 2025-02-24 10:59:16,471 >> added tokens file saved in M2M-100/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  total_flos               =  2053987GF\n","  train_loss               =     2.8965\n","  train_runtime            = 0:48:46.23\n","  train_samples            =      10000\n","  train_samples_per_second =     10.252\n","  train_steps_per_second   =      1.282\n","02/24/2025 10:59:16 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:4260] 2025-02-24 10:59:16,625 >> \n","***** Running Evaluation *****\n","[INFO|trainer.py:4262] 2025-02-24 10:59:16,625 >>   Num examples = 3000\n","[INFO|trainer.py:4265] 2025-02-24 10:59:16,626 >>   Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn(\n","100% 375/375 [19:41<00:00,  3.15s/it]\n","***** eval metrics *****\n","  epoch                   =        3.0\n","  eval_bleu               =     7.9488\n","  eval_gen_len            =      24.16\n","  eval_loss               =     2.7156\n","  eval_runtime            = 0:19:42.59\n","  eval_samples            =       3000\n","  eval_samples_per_second =      2.537\n","  eval_steps_per_second   =      0.317\n","02/24/2025 11:18:59 - INFO - __main__ - *** Predict ***\n","[INFO|trainer.py:4260] 2025-02-24 11:18:59,222 >> \n","***** Running Prediction *****\n","[INFO|trainer.py:4262] 2025-02-24 11:18:59,222 >>   Num examples = 1000\n","[INFO|trainer.py:4265] 2025-02-24 11:18:59,222 >>   Batch size = 8\n","100% 125/125 [04:58<00:00,  2.39s/it]\n","***** predict metrics *****\n","  predict_bleu               =     9.3252\n","  predict_gen_len            =     20.779\n","  predict_loss               =     2.4305\n","  predict_runtime            = 0:05:00.06\n","  predict_samples            =       1000\n","  predict_samples_per_second =      3.333\n","  predict_steps_per_second   =      0.417\n","[INFO|modelcard.py:449] 2025-02-24 11:24:12,922 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Translation', 'type': 'translation'}, 'metrics': [{'name': 'Bleu', 'type': 'bleu', 'value': 7.9488}]}\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"hbNrB5boVIgU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740396255536,"user_tz":-120,"elapsed":8,"user":{"displayName":"Emmanuel Kwame AYANFUL","userId":"02540403979605827324"}},"outputId":"8ff025dd-fa3b-44f5-aaf5-d4c3f5e13bed"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Feb 24 11:24:14 2025       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0              33W /  70W |      0MiB / 15360MiB |     55%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n","| N/A   54C    P0              32W /  70W |      0MiB / 15360MiB |     47%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]}]}